<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Time Series - Deep Learning for TS</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles/layout.css">
<link rel="stylesheet" href="./styles/layout.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Time Series</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about.html">
 <span class="menu-text">ABOUT ME</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Introduction.html">
 <span class="menu-text">Introduction</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./DataSources.html">
 <span class="menu-text">Data Sources</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./DataVis.html">
 <span class="menu-text">Data Visualization</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./EDA.html">
 <span class="menu-text">Exploratory Data Analysis</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./ARModels.html">
 <span class="menu-text">ARMA/ARIMA/SARIMA Models</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./ASV.html">
 <span class="menu-text">ARIMAX/SARIMAX/VAR</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./SAF.html">
 <span class="menu-text">Spectral Analysis and Filtering</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./GARCH.html">
 <span class="menu-text">Financial Time Series Models (ARCH/GARCH)</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./TS.html" aria-current="page">
 <span class="menu-text">Deep Learning for TS</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./conclusion.html">
 <span class="menu-text">Conclusions</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#median-sale-price-deep-learning-analysis" id="toc-median-sale-price-deep-learning-analysis" class="nav-link active" data-scroll-target="#median-sale-price-deep-learning-analysis">Median Sale Price Deep Learning Analysis</a>
  <ul class="collapse">
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">Data Preparation</a></li>
  <li><a href="#train-test-dataset" id="toc-train-test-dataset" class="nav-link" data-scroll-target="#train-test-dataset">Train &amp; Test Dataset</a></li>
  <li><a href="#preparation-for-input-and-target" id="toc-preparation-for-input-and-target" class="nav-link" data-scroll-target="#preparation-for-input-and-target">Preparation For Input and Target</a></li>
  <li><a href="#lstm" id="toc-lstm" class="nav-link" data-scroll-target="#lstm">LSTM</a>
  <ul class="collapse">
  <li><a href="#no-regularization" id="toc-no-regularization" class="nav-link" data-scroll-target="#no-regularization">NO Regularization</a></li>
  <li><a href="#with-regularization" id="toc-with-regularization" class="nav-link" data-scroll-target="#with-regularization">With Regularization</a></li>
  <li><a href="#predictions-discussions" id="toc-predictions-discussions" class="nav-link" data-scroll-target="#predictions-discussions">Predictions &amp; Discussions</a></li>
  <li><a href="#regulariztaion-effect" id="toc-regulariztaion-effect" class="nav-link" data-scroll-target="#regulariztaion-effect">Regulariztaion Effect</a></li>
  <li><a href="#how-far-into-future" id="toc-how-far-into-future" class="nav-link" data-scroll-target="#how-far-into-future">How Far Into Future</a></li>
  </ul></li>
  <li><a href="#rnn" id="toc-rnn" class="nav-link" data-scroll-target="#rnn">RNN</a>
  <ul class="collapse">
  <li><a href="#no-regularization-1" id="toc-no-regularization-1" class="nav-link" data-scroll-target="#no-regularization-1">No Regularization</a></li>
  <li><a href="#with-regularization-1" id="toc-with-regularization-1" class="nav-link" data-scroll-target="#with-regularization-1">With Regularization</a></li>
  <li><a href="#predictions" id="toc-predictions" class="nav-link" data-scroll-target="#predictions">Predictions</a></li>
  </ul></li>
  <li><a href="#gru" id="toc-gru" class="nav-link" data-scroll-target="#gru">GRU</a>
  <ul class="collapse">
  <li><a href="#no-regularization-2" id="toc-no-regularization-2" class="nav-link" data-scroll-target="#no-regularization-2">NO Regularization</a></li>
  <li><a href="#with-regularization-2" id="toc-with-regularization-2" class="nav-link" data-scroll-target="#with-regularization-2">With Regularization</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#household-saving-deep-learning-analysis" id="toc-household-saving-deep-learning-analysis" class="nav-link" data-scroll-target="#household-saving-deep-learning-analysis">Household Saving Deep Learning Analysis</a>
  <ul class="collapse">
  <li><a href="#data-preparation-1" id="toc-data-preparation-1" class="nav-link" data-scroll-target="#data-preparation-1">Data Preparation</a></li>
  <li><a href="#lstm-1" id="toc-lstm-1" class="nav-link" data-scroll-target="#lstm-1">LSTM</a>
  <ul class="collapse">
  <li><a href="#no-regularization-3" id="toc-no-regularization-3" class="nav-link" data-scroll-target="#no-regularization-3">No Regularization</a></li>
  <li><a href="#with-regularization-3" id="toc-with-regularization-3" class="nav-link" data-scroll-target="#with-regularization-3">With Regularization</a></li>
  </ul></li>
  <li><a href="#rnn-1" id="toc-rnn-1" class="nav-link" data-scroll-target="#rnn-1">RNN</a>
  <ul class="collapse">
  <li><a href="#no-regularization-4" id="toc-no-regularization-4" class="nav-link" data-scroll-target="#no-regularization-4">No Regularization</a></li>
  <li><a href="#with-regularization-4" id="toc-with-regularization-4" class="nav-link" data-scroll-target="#with-regularization-4">With Regularization</a></li>
  </ul></li>
  <li><a href="#gru-1" id="toc-gru-1" class="nav-link" data-scroll-target="#gru-1">GRU</a>
  <ul class="collapse">
  <li><a href="#no-regularization-5" id="toc-no-regularization-5" class="nav-link" data-scroll-target="#no-regularization-5">No Regularization</a></li>
  <li><a href="#with-regularization-5" id="toc-with-regularization-5" class="nav-link" data-scroll-target="#with-regularization-5">With Regularization</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#discussions-i" id="toc-discussions-i" class="nav-link" data-scroll-target="#discussions-i">Discussions I</a>
  <ul class="collapse">
  <li><a href="#for-median-sale-price" id="toc-for-median-sale-price" class="nav-link" data-scroll-target="#for-median-sale-price">For Median Sale Price</a>
  <ul class="collapse">
  <li><a href="#deep-learning-methods-comparison" id="toc-deep-learning-methods-comparison" class="nav-link" data-scroll-target="#deep-learning-methods-comparison">Deep learning methods comparison</a></li>
  <li><a href="#regulariztaion-effect-1" id="toc-regulariztaion-effect-1" class="nav-link" data-scroll-target="#regulariztaion-effect-1">Regulariztaion Effect</a></li>
  <li><a href="#how-far-can-the-deep-learning-methods-predict" id="toc-how-far-can-the-deep-learning-methods-predict" class="nav-link" data-scroll-target="#how-far-can-the-deep-learning-methods-predict">How Far can the deep learning methods predict</a></li>
  <li><a href="#comparison-to-armaarima" id="toc-comparison-to-armaarima" class="nav-link" data-scroll-target="#comparison-to-armaarima">Comparison to ARMA/ARIMA</a></li>
  </ul></li>
  <li><a href="#for-household-saving" id="toc-for-household-saving" class="nav-link" data-scroll-target="#for-household-saving">For Household Saving</a>
  <ul class="collapse">
  <li><a href="#deep-learning-methods-comparison-1" id="toc-deep-learning-methods-comparison-1" class="nav-link" data-scroll-target="#deep-learning-methods-comparison-1">Deep learning methods comparison</a></li>
  <li><a href="#regularization-effect" id="toc-regularization-effect" class="nav-link" data-scroll-target="#regularization-effect">Regularization Effect</a></li>
  <li><a href="#how-far-can-the-deep-learning-methods-predict-1" id="toc-how-far-can-the-deep-learning-methods-predict-1" class="nav-link" data-scroll-target="#how-far-can-the-deep-learning-methods-predict-1">How Far can the deep learning methods predict</a></li>
  <li><a href="#comparison-to-armaarima-1" id="toc-comparison-to-armaarima-1" class="nav-link" data-scroll-target="#comparison-to-armaarima-1">Comparison to ARMA/ARIMA</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#gdp-deflator-deep-learning-analysis-compare-with-var-model" id="toc-gdp-deflator-deep-learning-analysis-compare-with-var-model" class="nav-link" data-scroll-target="#gdp-deflator-deep-learning-analysis-compare-with-var-model">GDP Deflator Deep Learning Analysis (Compare With VAR Model)</a>
  <ul class="collapse">
  <li><a href="#data-preparation-2" id="toc-data-preparation-2" class="nav-link" data-scroll-target="#data-preparation-2">Data Preparation</a></li>
  <li><a href="#lstm-2" id="toc-lstm-2" class="nav-link" data-scroll-target="#lstm-2">LSTM</a>
  <ul class="collapse">
  <li><a href="#no-regularization-6" id="toc-no-regularization-6" class="nav-link" data-scroll-target="#no-regularization-6">No Regularization</a></li>
  <li><a href="#with-regularization-6" id="toc-with-regularization-6" class="nav-link" data-scroll-target="#with-regularization-6">With Regularization</a></li>
  </ul></li>
  <li><a href="#rnn-2" id="toc-rnn-2" class="nav-link" data-scroll-target="#rnn-2">RNN</a>
  <ul class="collapse">
  <li><a href="#no-regularization-7" id="toc-no-regularization-7" class="nav-link" data-scroll-target="#no-regularization-7">No Regularization</a></li>
  <li><a href="#with-regularization-7" id="toc-with-regularization-7" class="nav-link" data-scroll-target="#with-regularization-7">With Regularization</a></li>
  </ul></li>
  <li><a href="#gru-2" id="toc-gru-2" class="nav-link" data-scroll-target="#gru-2">GRU</a>
  <ul class="collapse">
  <li><a href="#no-regularization-8" id="toc-no-regularization-8" class="nav-link" data-scroll-target="#no-regularization-8">No Regularization</a></li>
  <li><a href="#with-regularization-8" id="toc-with-regularization-8" class="nav-link" data-scroll-target="#with-regularization-8">With Regularization</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#discussions-ii" id="toc-discussions-ii" class="nav-link" data-scroll-target="#discussions-ii">Discussions II</a>
  <ul class="collapse">
  <li><a href="#for-gdp-deflator" id="toc-for-gdp-deflator" class="nav-link" data-scroll-target="#for-gdp-deflator">For GDP Deflator</a>
  <ul class="collapse">
  <li><a href="#deep-learning-methods-comparison-2" id="toc-deep-learning-methods-comparison-2" class="nav-link" data-scroll-target="#deep-learning-methods-comparison-2">Deep learning methods comparison</a></li>
  <li><a href="#regularization-effect-1" id="toc-regularization-effect-1" class="nav-link" data-scroll-target="#regularization-effect-1">Regularization Effect</a></li>
  <li><a href="#how-far-can-the-deep-learning-methods-predict-2" id="toc-how-far-can-the-deep-learning-methods-predict-2" class="nav-link" data-scroll-target="#how-far-can-the-deep-learning-methods-predict-2">How Far can the deep learning methods predict</a></li>
  <li><a href="#comparison-to-var-model" id="toc-comparison-to-var-model" class="nav-link" data-scroll-target="#comparison-to-var-model">Comparison to VAR Model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#multivariable-deep-learning-optional" id="toc-multivariable-deep-learning-optional" class="nav-link" data-scroll-target="#multivariable-deep-learning-optional">Multivariable Deep Learning (OPTIONAL)</a>
  <ul class="collapse">
  <li><a href="#data-preparation-gdp-deflator-personal-saving-rate-median-sale-price" id="toc-data-preparation-gdp-deflator-personal-saving-rate-median-sale-price" class="nav-link" data-scroll-target="#data-preparation-gdp-deflator-personal-saving-rate-median-sale-price">Data Preparation: GDP Deflator, Personal Saving Rate, Median Sale Price</a></li>
  <li><a href="#array-preparations-for-modeling" id="toc-array-preparations-for-modeling" class="nav-link" data-scroll-target="#array-preparations-for-modeling">Array Preparations for Modeling</a></li>
  <li><a href="#lstm-3" id="toc-lstm-3" class="nav-link" data-scroll-target="#lstm-3">LSTM</a>
  <ul class="collapse">
  <li><a href="#no-regularization-9" id="toc-no-regularization-9" class="nav-link" data-scroll-target="#no-regularization-9">No Regularization</a></li>
  <li><a href="#with-regularization-9" id="toc-with-regularization-9" class="nav-link" data-scroll-target="#with-regularization-9">With Regularization</a></li>
  </ul></li>
  <li><a href="#rnn-3" id="toc-rnn-3" class="nav-link" data-scroll-target="#rnn-3">RNN</a>
  <ul class="collapse">
  <li><a href="#with-regularization-10" id="toc-with-regularization-10" class="nav-link" data-scroll-target="#with-regularization-10">With Regularization</a></li>
  </ul></li>
  <li><a href="#gru-3" id="toc-gru-3" class="nav-link" data-scroll-target="#gru-3">GRU</a>
  <ul class="collapse">
  <li><a href="#no-regularization-10" id="toc-no-regularization-10" class="nav-link" data-scroll-target="#no-regularization-10">No Regularization</a></li>
  <li><a href="#with-regularization-11" id="toc-with-regularization-11" class="nav-link" data-scroll-target="#with-regularization-11">With Regularization</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#discussion-iii" id="toc-discussion-iii" class="nav-link" data-scroll-target="#discussion-iii">Discussion III</a>
  <ul class="collapse">
  <li><a href="#overall-effect-of-including-regularization" id="toc-overall-effect-of-including-regularization" class="nav-link" data-scroll-target="#overall-effect-of-including-regularization">Overall Effect of Including Regularization:</a></li>
  <li><a href="#how-far-can-the-deep-learning-model-predict" id="toc-how-far-can-the-deep-learning-model-predict" class="nav-link" data-scroll-target="#how-far-can-the-deep-learning-model-predict">How far can the Deep Learning Model predict</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Deep Learning for TS</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="median-sale-price-deep-learning-analysis" class="level1">
<h1>Median Sale Price Deep Learning Analysis</h1>
<p>The first analysis is the median sale price analysis, which is also utilzied during previous sections. In here, the goal is to utilize three different models: LSTM, RNN, and GRU. Then make comparsion between deep learning methods and ARIMA models.</p>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data Preparation</h2>
<p>The corresponding time seires dataset is prepared and cleaned with objective column and then use train test splits for furthering steps in later section.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> SimpleRNN, Dense</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> LSTM, GRU, Dense</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> regularizers</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting seeds for reproducibility</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">236</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">236</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>tf.random.set_seed(<span class="dv">236</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"../Dataset/project/MSPUS.csv"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.rename(columns<span class="op">=</span>{<span class="st">"MSPUS"</span>: <span class="st">"y"</span>}) <span class="co"># The objective</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">"DATE"</span>, <span class="st">"y"</span>]]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(df[<span class="st">"y"</span>].values.astype(<span class="st">"float32"</span>)).reshape(df.shape[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Train and Test Split &amp; Normalization</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_test_split(data, split_percent<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> scaler.fit_transform(data).flatten()</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    split <span class="op">=</span> <span class="bu">int</span>(n <span class="op">*</span> split_percent)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> data[<span class="bu">range</span>(split)]</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    test_data <span class="op">=</span> data[split:]</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_data, test_data, data</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>train_data, test_data, data <span class="op">=</span> train_test_split(X)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train shape:"</span>, train_data.shape)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test shape:"</span>, test_data.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\yzh20\anaconda3\lib\site-packages\scipy\__init__.py:146: UserWarning:

A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.26.0
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>WARNING:tensorflow:From C:\Users\yzh20\anaconda3\lib\site-packages\keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>WARNING:tensorflow:From C:\Users\yzh20\AppData\Local\Temp\ipykernel_43192\124761955.py:15: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>train shape: (193,)
test shape: (49,)</code></pre>
</div>
</div>
</section>
<section id="train-test-dataset" class="level2">
<h2 class="anchored" data-anchor-id="train-test-dataset">Train &amp; Test Dataset</h2>
<p>Below, we can see clearly about the train and test dataset that I splitted. The goal is to have a visulization of the dataset as a whole.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">100</span>)  <span class="co"># Set the size and DPI of the figure</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>fig.patch.set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the background color for the outer figure</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>ax.set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the background color for the axes</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the training data</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(train_data)), train_data, <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Training Data"</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the test data</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="bu">len</span>(train_data), <span class="bu">len</span>(train_data) <span class="op">+</span> <span class="bu">len</span>(test_data)), test_data, <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Test Data"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Set labels and title</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Time (days)"</span>, ylabel<span class="op">=</span><span class="st">"Median Sale Price Scaled"</span>, title<span class="op">=</span><span class="st">"Median Sale Price Over Time"</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Add grid with white color for better visibility on the gray background</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>ax.grid(color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Add legend to the plot</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-3-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="preparation-for-input-and-target" class="level2">
<h2 class="anchored" data-anchor-id="preparation-for-input-and-target">Preparation For Input and Target</h2>
<p>In order to correctly fit into the corresonding models, the size of x and y must be determined and transformed correctly.</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PREPARE THE INPUT X AND TARGET Y</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_XY(dat, time_steps, plot_data_partition<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> X_ind, X, Y_ind, Y  <span class="co"># use for plotting later</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># INDICES OF TARGET ARRAY</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Y_ind [  12   24   36   48 ..]; print(np.arange(1,12,1)); exit()</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    Y_ind <span class="op">=</span> np.arange(time_steps, <span class="bu">len</span>(dat), time_steps)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(Y_ind); exit()</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> dat[Y_ind]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PREPARE X</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    rows_x <span class="op">=</span> <span class="bu">len</span>(Y)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    X_ind <span class="op">=</span> [<span class="op">*</span><span class="bu">range</span>(time_steps <span class="op">*</span> rows_x)]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">del</span> X_ind[::time_steps]  <span class="co"># if time_steps=10 remove every 10th entry</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> dat[X_ind]</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PLOT</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> plot_data_partition:</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        plt.plot(Y_ind, Y, <span class="st">"o"</span>, X_ind, X, <span class="st">"-"</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RESHAPE INTO KERAS FORMAT</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    X1 <span class="op">=</span> np.reshape(X, (rows_x, time_steps <span class="op">-</span> <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print([*X_ind]); print(X1); print(X1.shape,Y.shape); exit()</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X1, Y</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co"># PARTITION DATA</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">30</span>  <span class="co">#</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>testX, testY <span class="op">=</span> get_XY(test_data, p)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>trainX, trainY <span class="op">=</span> get_XY(train_data, p)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a> <span class="co">#USER PARAM</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>recurrent_hidden_units <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>f_batch <span class="op">=</span> <span class="fl">0.2</span>  <span class="co"># fraction used for batch size</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> <span class="st">"RMSprop"</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="co"># trainY=trainY.reshape(trainY.shape[0],1)</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a><span class="co"># testY=testY.reshape(testY.shape[0],1)</span></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Array Shape:"</span>, testX.shape, testY.shape)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Array Shape:"</span>, trainX.shape, trainY.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Testing Array Shape: (1, 29, 1) (1,)
Training Array Shape: (6, 29, 1) (6,)</code></pre>
</div>
</div>
<p>Now, we are ready for training into the model for analysis.</p>
</section>
<section id="lstm" class="level2">
<h2 class="anchored" data-anchor-id="lstm">LSTM</h2>
<p>For this LSTM model, we will compare the performance using RMSE for regularization and no regularization.</p>
<section id="no-regularization" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization">NO Regularization</h3>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> lstm (LSTM)                 (None, 3)                 60        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense (Dense)               (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_result(trainY, testY, train_predict, test_predict):</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">200</span>, facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>)  <span class="co"># Set higher DPI and background color for the figure</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ORIGINAL DATA</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(X.shape, Y.shape)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, Y, <span class="st">"o"</span>, label<span class="op">=</span><span class="st">"Target"</span>)</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>    plt.plot(X_ind, X, <span class="st">"."</span>, label<span class="op">=</span><span class="st">"Training points"</span>)</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, train_predict, <span class="st">"b."</span>, label<span class="op">=</span><span class="st">"Prediction"</span>)</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, train_predict, <span class="st">"r-"</span>)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Observation number after given time steps"</span>)</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Median Sale Price Scaled"</span>)</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Actual and Predicted Values"</span>)</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>    plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set grid color to white for better visibility</span></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 255ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-6-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00324 RMSE = 0.05688
Test MSE = 0.08436 RMSE = 0.29045</code></pre>
</div>
</div>
<p>For LSTM with no regulariztaion, we have the test and train RMSE: 0.29045 and 0.05688</p>
<section id="predication-plot" class="level4">
<h4 class="anchored" data-anchor-id="predication-plot">Predication Plot</h4>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(174,) (6,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-7-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We can see that from this plot based on LSTM no regulariztaion, the performance of the model is pretty good. The targets and prediction values are close.</p>
</section>
</section>
<section id="with-regularization" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization">With Regularization</h3>
<p>Now, we compare the model by adding some regularization. The goal of the regularization is to prevent overfitting.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(SimpleRNN(</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> lstm_1 (LSTM)               (None, 3)                 60        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_1 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 237ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-9-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00049 RMSE = 0.02203
Test MSE = 0.02428 RMSE = 0.15581</code></pre>
</div>
</div>
<p>From here, we can see that the test and train RMSE becomes: 0.15581 and 0.02203.</p>
<p>In this case, by adding the regularization the RMSE becomes lower. This means that my model did not overfit. Overall, LSTM performs well.</p>
</section>
<section id="predictions-discussions" class="level3">
<h3 class="anchored" data-anchor-id="predictions-discussions">Predictions &amp; Discussions</h3>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(174,) (6,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="regulariztaion-effect" class="level3">
<h3 class="anchored" data-anchor-id="regulariztaion-effect">Regulariztaion Effect</h3>
<p>The result suggests that the model is able to capture the underlying trend in the data quite well. Regularization comparsion proved that the model did not overfit. Also, the smoothness of the prediction curve indicates that the L2 regularization has effectively penalized overly complex models that could have fit the noise in the training data.</p>
</section>
<section id="how-far-into-future" class="level3">
<h3 class="anchored" data-anchor-id="how-far-into-future">How Far Into Future</h3>
<p>The predictions seem to align well with the actual data for most of the original dataset. However, there appears to be a slight divergence toward the end. This divergence might indicate the limit of the models predictive horizon, which is about 175 days ahead. In this case, we can say that the model can predict with relatively accuracy for 200 days ahead.</p>
</section>
</section>
<section id="rnn" class="level2">
<h2 class="anchored" data-anchor-id="rnn">RNN</h2>
<section id="no-regularization-1" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-1">No Regularization</h3>
<p>Likewise, we will test the model prediction and errors with and without regularization for each model.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb61-39"><a href="#cb61-39" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb61-40"><a href="#cb61-40" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb61-41"><a href="#cb61-41" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb61-42"><a href="#cb61-42" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb61-43"><a href="#cb61-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb61-44"><a href="#cb61-44" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb61-45"><a href="#cb61-45" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb61-46"><a href="#cb61-46" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb61-47"><a href="#cb61-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb61-48"><a href="#cb61-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-49"><a href="#cb61-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-50"><a href="#cb61-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb61-51"><a href="#cb61-51" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb61-52"><a href="#cb61-52" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb61-53"><a href="#cb61-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-54"><a href="#cb61-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb61-55"><a href="#cb61-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb61-56"><a href="#cb61-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-57"><a href="#cb61-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb61-58"><a href="#cb61-58" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb61-59"><a href="#cb61-59" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb61-60"><a href="#cb61-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-61"><a href="#cb61-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb61-62"><a href="#cb61-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb61-63"><a href="#cb61-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_2"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> simple_rnn (SimpleRNN)      (None, 3)                 15        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_2 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 90ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-11-output-18.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 17ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00137 RMSE = 0.03706
Test MSE = 0.05575 RMSE = 0.23612</code></pre>
</div>
</div>
<p>With no regularization, the RNN performs better than LSTM with lower rmse. However, regularization can help us prevent overfitting. Therefore, we need further using regularization to make thorough analysis.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(174,) (6,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="with-regularization-1" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-1">With Regularization</h3>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb86-21"><a href="#cb86-21" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb86-22"><a href="#cb86-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-23"><a href="#cb86-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb86-24"><a href="#cb86-24" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb86-25"><a href="#cb86-25" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Ensures a 1D array output</span></span>
<span id="cb86-26"><a href="#cb86-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-27"><a href="#cb86-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Check shapes again to verify</span></span>
<span id="cb86-28"><a href="#cb86-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb86-29"><a href="#cb86-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-30"><a href="#cb86-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb86-31"><a href="#cb86-31" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb86-32"><a href="#cb86-32" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb86-33"><a href="#cb86-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-34"><a href="#cb86-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb86-35"><a href="#cb86-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb86-36"><a href="#cb86-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_3"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> simple_rnn_1 (SimpleRNN)    (None, 3)                 15        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_3 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 90ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.27946 RMSE = 0.52864
Test MSE = 1.46867 RMSE = 1.21189</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb105-18"><a href="#cb105-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb105-19"><a href="#cb105-19" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb105-20"><a href="#cb105-20" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb105-21"><a href="#cb105-21" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb105-22"><a href="#cb105-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb105-23"><a href="#cb105-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (train_rmse<span class="op">**</span><span class="fl">2.0</span>, train_rmse))</span>
<span id="cb105-24"><a href="#cb105-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (test_rmse<span class="op">**</span><span class="fl">2.0</span>, test_rmse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.27946 RMSE = 0.52864
Test MSE = 1.46867 RMSE = 1.21189</code></pre>
</div>
</div>
<p>Now, there are relatievly large differences when using regularization in RNN model. The results show that the model will overfit if we do not use regularization in RNN. The result for RNN model with regularization performs less than the LSTM model with higher rmse values.</p>
</section>
<section id="predictions" class="level3">
<h3 class="anchored" data-anchor-id="predictions">Predictions</h3>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(174,) (6,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-15-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The figure of the predictions and actual values also proves that the RNN model with regulariztaion performs less than the LSTM model. We can see that there are differences for the step points</p>
</section>
</section>
<section id="gru" class="level2">
<h2 class="anchored" data-anchor-id="gru">GRU</h2>
<p>The third model is GRU, we will also test the two results for both with regulariztaion and no regularization. Then by combining the results in a table, we can compare them clearly.</p>
<section id="no-regularization-2" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-2">NO Regularization</h3>
<p>Likewise, we will test the model prediction and errors with and without regularization for each model.</p>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-17"><a href="#cb109-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb109-18"><a href="#cb109-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb109-19"><a href="#cb109-19" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb109-20"><a href="#cb109-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-21"><a href="#cb109-21" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb109-22"><a href="#cb109-22" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb109-23"><a href="#cb109-23" aria-hidden="true" tabindex="-1"></a>tf.random.set_seed(<span class="dv">42</span>)</span>
<span id="cb109-24"><a href="#cb109-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-25"><a href="#cb109-25" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb109-26"><a href="#cb109-26" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb109-27"><a href="#cb109-27" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb109-28"><a href="#cb109-28" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb109-29"><a href="#cb109-29" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb109-30"><a href="#cb109-30" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb109-31"><a href="#cb109-31" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb109-32"><a href="#cb109-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb109-33"><a href="#cb109-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-34"><a href="#cb109-34" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb109-35"><a href="#cb109-35" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb109-36"><a href="#cb109-36" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb109-37"><a href="#cb109-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-38"><a href="#cb109-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-39"><a href="#cb109-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb109-40"><a href="#cb109-40" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb109-41"><a href="#cb109-41" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb109-42"><a href="#cb109-42" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb109-43"><a href="#cb109-43" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb109-44"><a href="#cb109-44" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb109-45"><a href="#cb109-45" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb109-46"><a href="#cb109-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb109-47"><a href="#cb109-47" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb109-48"><a href="#cb109-48" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb109-49"><a href="#cb109-49" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb109-50"><a href="#cb109-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb109-51"><a href="#cb109-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-52"><a href="#cb109-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-53"><a href="#cb109-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb109-54"><a href="#cb109-54" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb109-55"><a href="#cb109-55" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb109-56"><a href="#cb109-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-57"><a href="#cb109-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb109-58"><a href="#cb109-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb109-59"><a href="#cb109-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-60"><a href="#cb109-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb109-61"><a href="#cb109-61" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb109-62"><a href="#cb109-62" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb109-63"><a href="#cb109-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-64"><a href="#cb109-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb109-65"><a href="#cb109-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb109-66"><a href="#cb109-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_4"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> gru (GRU)                   (None, 3)                 54        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_4 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 217ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-16-output-18.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00003 RMSE = 0.00535
Test MSE = 0.00281 RMSE = 0.05301</code></pre>
</div>
</div>
<p>We can see that with no regulariztaion, the model performs very good. However, it could be overfitting.</p>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the function with your data</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(174,) (6,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-17-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The predictions and actual values align very well. This could be the reason of overfitting.</p>
</section>
<section id="with-regularization-2" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-2">With Regularization</h3>
<div class="cell" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb134-11"><a href="#cb134-11" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb134-12"><a href="#cb134-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb134-13"><a href="#cb134-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb134-14"><a href="#cb134-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-15"><a href="#cb134-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb134-16"><a href="#cb134-16" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb134-17"><a href="#cb134-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-18"><a href="#cb134-18" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb134-19"><a href="#cb134-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb134-20"><a href="#cb134-20" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb134-21"><a href="#cb134-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-22"><a href="#cb134-22" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb134-23"><a href="#cb134-23" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb134-24"><a href="#cb134-24" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb134-25"><a href="#cb134-25" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb134-26"><a href="#cb134-26" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb134-27"><a href="#cb134-27" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb134-28"><a href="#cb134-28" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb134-29"><a href="#cb134-29" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb134-30"><a href="#cb134-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb134-31"><a href="#cb134-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-32"><a href="#cb134-32" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb134-33"><a href="#cb134-33" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb134-34"><a href="#cb134-34" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb134-35"><a href="#cb134-35" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb134-36"><a href="#cb134-36" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb134-37"><a href="#cb134-37" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb134-38"><a href="#cb134-38" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb134-39"><a href="#cb134-39" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb134-40"><a href="#cb134-40" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb134-41"><a href="#cb134-41" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb134-42"><a href="#cb134-42" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb134-43"><a href="#cb134-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb134-44"><a href="#cb134-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-45"><a href="#cb134-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb134-46"><a href="#cb134-46" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()  <span class="co"># Ensures a 1D array output</span></span>
<span id="cb134-47"><a href="#cb134-47" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()</span>
<span id="cb134-48"><a href="#cb134-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-49"><a href="#cb134-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb134-50"><a href="#cb134-50" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb134-51"><a href="#cb134-51" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb134-52"><a href="#cb134-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-53"><a href="#cb134-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb134-54"><a href="#cb134-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb134-55"><a href="#cb134-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_5"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> gru_1 (GRU)                 (None, 3)                 54        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_5 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-18-output-14.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 210ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.01689 RMSE = 0.12998
Test MSE = 0.15742 RMSE = 0.39676</code></pre>
</div>
</div>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(174,) (6,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-19-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We can see that if we add regularization, the result of RMSE becomes higher. This shows that with no regularization, the GRU model overfitted.</p>
<p>In general, in my case, with regularization, LSTM model performed the best among the three models. RNN model perfomed the least among the three models.</p>
</section>
</section>
</section>
<section id="household-saving-deep-learning-analysis" class="level1">
<h1>Household Saving Deep Learning Analysis</h1>
<p>As we did in ARMA section, we will also do the deep learning analysis and compare with the results for household saving analysis.</p>
<section id="data-preparation-1" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation-1">Data Preparation</h2>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"../Dataset/project/household_saving.csv"</span>)</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.rename(columns<span class="op">=</span>{<span class="st">"W398RC1A027NBEA"</span>: <span class="st">"y"</span>}) <span class="co"># The objective</span></span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">"DATE"</span>, <span class="st">"y"</span>]]</span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(df[<span class="st">"y"</span>].values.astype(<span class="st">"float32"</span>)).reshape(df.shape[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Train and Test Split &amp; Normalization</span></span>
<span id="cb155-7"><a href="#cb155-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-8"><a href="#cb155-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_test_split(data, split_percent<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb155-9"><a href="#cb155-9" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb155-10"><a href="#cb155-10" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> scaler.fit_transform(data).flatten()</span>
<span id="cb155-11"><a href="#cb155-11" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb155-12"><a href="#cb155-12" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb155-13"><a href="#cb155-13" aria-hidden="true" tabindex="-1"></a>    split <span class="op">=</span> <span class="bu">int</span>(n <span class="op">*</span> split_percent)</span>
<span id="cb155-14"><a href="#cb155-14" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> data[<span class="bu">range</span>(split)]</span>
<span id="cb155-15"><a href="#cb155-15" aria-hidden="true" tabindex="-1"></a>    test_data <span class="op">=</span> data[split:]</span>
<span id="cb155-16"><a href="#cb155-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_data, test_data, data</span>
<span id="cb155-17"><a href="#cb155-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-18"><a href="#cb155-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-19"><a href="#cb155-19" aria-hidden="true" tabindex="-1"></a>train_data, test_data, data <span class="op">=</span> train_test_split(X)</span>
<span id="cb155-20"><a href="#cb155-20" aria-hidden="true" tabindex="-1"></a><span class="co"># PREPARE THE INPUT X AND TARGET Y</span></span>
<span id="cb155-21"><a href="#cb155-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_XY(dat, time_steps, plot_data_partition<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb155-22"><a href="#cb155-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> X_ind, X, Y_ind, Y  <span class="co"># use for plotting later</span></span>
<span id="cb155-23"><a href="#cb155-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-24"><a href="#cb155-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># INDICES OF TARGET ARRAY</span></span>
<span id="cb155-25"><a href="#cb155-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Y_ind [  12   24   36   48 ..]; print(np.arange(1,12,1)); exit()</span></span>
<span id="cb155-26"><a href="#cb155-26" aria-hidden="true" tabindex="-1"></a>    Y_ind <span class="op">=</span> np.arange(time_steps, <span class="bu">len</span>(dat), time_steps)</span>
<span id="cb155-27"><a href="#cb155-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(Y_ind); exit()</span></span>
<span id="cb155-28"><a href="#cb155-28" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> dat[Y_ind]</span>
<span id="cb155-29"><a href="#cb155-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-30"><a href="#cb155-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PREPARE X</span></span>
<span id="cb155-31"><a href="#cb155-31" aria-hidden="true" tabindex="-1"></a>    rows_x <span class="op">=</span> <span class="bu">len</span>(Y)</span>
<span id="cb155-32"><a href="#cb155-32" aria-hidden="true" tabindex="-1"></a>    X_ind <span class="op">=</span> [<span class="op">*</span><span class="bu">range</span>(time_steps <span class="op">*</span> rows_x)]</span>
<span id="cb155-33"><a href="#cb155-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">del</span> X_ind[::time_steps]  <span class="co"># if time_steps=10 remove every 10th entry</span></span>
<span id="cb155-34"><a href="#cb155-34" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> dat[X_ind]</span>
<span id="cb155-35"><a href="#cb155-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-36"><a href="#cb155-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PLOT</span></span>
<span id="cb155-37"><a href="#cb155-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> plot_data_partition:</span>
<span id="cb155-38"><a href="#cb155-38" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb155-39"><a href="#cb155-39" aria-hidden="true" tabindex="-1"></a>        plt.plot(Y_ind, Y, <span class="st">"o"</span>, X_ind, X, <span class="st">"-"</span>)</span>
<span id="cb155-40"><a href="#cb155-40" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb155-41"><a href="#cb155-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-42"><a href="#cb155-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RESHAPE INTO KERAS FORMAT</span></span>
<span id="cb155-43"><a href="#cb155-43" aria-hidden="true" tabindex="-1"></a>    X1 <span class="op">=</span> np.reshape(X, (rows_x, time_steps <span class="op">-</span> <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb155-44"><a href="#cb155-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print([*X_ind]); print(X1); print(X1.shape,Y.shape); exit()</span></span>
<span id="cb155-45"><a href="#cb155-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-46"><a href="#cb155-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X1, Y</span>
<span id="cb155-47"><a href="#cb155-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-48"><a href="#cb155-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-49"><a href="#cb155-49" aria-hidden="true" tabindex="-1"></a><span class="co"># PARTITION DATA</span></span>
<span id="cb155-50"><a href="#cb155-50" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">3</span>  <span class="co">#</span></span>
<span id="cb155-51"><a href="#cb155-51" aria-hidden="true" tabindex="-1"></a>testX, testY <span class="op">=</span> get_XY(test_data, p)</span>
<span id="cb155-52"><a href="#cb155-52" aria-hidden="true" tabindex="-1"></a>trainX, trainY <span class="op">=</span> get_XY(train_data, p)</span>
<span id="cb155-53"><a href="#cb155-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-54"><a href="#cb155-54" aria-hidden="true" tabindex="-1"></a> <span class="co">#USER PARAM</span></span>
<span id="cb155-55"><a href="#cb155-55" aria-hidden="true" tabindex="-1"></a>recurrent_hidden_units <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb155-56"><a href="#cb155-56" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb155-57"><a href="#cb155-57" aria-hidden="true" tabindex="-1"></a>f_batch <span class="op">=</span> <span class="fl">0.2</span>  <span class="co"># fraction used for batch size</span></span>
<span id="cb155-58"><a href="#cb155-58" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> <span class="st">"RMSprop"</span></span>
<span id="cb155-59"><a href="#cb155-59" aria-hidden="true" tabindex="-1"></a>validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb155-60"><a href="#cb155-60" aria-hidden="true" tabindex="-1"></a><span class="co"># trainY=trainY.reshape(trainY.shape[0],1)</span></span>
<span id="cb155-61"><a href="#cb155-61" aria-hidden="true" tabindex="-1"></a><span class="co"># testY=testY.reshape(testY.shape[0],1)</span></span>
<span id="cb155-62"><a href="#cb155-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Array Shape:"</span>, testX.shape, testY.shape)</span>
<span id="cb155-63"><a href="#cb155-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Array Shape:"</span>, trainX.shape, trainY.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Testing Array Shape: (1, 2, 1) (1,)
Training Array Shape: (7, 2, 1) (7,)</code></pre>
</div>
</div>
<p>After getting the corresponding train and test datasets, we can continue the process similarly.</p>
</section>
<section id="lstm-1" class="level2">
<h2 class="anchored" data-anchor-id="lstm-1">LSTM</h2>
<section id="no-regularization-3" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-3">No Regularization</h3>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb157-8"><a href="#cb157-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb157-9"><a href="#cb157-9" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb157-10"><a href="#cb157-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb157-11"><a href="#cb157-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb157-12"><a href="#cb157-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb157-13"><a href="#cb157-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-14"><a href="#cb157-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb157-15"><a href="#cb157-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb157-16"><a href="#cb157-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-17"><a href="#cb157-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb157-18"><a href="#cb157-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb157-19"><a href="#cb157-19" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb157-20"><a href="#cb157-20" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb157-21"><a href="#cb157-21" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb157-22"><a href="#cb157-22" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb157-23"><a href="#cb157-23" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb157-24"><a href="#cb157-24" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb157-25"><a href="#cb157-25" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb157-26"><a href="#cb157-26" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb157-27"><a href="#cb157-27" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb157-28"><a href="#cb157-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb157-29"><a href="#cb157-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-30"><a href="#cb157-30" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb157-31"><a href="#cb157-31" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb157-32"><a href="#cb157-32" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb157-33"><a href="#cb157-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-34"><a href="#cb157-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-35"><a href="#cb157-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb157-36"><a href="#cb157-36" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb157-37"><a href="#cb157-37" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb157-38"><a href="#cb157-38" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb157-39"><a href="#cb157-39" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb157-40"><a href="#cb157-40" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb157-41"><a href="#cb157-41" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb157-42"><a href="#cb157-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb157-43"><a href="#cb157-43" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb157-44"><a href="#cb157-44" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb157-45"><a href="#cb157-45" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb157-46"><a href="#cb157-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb157-47"><a href="#cb157-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-48"><a href="#cb157-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-49"><a href="#cb157-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb157-50"><a href="#cb157-50" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb157-51"><a href="#cb157-51" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb157-52"><a href="#cb157-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-53"><a href="#cb157-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb157-54"><a href="#cb157-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb157-55"><a href="#cb157-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-56"><a href="#cb157-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb157-57"><a href="#cb157-57" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb157-58"><a href="#cb157-58" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb157-59"><a href="#cb157-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-60"><a href="#cb157-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb157-61"><a href="#cb157-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb157-62"><a href="#cb157-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb157-63"><a href="#cb157-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-64"><a href="#cb157-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-65"><a href="#cb157-65" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_result(trainY, testY, train_predict, test_predict):</span>
<span id="cb157-66"><a href="#cb157-66" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">200</span>, facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>)  <span class="co"># Set higher DPI and background color for the figure</span></span>
<span id="cb157-67"><a href="#cb157-67" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb157-68"><a href="#cb157-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ORIGINAL DATA</span></span>
<span id="cb157-69"><a href="#cb157-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(X.shape, Y.shape)</span>
<span id="cb157-70"><a href="#cb157-70" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, Y, <span class="st">"o"</span>, label<span class="op">=</span><span class="st">"Target"</span>)</span>
<span id="cb157-71"><a href="#cb157-71" aria-hidden="true" tabindex="-1"></a>    plt.plot(X_ind, X, <span class="st">"."</span>, label<span class="op">=</span><span class="st">"Training points"</span>)</span>
<span id="cb157-72"><a href="#cb157-72" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, train_predict, <span class="st">"b."</span>, label<span class="op">=</span><span class="st">"Prediction"</span>)</span>
<span id="cb157-73"><a href="#cb157-73" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, train_predict, <span class="st">"r-"</span>)</span>
<span id="cb157-74"><a href="#cb157-74" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb157-75"><a href="#cb157-75" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Observation number after given time steps"</span>)</span>
<span id="cb157-76"><a href="#cb157-76" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">" Household Saving Scaled"</span>)</span>
<span id="cb157-77"><a href="#cb157-77" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Actual and Predicted Values"</span>)</span>
<span id="cb157-78"><a href="#cb157-78" aria-hidden="true" tabindex="-1"></a>    plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set grid color to white for better visibility</span></span>
<span id="cb157-79"><a href="#cb157-79" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb157-80"><a href="#cb157-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-81"><a href="#cb157-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-82"><a href="#cb157-82" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_6"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> lstm_2 (LSTM)               (None, 3)                 60        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_6 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 229ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-21-output-18.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00669 RMSE = 0.08181
Test MSE = 0.16973 RMSE = 0.41198
(14,) (7,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-21-output-24.png" class="img-fluid"></p>
</div>
</div>
<p>The RMSE for household saving analysis is about 0.41, we can see that the points predicted roughly the same from 1 to 15 time steps. Then it started to predict wrongly. Then, we will compare with regularization conducted to see if the result is overfitted.</p>
</section>
<section id="with-regularization-3" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-3">With Regularization</h3>
<div class="cell" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb180-6"><a href="#cb180-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(SimpleRNN(</span></span>
<span id="cb180-7"><a href="#cb180-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb180-8"><a href="#cb180-8" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb180-9"><a href="#cb180-9" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb180-10"><a href="#cb180-10" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb180-11"><a href="#cb180-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb180-12"><a href="#cb180-12" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb180-13"><a href="#cb180-13" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb180-14"><a href="#cb180-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb180-15"><a href="#cb180-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb180-16"><a href="#cb180-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-17"><a href="#cb180-17" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb180-18"><a href="#cb180-18" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb180-19"><a href="#cb180-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-20"><a href="#cb180-20" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb180-21"><a href="#cb180-21" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb180-22"><a href="#cb180-22" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb180-23"><a href="#cb180-23" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb180-24"><a href="#cb180-24" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb180-25"><a href="#cb180-25" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb180-26"><a href="#cb180-26" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb180-27"><a href="#cb180-27" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb180-28"><a href="#cb180-28" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb180-29"><a href="#cb180-29" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb180-30"><a href="#cb180-30" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb180-31"><a href="#cb180-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb180-32"><a href="#cb180-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-33"><a href="#cb180-33" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb180-34"><a href="#cb180-34" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb180-35"><a href="#cb180-35" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb180-36"><a href="#cb180-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb180-37"><a href="#cb180-37" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb180-38"><a href="#cb180-38" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb180-39"><a href="#cb180-39" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb180-40"><a href="#cb180-40" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb180-41"><a href="#cb180-41" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb180-42"><a href="#cb180-42" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb180-43"><a href="#cb180-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb180-44"><a href="#cb180-44" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb180-45"><a href="#cb180-45" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb180-46"><a href="#cb180-46" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb180-47"><a href="#cb180-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb180-48"><a href="#cb180-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb180-49"><a href="#cb180-49" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb180-50"><a href="#cb180-50" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb180-51"><a href="#cb180-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-52"><a href="#cb180-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb180-53"><a href="#cb180-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb180-54"><a href="#cb180-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-55"><a href="#cb180-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb180-56"><a href="#cb180-56" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb180-57"><a href="#cb180-57" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb180-58"><a href="#cb180-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-59"><a href="#cb180-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb180-60"><a href="#cb180-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb180-61"><a href="#cb180-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb180-62"><a href="#cb180-62" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_7"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> lstm_3 (LSTM)               (None, 3)                 60        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_7 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 232ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-22-output-18.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00511 RMSE = 0.07146
Test MSE = 0.14327 RMSE = 0.37851
(14,) (7,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-22-output-24.png" class="img-fluid"></p>
</div>
</div>
<p>From this result, we can see that the RMSE is actually lower. This means that in this case, the LSTM did not overfit for the household saving dataset. The possible reason could be the size of the dataset is relatively small which actually prevented the overfitting. However, I think that due to the small size of the dataset, the deep learning model is not as effective as the ARIMA models.</p>
</section>
</section>
<section id="rnn-1" class="level2">
<h2 class="anchored" data-anchor-id="rnn-1">RNN</h2>
<p>For RNN, we do the same process.</p>
<section id="no-regularization-4" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-4">No Regularization</h3>
<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb203-3"><a href="#cb203-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb203-4"><a href="#cb203-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb203-5"><a href="#cb203-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb203-6"><a href="#cb203-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb203-7"><a href="#cb203-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb203-8"><a href="#cb203-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb203-9"><a href="#cb203-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb203-10"><a href="#cb203-10" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb203-11"><a href="#cb203-11" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb203-12"><a href="#cb203-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb203-13"><a href="#cb203-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb203-14"><a href="#cb203-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-15"><a href="#cb203-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb203-16"><a href="#cb203-16" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb203-17"><a href="#cb203-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-18"><a href="#cb203-18" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb203-19"><a href="#cb203-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb203-20"><a href="#cb203-20" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb203-21"><a href="#cb203-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-22"><a href="#cb203-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-23"><a href="#cb203-23" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb203-24"><a href="#cb203-24" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb203-25"><a href="#cb203-25" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb203-26"><a href="#cb203-26" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb203-27"><a href="#cb203-27" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb203-28"><a href="#cb203-28" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb203-29"><a href="#cb203-29" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb203-30"><a href="#cb203-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb203-31"><a href="#cb203-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-32"><a href="#cb203-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-33"><a href="#cb203-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb203-34"><a href="#cb203-34" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb203-35"><a href="#cb203-35" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb203-36"><a href="#cb203-36" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb203-37"><a href="#cb203-37" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb203-38"><a href="#cb203-38" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb203-39"><a href="#cb203-39" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb203-40"><a href="#cb203-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb203-41"><a href="#cb203-41" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb203-42"><a href="#cb203-42" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb203-43"><a href="#cb203-43" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb203-44"><a href="#cb203-44" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb203-45"><a href="#cb203-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-46"><a href="#cb203-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-47"><a href="#cb203-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb203-48"><a href="#cb203-48" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb203-49"><a href="#cb203-49" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb203-50"><a href="#cb203-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-51"><a href="#cb203-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb203-52"><a href="#cb203-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb203-53"><a href="#cb203-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-54"><a href="#cb203-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb203-55"><a href="#cb203-55" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb203-56"><a href="#cb203-56" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb203-57"><a href="#cb203-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-58"><a href="#cb203-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb203-59"><a href="#cb203-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb203-60"><a href="#cb203-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb203-61"><a href="#cb203-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-62"><a href="#cb203-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-63"><a href="#cb203-63" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_8"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> simple_rnn_2 (SimpleRNN)    (None, 3)                 15        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_8 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-23-output-14.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 88ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00400 RMSE = 0.06322
Test MSE = 0.11479 RMSE = 0.33881
(14,) (7,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-23-output-20.png" class="img-fluid"></p>
</div>
</div>
<p>For RNN with no regularization, the result is higher compare to LSTM</p>
</section>
<section id="with-regularization-4" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-4">With Regularization</h3>
<div class="cell" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb222-2"><a href="#cb222-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb222-3"><a href="#cb222-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb222-4"><a href="#cb222-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb222-5"><a href="#cb222-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb222-6"><a href="#cb222-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb222-7"><a href="#cb222-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb222-8"><a href="#cb222-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb222-9"><a href="#cb222-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb222-10"><a href="#cb222-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb222-11"><a href="#cb222-11" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb222-12"><a href="#cb222-12" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb222-13"><a href="#cb222-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb222-14"><a href="#cb222-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb222-15"><a href="#cb222-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-16"><a href="#cb222-16" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb222-17"><a href="#cb222-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb222-18"><a href="#cb222-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-19"><a href="#cb222-19" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb222-20"><a href="#cb222-20" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb222-21"><a href="#cb222-21" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb222-22"><a href="#cb222-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-23"><a href="#cb222-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Check shapes again to verify</span></span>
<span id="cb222-24"><a href="#cb222-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb222-25"><a href="#cb222-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-26"><a href="#cb222-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb222-27"><a href="#cb222-27" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb222-28"><a href="#cb222-28" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb222-29"><a href="#cb222-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-30"><a href="#cb222-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-31"><a href="#cb222-31" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb222-32"><a href="#cb222-32" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb222-33"><a href="#cb222-33" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb222-34"><a href="#cb222-34" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb222-35"><a href="#cb222-35" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb222-36"><a href="#cb222-36" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb222-37"><a href="#cb222-37" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb222-38"><a href="#cb222-38" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb222-39"><a href="#cb222-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb222-40"><a href="#cb222-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-41"><a href="#cb222-41" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb222-42"><a href="#cb222-42" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb222-43"><a href="#cb222-43" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb222-44"><a href="#cb222-44" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb222-45"><a href="#cb222-45" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb222-46"><a href="#cb222-46" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb222-47"><a href="#cb222-47" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb222-48"><a href="#cb222-48" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb222-49"><a href="#cb222-49" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb222-50"><a href="#cb222-50" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb222-51"><a href="#cb222-51" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb222-52"><a href="#cb222-52" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb222-53"><a href="#cb222-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-54"><a href="#cb222-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb222-55"><a href="#cb222-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb222-56"><a href="#cb222-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb222-57"><a href="#cb222-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-58"><a href="#cb222-58" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_9"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> simple_rnn_3 (SimpleRNN)    (None, 3)                 15        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_9 (Dense)             (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-24-output-15.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.00400 RMSE = 0.06322
Test MSE = 0.11479 RMSE = 0.33881
(14,) (7,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-24-output-17.png" class="img-fluid"></p>
</div>
</div>
<p>Again, we can see that the RNN model with and without regularization yields similar results. I think the reason could be the same as LSTM, the dataset is relatively small such that there is no overfitting yet.</p>
</section>
</section>
<section id="gru-1" class="level2">
<h2 class="anchored" data-anchor-id="gru-1">GRU</h2>
<p>Same steps with GRU</p>
<section id="no-regularization-5" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-5">No Regularization</h3>
<div class="cell" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb238"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb238-2"><a href="#cb238-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb238-3"><a href="#cb238-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb238-4"><a href="#cb238-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb238-5"><a href="#cb238-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb238-6"><a href="#cb238-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb238-7"><a href="#cb238-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb238-8"><a href="#cb238-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb238-9"><a href="#cb238-9" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb238-10"><a href="#cb238-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb238-11"><a href="#cb238-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb238-12"><a href="#cb238-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb238-13"><a href="#cb238-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-14"><a href="#cb238-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb238-15"><a href="#cb238-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb238-16"><a href="#cb238-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-17"><a href="#cb238-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb238-18"><a href="#cb238-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb238-19"><a href="#cb238-19" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb238-20"><a href="#cb238-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-21"><a href="#cb238-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-22"><a href="#cb238-22" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb238-23"><a href="#cb238-23" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb238-24"><a href="#cb238-24" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb238-25"><a href="#cb238-25" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb238-26"><a href="#cb238-26" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb238-27"><a href="#cb238-27" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb238-28"><a href="#cb238-28" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb238-29"><a href="#cb238-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb238-30"><a href="#cb238-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-31"><a href="#cb238-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-32"><a href="#cb238-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-33"><a href="#cb238-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb238-34"><a href="#cb238-34" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb238-35"><a href="#cb238-35" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb238-36"><a href="#cb238-36" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb238-37"><a href="#cb238-37" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb238-38"><a href="#cb238-38" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb238-39"><a href="#cb238-39" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb238-40"><a href="#cb238-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb238-41"><a href="#cb238-41" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb238-42"><a href="#cb238-42" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb238-43"><a href="#cb238-43" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb238-44"><a href="#cb238-44" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb238-45"><a href="#cb238-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-46"><a href="#cb238-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-47"><a href="#cb238-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb238-48"><a href="#cb238-48" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb238-49"><a href="#cb238-49" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb238-50"><a href="#cb238-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-51"><a href="#cb238-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb238-52"><a href="#cb238-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb238-53"><a href="#cb238-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-54"><a href="#cb238-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb238-55"><a href="#cb238-55" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb238-56"><a href="#cb238-56" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb238-57"><a href="#cb238-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-58"><a href="#cb238-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb238-59"><a href="#cb238-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb238-60"><a href="#cb238-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb238-61"><a href="#cb238-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-62"><a href="#cb238-62" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_10"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> gru_2 (GRU)                 (None, 3)                 54        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_10 (Dense)            (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-25-output-14.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 223ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 17ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (1,)
Train MSE = 0.00211 RMSE = 0.04596
Test MSE = 0.08885 RMSE = 0.29807
(14,) (7,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-25-output-20.png" class="img-fluid"></p>
</div>
</div>
<p>We can see that overall, GRU has the lowest RMSE for no regularization.</p>
</section>
<section id="with-regularization-5" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-5">With Regularization</h3>
<div class="cell" data-execution_count="25">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb257"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb257-2"><a href="#cb257-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb257-3"><a href="#cb257-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb257-4"><a href="#cb257-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb257-5"><a href="#cb257-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb257-6"><a href="#cb257-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb257-7"><a href="#cb257-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb257-8"><a href="#cb257-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb257-9"><a href="#cb257-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb257-10"><a href="#cb257-10" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb257-11"><a href="#cb257-11" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb257-12"><a href="#cb257-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb257-13"><a href="#cb257-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb257-14"><a href="#cb257-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-15"><a href="#cb257-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb257-16"><a href="#cb257-16" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb257-17"><a href="#cb257-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-18"><a href="#cb257-18" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb257-19"><a href="#cb257-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb257-20"><a href="#cb257-20" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb257-21"><a href="#cb257-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-22"><a href="#cb257-22" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb257-23"><a href="#cb257-23" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb257-24"><a href="#cb257-24" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb257-25"><a href="#cb257-25" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb257-26"><a href="#cb257-26" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb257-27"><a href="#cb257-27" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb257-28"><a href="#cb257-28" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb257-29"><a href="#cb257-29" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb257-30"><a href="#cb257-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb257-31"><a href="#cb257-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-32"><a href="#cb257-32" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb257-33"><a href="#cb257-33" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb257-34"><a href="#cb257-34" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb257-35"><a href="#cb257-35" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb257-36"><a href="#cb257-36" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb257-37"><a href="#cb257-37" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb257-38"><a href="#cb257-38" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb257-39"><a href="#cb257-39" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb257-40"><a href="#cb257-40" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb257-41"><a href="#cb257-41" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb257-42"><a href="#cb257-42" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb257-43"><a href="#cb257-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb257-44"><a href="#cb257-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-45"><a href="#cb257-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb257-46"><a href="#cb257-46" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()  <span class="co"># Ensures a 1D array output</span></span>
<span id="cb257-47"><a href="#cb257-47" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()</span>
<span id="cb257-48"><a href="#cb257-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-49"><a href="#cb257-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb257-50"><a href="#cb257-50" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb257-51"><a href="#cb257-51" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb257-52"><a href="#cb257-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-53"><a href="#cb257-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb257-54"><a href="#cb257-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb257-55"><a href="#cb257-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb257-56"><a href="#cb257-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-57"><a href="#cb257-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-58"><a href="#cb257-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the function with your data</span></span>
<span id="cb257-59"><a href="#cb257-59" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_11"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> gru_3 (GRU)                 (None, 3)                 54        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_11 (Dense)            (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 58 (232.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-26-output-14.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 213ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.00192 RMSE = 0.04377
Test MSE = 0.08302 RMSE = 0.28813
(14,) (7,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-26-output-20.png" class="img-fluid"></p>
</div>
</div>
<p>Overll, the GRU model performs the best for household savings analysis.</p>
</section>
</section>
</section>
<section id="discussions-i" class="level1">
<h1>Discussions I</h1>
<section id="for-median-sale-price" class="level2">
<h2 class="anchored" data-anchor-id="for-median-sale-price">For Median Sale Price</h2>
<section id="deep-learning-methods-comparison" class="level3">
<h3 class="anchored" data-anchor-id="deep-learning-methods-comparison">Deep learning methods comparison</h3>
<p>In my case, the LSTM performed the best with lowest RMSE. In addition, the prediction plot with the actual data also shows that the LSTM is better among the three methods for my median sale price analysis.</p>
</section>
<section id="regulariztaion-effect-1" class="level3">
<h3 class="anchored" data-anchor-id="regulariztaion-effect-1">Regulariztaion Effect</h3>
<p>The result suggests that the model is able to capture the underlying trend in the data quite well. Regularization comparsion proved that the model did not overfit too much. Also, the smoothness of the prediction curve indicates that the L2 regularization has effectively penalized overly complex models that could have fit the noise in the training data.</p>
</section>
<section id="how-far-can-the-deep-learning-methods-predict" class="level3">
<h3 class="anchored" data-anchor-id="how-far-can-the-deep-learning-methods-predict">How Far can the deep learning methods predict</h3>
<p>In my analsyis for median sale price, overall, the LSTM made relatively better predictions. The predictions started going wrong after 150 given steps. Therefore, I think that for deep learning methods, it can predict around half of year correctly.</p>
</section>
<section id="comparison-to-armaarima" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-armaarima">Comparison to ARMA/ARIMA</h3>
<p>For median sale price analsyis, the LSTM model performs the best with relatively low RMSE. Compare to the ARIMA model in ARIMA section, the model used for median sale price was ARIMA(1,1,1). And the RMSE is higher than the deep learning methods. Therefore, in my case, I believe that the LSTM model provides better predictions. The possible reason I think is that the deep learning models can evaluate the dataset by capturing more features. Especially that the dataset has an obvious upwarding trend. The deep learning model can interpret the trend better with each epoch trained therefore we can get better results. However, the overfitting could exist therefore regularization must be included to avoid overfitting.</p>
</section>
</section>
<section id="for-household-saving" class="level2">
<h2 class="anchored" data-anchor-id="for-household-saving">For Household Saving</h2>
<p>We can see that comparing to Median Sale Price analysis, the analysis for household saving is not as effective. The reason is because of the dataset size different. With less datapoints, the models for household saving did not perform as well as they should be. We also can not determine the prediction power of models on this dataset. Therefore, in my case for household saving analysis, the deep learning methods are not as effective as the ARIMA models.</p>
<section id="deep-learning-methods-comparison-1" class="level3">
<h3 class="anchored" data-anchor-id="deep-learning-methods-comparison-1">Deep learning methods comparison</h3>
<p>In my case, the GRU performed the best with lowest RMSE. In addition, the prediction plot with the actual data also shows that the GRU is better among the three methods for my household saving analysis.</p>
</section>
<section id="regularization-effect" class="level3">
<h3 class="anchored" data-anchor-id="regularization-effect">Regularization Effect</h3>
<p>In this case, the regularization actually did not change too much for the results. Regularization comparsion proved that the model did not overfit. Again, it could be due to the small size of the dataset.</p>
</section>
<section id="how-far-can-the-deep-learning-methods-predict-1" class="level3">
<h3 class="anchored" data-anchor-id="how-far-can-the-deep-learning-methods-predict-1">How Far can the deep learning methods predict</h3>
<p>The RMSE for household saving analysis is about 0.41, we can see that the points predicted roughly the same from 1 to 15 time steps. Then it started to predict wrongly. Again, it could be due to the small size of this dataset. It is hard to tell the exact prediction power. Overall, I do not think that deep learning methods are effective for household saving analysis.</p>
</section>
<section id="comparison-to-armaarima-1" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-armaarima-1">Comparison to ARMA/ARIMA</h3>
<p>For household saving analsyis, I think that due to the small size of the dataset, the deep learning model is not as effective as the ARIMA models. ARIMA model can capture better for this dataset by considering different patterns such as stationary and season. In my case, I believe that the ARIMA model performs better. For deep learning methods, although the results have smaller RMSEs, I still think that the analysis could be improved by using larger datasets.</p>
</section>
</section>
</section>
<section id="gdp-deflator-deep-learning-analysis-compare-with-var-model" class="level1">
<h1>GDP Deflator Deep Learning Analysis (Compare With VAR Model)</h1>
<p>In my ARIMAX and VAR section, I made analysis on two VAR models. Both of the VAR models contain the GDP deflator variable since it is a crucial factor in representing the economic as a whole. It can provide insights in determine the effects and impacts on personal income and saving, further impling the housing prices and affordability. Therefore, in here, I want to gain insights and make comparison by using deep learning methods.</p>
<section id="data-preparation-2" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation-2">Data Preparation</h2>
<p>In this code part, I also included datasets for mutivariable analysis in later section</p>
<div class="cell" data-execution_count="26">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"../Dataset/project/A191RI1Q225SBEA.csv"</span>)</span>
<span id="cb276-2"><a href="#cb276-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">"../Dataset/project/MSPUS.csv"</span>)</span>
<span id="cb276-3"><a href="#cb276-3" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd.read_csv(<span class="st">"../Dataset/project/PSAVERT.csv"</span>)</span>
<span id="cb276-4"><a href="#cb276-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-5"><a href="#cb276-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.rename(columns<span class="op">=</span>{<span class="st">"A191RI1Q225SBEA"</span>: <span class="st">"y"</span>}) <span class="co"># The objective</span></span>
<span id="cb276-6"><a href="#cb276-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">"DATE"</span>, <span class="st">"y"</span>]]</span>
<span id="cb276-7"><a href="#cb276-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(df[<span class="st">"y"</span>].values.astype(<span class="st">"float32"</span>)).reshape(df.shape[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb276-8"><a href="#cb276-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-9"><a href="#cb276-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Train and Test Split &amp; Normalization</span></span>
<span id="cb276-10"><a href="#cb276-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-11"><a href="#cb276-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_test_split(data, split_percent<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb276-12"><a href="#cb276-12" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb276-13"><a href="#cb276-13" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> scaler.fit_transform(data).flatten()</span>
<span id="cb276-14"><a href="#cb276-14" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb276-15"><a href="#cb276-15" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb276-16"><a href="#cb276-16" aria-hidden="true" tabindex="-1"></a>    split <span class="op">=</span> <span class="bu">int</span>(n <span class="op">*</span> split_percent)</span>
<span id="cb276-17"><a href="#cb276-17" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> data[<span class="bu">range</span>(split)]</span>
<span id="cb276-18"><a href="#cb276-18" aria-hidden="true" tabindex="-1"></a>    test_data <span class="op">=</span> data[split:]</span>
<span id="cb276-19"><a href="#cb276-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_data, test_data, data</span>
<span id="cb276-20"><a href="#cb276-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-21"><a href="#cb276-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-22"><a href="#cb276-22" aria-hidden="true" tabindex="-1"></a>train_data, test_data, data <span class="op">=</span> train_test_split(X)</span>
<span id="cb276-23"><a href="#cb276-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-24"><a href="#cb276-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train shape:"</span>, train_data.shape)</span>
<span id="cb276-25"><a href="#cb276-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test shape:"</span>, test_data.shape)</span>
<span id="cb276-26"><a href="#cb276-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-27"><a href="#cb276-27" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">100</span>)  <span class="co"># Set the size and DPI of the figure</span></span>
<span id="cb276-28"><a href="#cb276-28" aria-hidden="true" tabindex="-1"></a>fig.patch.set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the background color for the outer figure</span></span>
<span id="cb276-29"><a href="#cb276-29" aria-hidden="true" tabindex="-1"></a>ax.set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the background color for the axes</span></span>
<span id="cb276-30"><a href="#cb276-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-31"><a href="#cb276-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the training data</span></span>
<span id="cb276-32"><a href="#cb276-32" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(train_data)), train_data, <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Training Data"</span>)</span>
<span id="cb276-33"><a href="#cb276-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-34"><a href="#cb276-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the test data</span></span>
<span id="cb276-35"><a href="#cb276-35" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="bu">len</span>(train_data), <span class="bu">len</span>(train_data) <span class="op">+</span> <span class="bu">len</span>(test_data)), test_data, <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Test Data"</span>)</span>
<span id="cb276-36"><a href="#cb276-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-37"><a href="#cb276-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Set labels and title</span></span>
<span id="cb276-38"><a href="#cb276-38" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Time (days)"</span>, ylabel<span class="op">=</span><span class="st">"Median GDP Deflator Scaled"</span>, title<span class="op">=</span><span class="st">"Median GDP Deflator Over Time"</span>)</span>
<span id="cb276-39"><a href="#cb276-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-40"><a href="#cb276-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Add grid with white color for better visibility on the gray background</span></span>
<span id="cb276-41"><a href="#cb276-41" aria-hidden="true" tabindex="-1"></a>ax.grid(color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb276-42"><a href="#cb276-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-43"><a href="#cb276-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Add legend to the plot</span></span>
<span id="cb276-44"><a href="#cb276-44" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb276-45"><a href="#cb276-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-46"><a href="#cb276-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb276-47"><a href="#cb276-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb276-48"><a href="#cb276-48" aria-hidden="true" tabindex="-1"></a><span class="co"># PREPARE THE INPUT X AND TARGET Y</span></span>
<span id="cb276-49"><a href="#cb276-49" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_XY(dat, time_steps, plot_data_partition<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb276-50"><a href="#cb276-50" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> X_ind, X, Y_ind, Y  <span class="co"># use for plotting later</span></span>
<span id="cb276-51"><a href="#cb276-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-52"><a href="#cb276-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># INDICES OF TARGET ARRAY</span></span>
<span id="cb276-53"><a href="#cb276-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Y_ind [  12   24   36   48 ..]; print(np.arange(1,12,1)); exit()</span></span>
<span id="cb276-54"><a href="#cb276-54" aria-hidden="true" tabindex="-1"></a>    Y_ind <span class="op">=</span> np.arange(time_steps, <span class="bu">len</span>(dat), time_steps)</span>
<span id="cb276-55"><a href="#cb276-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(Y_ind); exit()</span></span>
<span id="cb276-56"><a href="#cb276-56" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> dat[Y_ind]</span>
<span id="cb276-57"><a href="#cb276-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-58"><a href="#cb276-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PREPARE X</span></span>
<span id="cb276-59"><a href="#cb276-59" aria-hidden="true" tabindex="-1"></a>    rows_x <span class="op">=</span> <span class="bu">len</span>(Y)</span>
<span id="cb276-60"><a href="#cb276-60" aria-hidden="true" tabindex="-1"></a>    X_ind <span class="op">=</span> [<span class="op">*</span><span class="bu">range</span>(time_steps <span class="op">*</span> rows_x)]</span>
<span id="cb276-61"><a href="#cb276-61" aria-hidden="true" tabindex="-1"></a>    <span class="kw">del</span> X_ind[::time_steps]  <span class="co"># if time_steps=10 remove every 10th entry</span></span>
<span id="cb276-62"><a href="#cb276-62" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> dat[X_ind]</span>
<span id="cb276-63"><a href="#cb276-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-64"><a href="#cb276-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PLOT</span></span>
<span id="cb276-65"><a href="#cb276-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> plot_data_partition:</span>
<span id="cb276-66"><a href="#cb276-66" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb276-67"><a href="#cb276-67" aria-hidden="true" tabindex="-1"></a>        plt.plot(Y_ind, Y, <span class="st">"o"</span>, X_ind, X, <span class="st">"-"</span>)</span>
<span id="cb276-68"><a href="#cb276-68" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb276-69"><a href="#cb276-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-70"><a href="#cb276-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RESHAPE INTO KERAS FORMAT</span></span>
<span id="cb276-71"><a href="#cb276-71" aria-hidden="true" tabindex="-1"></a>    X1 <span class="op">=</span> np.reshape(X, (rows_x, time_steps <span class="op">-</span> <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb276-72"><a href="#cb276-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print([*X_ind]); print(X1); print(X1.shape,Y.shape); exit()</span></span>
<span id="cb276-73"><a href="#cb276-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-74"><a href="#cb276-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X1, Y</span>
<span id="cb276-75"><a href="#cb276-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-76"><a href="#cb276-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-77"><a href="#cb276-77" aria-hidden="true" tabindex="-1"></a><span class="co"># PARTITION DATA</span></span>
<span id="cb276-78"><a href="#cb276-78" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">30</span>  <span class="co">#</span></span>
<span id="cb276-79"><a href="#cb276-79" aria-hidden="true" tabindex="-1"></a>testX, testY <span class="op">=</span> get_XY(test_data, p)</span>
<span id="cb276-80"><a href="#cb276-80" aria-hidden="true" tabindex="-1"></a>trainX, trainY <span class="op">=</span> get_XY(train_data, p)</span>
<span id="cb276-81"><a href="#cb276-81" aria-hidden="true" tabindex="-1"></a> <span class="co">#USER PARAM</span></span>
<span id="cb276-82"><a href="#cb276-82" aria-hidden="true" tabindex="-1"></a>recurrent_hidden_units <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb276-83"><a href="#cb276-83" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb276-84"><a href="#cb276-84" aria-hidden="true" tabindex="-1"></a>f_batch <span class="op">=</span> <span class="fl">0.2</span>  <span class="co"># fraction used for batch size</span></span>
<span id="cb276-85"><a href="#cb276-85" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> <span class="st">"RMSprop"</span></span>
<span id="cb276-86"><a href="#cb276-86" aria-hidden="true" tabindex="-1"></a>validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb276-87"><a href="#cb276-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-88"><a href="#cb276-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Array Shape:"</span>, testX.shape, testY.shape)</span>
<span id="cb276-89"><a href="#cb276-89" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Array Shape:"</span>, trainX.shape, trainY.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>train shape: (244,)
test shape: (61,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-27-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing Array Shape: (2, 29, 1) (2,)
Training Array Shape: (8, 29, 1) (8,)</code></pre>
</div>
</div>
</section>
<section id="lstm-2" class="level2">
<h2 class="anchored" data-anchor-id="lstm-2">LSTM</h2>
<p>Similar Process as the above sections</p>
<section id="no-regularization-6" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-6">No Regularization</h3>
<div class="cell" data-execution_count="27">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb279"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb279-2"><a href="#cb279-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-3"><a href="#cb279-3" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb279-4"><a href="#cb279-4" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb279-5"><a href="#cb279-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb279-6"><a href="#cb279-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb279-7"><a href="#cb279-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb279-8"><a href="#cb279-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb279-9"><a href="#cb279-9" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb279-10"><a href="#cb279-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb279-11"><a href="#cb279-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb279-12"><a href="#cb279-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb279-13"><a href="#cb279-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-14"><a href="#cb279-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb279-15"><a href="#cb279-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb279-16"><a href="#cb279-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-17"><a href="#cb279-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb279-18"><a href="#cb279-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb279-19"><a href="#cb279-19" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb279-20"><a href="#cb279-20" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb279-21"><a href="#cb279-21" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb279-22"><a href="#cb279-22" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb279-23"><a href="#cb279-23" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb279-24"><a href="#cb279-24" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb279-25"><a href="#cb279-25" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb279-26"><a href="#cb279-26" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb279-27"><a href="#cb279-27" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb279-28"><a href="#cb279-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb279-29"><a href="#cb279-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-30"><a href="#cb279-30" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb279-31"><a href="#cb279-31" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb279-32"><a href="#cb279-32" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb279-33"><a href="#cb279-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-34"><a href="#cb279-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-35"><a href="#cb279-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb279-36"><a href="#cb279-36" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb279-37"><a href="#cb279-37" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb279-38"><a href="#cb279-38" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb279-39"><a href="#cb279-39" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb279-40"><a href="#cb279-40" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb279-41"><a href="#cb279-41" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb279-42"><a href="#cb279-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb279-43"><a href="#cb279-43" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb279-44"><a href="#cb279-44" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb279-45"><a href="#cb279-45" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb279-46"><a href="#cb279-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb279-47"><a href="#cb279-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-48"><a href="#cb279-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-49"><a href="#cb279-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb279-50"><a href="#cb279-50" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb279-51"><a href="#cb279-51" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb279-52"><a href="#cb279-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-53"><a href="#cb279-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb279-54"><a href="#cb279-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb279-55"><a href="#cb279-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-56"><a href="#cb279-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb279-57"><a href="#cb279-57" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb279-58"><a href="#cb279-58" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb279-59"><a href="#cb279-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-60"><a href="#cb279-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb279-61"><a href="#cb279-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb279-62"><a href="#cb279-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb279-63"><a href="#cb279-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-64"><a href="#cb279-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-65"><a href="#cb279-65" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_result(trainY, testY, train_predict, test_predict):</span>
<span id="cb279-66"><a href="#cb279-66" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">200</span>, facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>)  <span class="co"># Set higher DPI and background color for the figure</span></span>
<span id="cb279-67"><a href="#cb279-67" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb279-68"><a href="#cb279-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ORIGINAL DATA</span></span>
<span id="cb279-69"><a href="#cb279-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(X.shape, Y.shape)</span>
<span id="cb279-70"><a href="#cb279-70" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, Y, <span class="st">"o"</span>, label<span class="op">=</span><span class="st">"Target"</span>)</span>
<span id="cb279-71"><a href="#cb279-71" aria-hidden="true" tabindex="-1"></a>    plt.plot(X_ind, X, <span class="st">"."</span>, label<span class="op">=</span><span class="st">"Training points"</span>)</span>
<span id="cb279-72"><a href="#cb279-72" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, train_predict, <span class="st">"b."</span>, label<span class="op">=</span><span class="st">"Prediction"</span>)</span>
<span id="cb279-73"><a href="#cb279-73" aria-hidden="true" tabindex="-1"></a>    plt.plot(Y_ind, train_predict, <span class="st">"r-"</span>)</span>
<span id="cb279-74"><a href="#cb279-74" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb279-75"><a href="#cb279-75" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Observation number after given time steps"</span>)</span>
<span id="cb279-76"><a href="#cb279-76" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Median GDP Deflator Scaled"</span>)</span>
<span id="cb279-77"><a href="#cb279-77" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Actual and Predicted Values"</span>)</span>
<span id="cb279-78"><a href="#cb279-78" aria-hidden="true" tabindex="-1"></a>    plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set grid color to white for better visibility</span></span>
<span id="cb279-79"><a href="#cb279-79" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb279-80"><a href="#cb279-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-81"><a href="#cb279-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-82"><a href="#cb279-82" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_12"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> lstm_4 (LSTM)               (None, 3)                 60        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_12 (Dense)            (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 231ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-28-output-18.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (2,)
Train MSE = 0.00087 RMSE = 0.02954
Test MSE = 0.02076 RMSE = 0.14407
(232,) (8,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-28-output-24.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="with-regularization-6" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-6">With Regularization</h3>
<div class="cell" data-execution_count="28">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb302"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb302-2"><a href="#cb302-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb302-3"><a href="#cb302-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb302-4"><a href="#cb302-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb302-5"><a href="#cb302-5" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb302-6"><a href="#cb302-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(SimpleRNN(</span></span>
<span id="cb302-7"><a href="#cb302-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb302-8"><a href="#cb302-8" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb302-9"><a href="#cb302-9" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb302-10"><a href="#cb302-10" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb302-11"><a href="#cb302-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb302-12"><a href="#cb302-12" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb302-13"><a href="#cb302-13" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb302-14"><a href="#cb302-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb302-15"><a href="#cb302-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb302-16"><a href="#cb302-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-17"><a href="#cb302-17" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb302-18"><a href="#cb302-18" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb302-19"><a href="#cb302-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-20"><a href="#cb302-20" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb302-21"><a href="#cb302-21" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb302-22"><a href="#cb302-22" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb302-23"><a href="#cb302-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-24"><a href="#cb302-24" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb302-25"><a href="#cb302-25" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb302-26"><a href="#cb302-26" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb302-27"><a href="#cb302-27" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb302-28"><a href="#cb302-28" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb302-29"><a href="#cb302-29" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb302-30"><a href="#cb302-30" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb302-31"><a href="#cb302-31" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb302-32"><a href="#cb302-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb302-33"><a href="#cb302-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-34"><a href="#cb302-34" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb302-35"><a href="#cb302-35" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb302-36"><a href="#cb302-36" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb302-37"><a href="#cb302-37" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb302-38"><a href="#cb302-38" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb302-39"><a href="#cb302-39" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb302-40"><a href="#cb302-40" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb302-41"><a href="#cb302-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb302-42"><a href="#cb302-42" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb302-43"><a href="#cb302-43" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb302-44"><a href="#cb302-44" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb302-45"><a href="#cb302-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb302-46"><a href="#cb302-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb302-47"><a href="#cb302-47" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb302-48"><a href="#cb302-48" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb302-49"><a href="#cb302-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-50"><a href="#cb302-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb302-51"><a href="#cb302-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb302-52"><a href="#cb302-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-53"><a href="#cb302-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb302-54"><a href="#cb302-54" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb302-55"><a href="#cb302-55" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb302-56"><a href="#cb302-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-57"><a href="#cb302-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb302-58"><a href="#cb302-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb302-59"><a href="#cb302-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb302-60"><a href="#cb302-60" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_13"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> lstm_5 (LSTM)               (None, 3)                 60        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_13 (Dense)            (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 64 (256.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-29-output-14.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 231ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (2,)
Train MSE = 0.00082 RMSE = 0.02872
Test MSE = 0.01277 RMSE = 0.11302
(232,) (8,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-29-output-20.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="rnn-2" class="level2">
<h2 class="anchored" data-anchor-id="rnn-2">RNN</h2>
<section id="no-regularization-7" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-7">No Regularization</h3>
<div class="cell" data-execution_count="29">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb321"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb321-1"><a href="#cb321-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb321-2"><a href="#cb321-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb321-3"><a href="#cb321-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb321-4"><a href="#cb321-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb321-5"><a href="#cb321-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb321-6"><a href="#cb321-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb321-7"><a href="#cb321-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb321-8"><a href="#cb321-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb321-9"><a href="#cb321-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb321-10"><a href="#cb321-10" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb321-11"><a href="#cb321-11" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb321-12"><a href="#cb321-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb321-13"><a href="#cb321-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb321-14"><a href="#cb321-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-15"><a href="#cb321-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb321-16"><a href="#cb321-16" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb321-17"><a href="#cb321-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-18"><a href="#cb321-18" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb321-19"><a href="#cb321-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb321-20"><a href="#cb321-20" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb321-21"><a href="#cb321-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-22"><a href="#cb321-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-23"><a href="#cb321-23" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb321-24"><a href="#cb321-24" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb321-25"><a href="#cb321-25" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb321-26"><a href="#cb321-26" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb321-27"><a href="#cb321-27" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb321-28"><a href="#cb321-28" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb321-29"><a href="#cb321-29" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb321-30"><a href="#cb321-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb321-31"><a href="#cb321-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-32"><a href="#cb321-32" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb321-33"><a href="#cb321-33" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb321-34"><a href="#cb321-34" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb321-35"><a href="#cb321-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-36"><a href="#cb321-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-37"><a href="#cb321-37" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb321-38"><a href="#cb321-38" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb321-39"><a href="#cb321-39" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb321-40"><a href="#cb321-40" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb321-41"><a href="#cb321-41" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb321-42"><a href="#cb321-42" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb321-43"><a href="#cb321-43" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb321-44"><a href="#cb321-44" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb321-45"><a href="#cb321-45" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb321-46"><a href="#cb321-46" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb321-47"><a href="#cb321-47" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb321-48"><a href="#cb321-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb321-49"><a href="#cb321-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-50"><a href="#cb321-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-51"><a href="#cb321-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb321-52"><a href="#cb321-52" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb321-53"><a href="#cb321-53" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb321-54"><a href="#cb321-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-55"><a href="#cb321-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-56"><a href="#cb321-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-57"><a href="#cb321-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb321-58"><a href="#cb321-58" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb321-59"><a href="#cb321-59" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb321-60"><a href="#cb321-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-61"><a href="#cb321-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb321-62"><a href="#cb321-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb321-63"><a href="#cb321-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb321-64"><a href="#cb321-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-65"><a href="#cb321-65" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_14"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> simple_rnn_4 (SimpleRNN)    (None, 3)                 15        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_14 (Dense)            (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 89ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-30-output-18.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.00226 RMSE = 0.04756
Test MSE = 0.03703 RMSE = 0.19243
(232,) (8,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-30-output-24.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="with-regularization-7" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-7">With Regularization</h3>
<div class="cell" data-execution_count="30">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb344"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb344-2"><a href="#cb344-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb344-3"><a href="#cb344-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb344-4"><a href="#cb344-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb344-5"><a href="#cb344-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb344-6"><a href="#cb344-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb344-7"><a href="#cb344-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb344-8"><a href="#cb344-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb344-9"><a href="#cb344-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb344-10"><a href="#cb344-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb344-11"><a href="#cb344-11" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb344-12"><a href="#cb344-12" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb344-13"><a href="#cb344-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb344-14"><a href="#cb344-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb344-15"><a href="#cb344-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-16"><a href="#cb344-16" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb344-17"><a href="#cb344-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb344-18"><a href="#cb344-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-19"><a href="#cb344-19" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb344-20"><a href="#cb344-20" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb344-21"><a href="#cb344-21" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb344-22"><a href="#cb344-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb344-23"><a href="#cb344-23" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb344-24"><a href="#cb344-24" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Ensures a 1D array output</span></span>
<span id="cb344-25"><a href="#cb344-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-26"><a href="#cb344-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Check shapes again to verify</span></span>
<span id="cb344-27"><a href="#cb344-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb344-28"><a href="#cb344-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-29"><a href="#cb344-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb344-30"><a href="#cb344-30" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb344-31"><a href="#cb344-31" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb344-32"><a href="#cb344-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-33"><a href="#cb344-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-34"><a href="#cb344-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (train_rmse<span class="op">**</span><span class="fl">2.0</span>, train_rmse))</span>
<span id="cb344-35"><a href="#cb344-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (test_rmse<span class="op">**</span><span class="fl">2.0</span>, test_rmse))</span>
<span id="cb344-36"><a href="#cb344-36" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_15"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> simple_rnn_5 (SimpleRNN)    (None, 3)                 15        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_15 (Dense)            (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 19 (76.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 91ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (2,)
Train MSE = 0.76253 RMSE = 0.87323
Test MSE = 0.25970 RMSE = 0.50961
(232,) (8,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-31-output-19.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="gru-2" class="level2">
<h2 class="anchored" data-anchor-id="gru-2">GRU</h2>
<section id="no-regularization-8" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-8">No Regularization</h3>
<div class="cell" data-execution_count="31">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb363"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb363-1"><a href="#cb363-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb363-2"><a href="#cb363-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb363-3"><a href="#cb363-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb363-4"><a href="#cb363-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb363-5"><a href="#cb363-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb363-6"><a href="#cb363-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb363-7"><a href="#cb363-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb363-8"><a href="#cb363-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb363-9"><a href="#cb363-9" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb363-10"><a href="#cb363-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb363-11"><a href="#cb363-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb363-12"><a href="#cb363-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb363-13"><a href="#cb363-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-14"><a href="#cb363-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb363-15"><a href="#cb363-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb363-16"><a href="#cb363-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-17"><a href="#cb363-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb363-18"><a href="#cb363-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb363-19"><a href="#cb363-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-20"><a href="#cb363-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb363-21"><a href="#cb363-21" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb363-22"><a href="#cb363-22" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb363-23"><a href="#cb363-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-24"><a href="#cb363-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-25"><a href="#cb363-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb363-26"><a href="#cb363-26" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb363-27"><a href="#cb363-27" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb363-28"><a href="#cb363-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-29"><a href="#cb363-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb363-30"><a href="#cb363-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb363-31"><a href="#cb363-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb363-32"><a href="#cb363-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-33"><a href="#cb363-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the function with your data</span></span>
<span id="cb363-34"><a href="#cb363-34" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 220ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.01187 RMSE = 0.10895
Test MSE = 0.00009 RMSE = 0.00930
(232,) (8,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-32-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="with-regularization-8" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-8">With Regularization</h3>
<div class="cell" data-execution_count="32">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb369"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb369-1"><a href="#cb369-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb369-2"><a href="#cb369-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb369-3"><a href="#cb369-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb369-4"><a href="#cb369-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb369-5"><a href="#cb369-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb369-6"><a href="#cb369-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb369-7"><a href="#cb369-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb369-8"><a href="#cb369-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb369-9"><a href="#cb369-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># recurrent_dropout=0.8,</span></span>
<span id="cb369-10"><a href="#cb369-10" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb369-11"><a href="#cb369-11" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb369-12"><a href="#cb369-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb369-13"><a href="#cb369-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb369-14"><a href="#cb369-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-15"><a href="#cb369-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb369-16"><a href="#cb369-16" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb369-17"><a href="#cb369-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-18"><a href="#cb369-18" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb369-19"><a href="#cb369-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb369-20"><a href="#cb369-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb369-21"><a href="#cb369-21" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()  <span class="co"># Ensures a 1D array output</span></span>
<span id="cb369-22"><a href="#cb369-22" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()</span>
<span id="cb369-23"><a href="#cb369-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-24"><a href="#cb369-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb369-25"><a href="#cb369-25" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb369-26"><a href="#cb369-26" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb369-27"><a href="#cb369-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-28"><a href="#cb369-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb369-29"><a href="#cb369-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb369-30"><a href="#cb369-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb369-31"><a href="#cb369-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-32"><a href="#cb369-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-33"><a href="#cb369-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the function with your data</span></span>
<span id="cb369-34"><a href="#cb369-34" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 221ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.31959 RMSE = 0.56533
Test MSE = 0.22049 RMSE = 0.46957
(232,) (8,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-33-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
</section>
<section id="discussions-ii" class="level1">
<h1>Discussions II</h1>
<section id="for-gdp-deflator" class="level2">
<h2 class="anchored" data-anchor-id="for-gdp-deflator">For GDP Deflator</h2>
<section id="deep-learning-methods-comparison-2" class="level3">
<h3 class="anchored" data-anchor-id="deep-learning-methods-comparison-2">Deep learning methods comparison</h3>
<p>In my case, the LSTM performed the best with lowest RMSE. In addition, the prediction plot with the actual data also shows that the LSTM is better among the three methods for GDP Deflator analysis.</p>
</section>
<section id="regularization-effect-1" class="level3">
<h3 class="anchored" data-anchor-id="regularization-effect-1">Regularization Effect</h3>
<p>For LSTM, the regularization actually did not give in too much difference in the results. However, for RNN and GRU, the result suggests that the model is overfitting. The RMSE for both model is different when appling regularization. Therefore, regularization help these two models for not overfitting.</p>
</section>
<section id="how-far-can-the-deep-learning-methods-predict-2" class="level3">
<h3 class="anchored" data-anchor-id="how-far-can-the-deep-learning-methods-predict-2">How Far can the deep learning methods predict</h3>
<p>In my analsyis for gdp deflator, overall, the LSTM made relatively better predictions. The predictions aligned the actual points for all time steps. This imply that the LSTM model has very effective prediction power for the gdp deflator. Therefore, I think it can predict the values correctly given the trend and pattern for pretty long time in to the future if there is no sudden change or other external impacts.</p>
</section>
<section id="comparison-to-var-model" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-var-model">Comparison to VAR Model</h3>
<p>The LSTM model performs the best with relatively low RMSE. Compare to the VAR model in VAR section, the model used for GDP Deflator was Var(13). For Var(13) The RMSE for cross validation is also relatively small. However, in my case, I still believe that the LSTM model provides better predictions. The possible reason I think is that the deep learning models can evaluate the dataset by capturing more features with deeper analysis. The deep learning model can interpret the trend better with each epoch trained therefore we can get better results. In addition, for LSTM the overfitting did not exist. However, for other model, the RNN and GRU are not as effective as the VAR model.</p>
</section>
</section>
</section>
<section id="multivariable-deep-learning-optional" class="level1">
<h1>Multivariable Deep Learning (OPTIONAL)</h1>
<section id="data-preparation-gdp-deflator-personal-saving-rate-median-sale-price" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation-gdp-deflator-personal-saving-rate-median-sale-price">Data Preparation: GDP Deflator, Personal Saving Rate, Median Sale Price</h2>
<div class="cell" data-execution_count="33">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb375"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb375-1"><a href="#cb375-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'DATE'</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">'DATE'</span>])</span>
<span id="cb375-2"><a href="#cb375-2" aria-hidden="true" tabindex="-1"></a>df2[<span class="st">'DATE'</span>] <span class="op">=</span> pd.to_datetime(df2[<span class="st">'DATE'</span>])</span>
<span id="cb375-3"><a href="#cb375-3" aria-hidden="true" tabindex="-1"></a>df3[<span class="st">'DATE'</span>] <span class="op">=</span> pd.to_datetime(df3[<span class="st">'DATE'</span>])</span>
<span id="cb375-4"><a href="#cb375-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-5"><a href="#cb375-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-6"><a href="#cb375-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter data based on the date range</span></span>
<span id="cb375-7"><a href="#cb375-7" aria-hidden="true" tabindex="-1"></a>start_date <span class="op">=</span> <span class="st">'1963-01-01'</span></span>
<span id="cb375-8"><a href="#cb375-8" aria-hidden="true" tabindex="-1"></a>end_date <span class="op">=</span> <span class="st">'2023-04-01'</span></span>
<span id="cb375-9"><a href="#cb375-9" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> df[(df[<span class="st">'DATE'</span>] <span class="op">&gt;=</span> start_date) <span class="op">&amp;</span> (df[<span class="st">'DATE'</span>] <span class="op">&lt;=</span> end_date)]</span>
<span id="cb375-10"><a href="#cb375-10" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df2[(df2[<span class="st">'DATE'</span>] <span class="op">&gt;=</span> start_date) <span class="op">&amp;</span> (df2[<span class="st">'DATE'</span>] <span class="op">&lt;=</span> end_date)]</span>
<span id="cb375-11"><a href="#cb375-11" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> df3[(df3[<span class="st">'DATE'</span>] <span class="op">&gt;=</span> start_date) <span class="op">&amp;</span> (df3[<span class="st">'DATE'</span>] <span class="op">&lt;=</span> end_date)]</span>
<span id="cb375-12"><a href="#cb375-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-13"><a href="#cb375-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the dataframes on the 'DATE' column</span></span>
<span id="cb375-14"><a href="#cb375-14" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.merge(df1, df2, on<span class="op">=</span><span class="st">'DATE'</span>, how<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb375-15"><a href="#cb375-15" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.merge(df, df3, on<span class="op">=</span><span class="st">'DATE'</span>, how<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb375-16"><a href="#cb375-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-17"><a href="#cb375-17" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb375-18"><a href="#cb375-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-19"><a href="#cb375-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-20"><a href="#cb375-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-21"><a href="#cb375-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-22"><a href="#cb375-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Train/Test Split &amp; Normalization</span></span>
<span id="cb375-23"><a href="#cb375-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_test_split_normalize(data, split_percent<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb375-24"><a href="#cb375-24" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb375-25"><a href="#cb375-25" aria-hidden="true" tabindex="-1"></a>    data_scaled <span class="op">=</span> scaler.fit_transform(data)</span>
<span id="cb375-26"><a href="#cb375-26" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data_scaled)</span>
<span id="cb375-27"><a href="#cb375-27" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb375-28"><a href="#cb375-28" aria-hidden="true" tabindex="-1"></a>    split <span class="op">=</span> <span class="bu">int</span>(n <span class="op">*</span> split_percent)</span>
<span id="cb375-29"><a href="#cb375-29" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> data_scaled[:split, :]</span>
<span id="cb375-30"><a href="#cb375-30" aria-hidden="true" tabindex="-1"></a>    test_data <span class="op">=</span> data_scaled[split:, :]</span>
<span id="cb375-31"><a href="#cb375-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_data, test_data, data_scaled</span>
<span id="cb375-32"><a href="#cb375-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-33"><a href="#cb375-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming the data from the CSVs are now in df</span></span>
<span id="cb375-34"><a href="#cb375-34" aria-hidden="true" tabindex="-1"></a>train_data, test_data, _ <span class="op">=</span> train_test_split_normalize(df.iloc[:, <span class="dv">1</span>:].values)  <span class="co"># Exclude 'DATE' column</span></span>
<span id="cb375-35"><a href="#cb375-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-36"><a href="#cb375-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare input X and target Y for multivariate time-series</span></span>
<span id="cb375-37"><a href="#cb375-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_XY_multivariate(dat, time_steps, num_features):</span>
<span id="cb375-38"><a href="#cb375-38" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> [], []</span>
<span id="cb375-39"><a href="#cb375-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(dat) <span class="op">-</span> time_steps):</span>
<span id="cb375-40"><a href="#cb375-40" aria-hidden="true" tabindex="-1"></a>        X.append(dat[i:(i <span class="op">+</span> time_steps), :])</span>
<span id="cb375-41"><a href="#cb375-41" aria-hidden="true" tabindex="-1"></a>        Y.append(dat[i <span class="op">+</span> time_steps, <span class="dv">0</span>])  <span class="co"># Assuming target is the first feature</span></span>
<span id="cb375-42"><a href="#cb375-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(X), np.array(Y)</span>
<span id="cb375-43"><a href="#cb375-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-44"><a href="#cb375-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Partition Data</span></span>
<span id="cb375-45"><a href="#cb375-45" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">30</span>  <span class="co"># Time steps</span></span>
<span id="cb375-46"><a href="#cb375-46" aria-hidden="true" tabindex="-1"></a>num_features <span class="op">=</span> df.shape[<span class="dv">1</span>] <span class="op">-</span> <span class="dv">1</span>  <span class="co"># Number of features, excluding 'DATE' column</span></span>
<span id="cb375-47"><a href="#cb375-47" aria-hidden="true" tabindex="-1"></a>trainX, trainY <span class="op">=</span> get_XY_multivariate(train_data, p, num_features)</span>
<span id="cb375-48"><a href="#cb375-48" aria-hidden="true" tabindex="-1"></a>testX, testY <span class="op">=</span> get_XY_multivariate(test_data, p, num_features)</span>
<span id="cb375-49"><a href="#cb375-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-50"><a href="#cb375-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Display shapes</span></span>
<span id="cb375-51"><a href="#cb375-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Array Shape:"</span>, testX.shape, testY.shape)</span>
<span id="cb375-52"><a href="#cb375-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Array Shape:"</span>, trainX.shape, trainY.shape)</span>
<span id="cb375-53"><a href="#cb375-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-54"><a href="#cb375-54" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">100</span>)  <span class="co"># Set the size and DPI of the figure</span></span>
<span id="cb375-55"><a href="#cb375-55" aria-hidden="true" tabindex="-1"></a>fig.patch.set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the background color for the outer figure</span></span>
<span id="cb375-56"><a href="#cb375-56" aria-hidden="true" tabindex="-1"></a>ax.set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the background color for the axes</span></span>
<span id="cb375-57"><a href="#cb375-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-58"><a href="#cb375-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the training data for each time-series</span></span>
<span id="cb375-59"><a href="#cb375-59" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(train_data)), train_data[:, <span class="dv">0</span>], <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Training Data - TS1"</span>)</span>
<span id="cb375-60"><a href="#cb375-60" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(train_data)), train_data[:, <span class="dv">1</span>], <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Training Data - TS2"</span>)</span>
<span id="cb375-61"><a href="#cb375-61" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(train_data)), train_data[:, <span class="dv">2</span>], <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Training Data - TS3"</span>)</span>
<span id="cb375-62"><a href="#cb375-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-63"><a href="#cb375-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the test data for each time-series</span></span>
<span id="cb375-64"><a href="#cb375-64" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="bu">len</span>(train_data), <span class="bu">len</span>(train_data) <span class="op">+</span> <span class="bu">len</span>(test_data)), test_data[:, <span class="dv">0</span>], <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Test Data - TS1"</span>)</span>
<span id="cb375-65"><a href="#cb375-65" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="bu">len</span>(train_data), <span class="bu">len</span>(train_data) <span class="op">+</span> <span class="bu">len</span>(test_data)), test_data[:, <span class="dv">1</span>], <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Test Data - TS2"</span>)</span>
<span id="cb375-66"><a href="#cb375-66" aria-hidden="true" tabindex="-1"></a>ax.plot(<span class="bu">range</span>(<span class="bu">len</span>(train_data), <span class="bu">len</span>(train_data) <span class="op">+</span> <span class="bu">len</span>(test_data)), test_data[:, <span class="dv">2</span>], <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Test Data - TS3"</span>)</span>
<span id="cb375-67"><a href="#cb375-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-68"><a href="#cb375-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Set labels and title</span></span>
<span id="cb375-69"><a href="#cb375-69" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Time (days)"</span>, ylabel<span class="op">=</span><span class="st">"Values Scaled"</span>, title<span class="op">=</span><span class="st">"Multivariate Time Series Over Time"</span>)</span>
<span id="cb375-70"><a href="#cb375-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-71"><a href="#cb375-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Add grid with white color for better visibility on the gray background</span></span>
<span id="cb375-72"><a href="#cb375-72" aria-hidden="true" tabindex="-1"></a>ax.grid(color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb375-73"><a href="#cb375-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-74"><a href="#cb375-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Add legend to the plot</span></span>
<span id="cb375-75"><a href="#cb375-75" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb375-76"><a href="#cb375-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-77"><a href="#cb375-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb375-78"><a href="#cb375-78" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Testing Array Shape: (19, 30, 3) (19,)
Training Array Shape: (163, 30, 3) (163,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-34-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="array-preparations-for-modeling" class="level2">
<h2 class="anchored" data-anchor-id="array-preparations-for-modeling">Array Preparations for Modeling</h2>
<div class="cell" data-execution_count="34">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb377"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb377-1"><a href="#cb377-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_XY_multivariate(dat, time_steps, num_features, plot_data_partition<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb377-2"><a href="#cb377-2" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> [], []</span>
<span id="cb377-3"><a href="#cb377-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb377-4"><a href="#cb377-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare X and Y</span></span>
<span id="cb377-5"><a href="#cb377-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(dat) <span class="op">-</span> time_steps):</span>
<span id="cb377-6"><a href="#cb377-6" aria-hidden="true" tabindex="-1"></a>        X.append(dat[i:i <span class="op">+</span> time_steps, :])</span>
<span id="cb377-7"><a href="#cb377-7" aria-hidden="true" tabindex="-1"></a>        Y.append(dat[i <span class="op">+</span> time_steps, <span class="dv">0</span>])  <span class="co"># Assuming target is the first feature at the next time step</span></span>
<span id="cb377-8"><a href="#cb377-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb377-9"><a href="#cb377-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to numpy arrays</span></span>
<span id="cb377-10"><a href="#cb377-10" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.array(X)</span>
<span id="cb377-11"><a href="#cb377-11" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.array(Y)</span>
<span id="cb377-12"><a href="#cb377-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb377-13"><a href="#cb377-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> plot_data_partition:</span>
<span id="cb377-14"><a href="#cb377-14" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb377-15"><a href="#cb377-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_features):</span>
<span id="cb377-16"><a href="#cb377-16" aria-hidden="true" tabindex="-1"></a>            plt.plot(Y_ind, dat[Y_ind, i], <span class="st">"o"</span>, label<span class="op">=</span><span class="ss">f"Feature </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Targets"</span>)</span>
<span id="cb377-17"><a href="#cb377-17" aria-hidden="true" tabindex="-1"></a>            plt.plot(<span class="bu">range</span>(<span class="bu">len</span>(dat)), dat[:, i], <span class="st">"-"</span>, label<span class="op">=</span><span class="ss">f"Feature </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Data"</span>)</span>
<span id="cb377-18"><a href="#cb377-18" aria-hidden="true" tabindex="-1"></a>        plt.legend()</span>
<span id="cb377-19"><a href="#cb377-19" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb377-20"><a href="#cb377-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb377-21"><a href="#cb377-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, Y</span>
<span id="cb377-22"><a href="#cb377-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb377-23"><a href="#cb377-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Use this function to partition data again</span></span>
<span id="cb377-24"><a href="#cb377-24" aria-hidden="true" tabindex="-1"></a>testX, testY <span class="op">=</span> get_XY_multivariate(test_data, p, num_features)</span>
<span id="cb377-25"><a href="#cb377-25" aria-hidden="true" tabindex="-1"></a>trainX, trainY <span class="op">=</span> get_XY_multivariate(train_data, p, num_features)</span>
<span id="cb377-26"><a href="#cb377-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb377-27"><a href="#cb377-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Print shapes</span></span>
<span id="cb377-28"><a href="#cb377-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Array Shape:"</span>, testX.shape, testY.shape)</span>
<span id="cb377-29"><a href="#cb377-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Array Shape:"</span>, trainX.shape, trainY.shape)</span>
<span id="cb377-30"><a href="#cb377-30" aria-hidden="true" tabindex="-1"></a> <span class="co">#USER PARAM</span></span>
<span id="cb377-31"><a href="#cb377-31" aria-hidden="true" tabindex="-1"></a>recurrent_hidden_units <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb377-32"><a href="#cb377-32" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb377-33"><a href="#cb377-33" aria-hidden="true" tabindex="-1"></a>f_batch <span class="op">=</span> <span class="fl">0.2</span>  <span class="co"># fraction used for batch size</span></span>
<span id="cb377-34"><a href="#cb377-34" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> <span class="st">"RMSprop"</span></span>
<span id="cb377-35"><a href="#cb377-35" aria-hidden="true" tabindex="-1"></a>validation_split <span class="op">=</span> <span class="fl">0.2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Testing Array Shape: (19, 30, 3) (19,)
Training Array Shape: (163, 30, 3) (163,)</code></pre>
</div>
</div>
</section>
<section id="lstm-3" class="level2">
<h2 class="anchored" data-anchor-id="lstm-3">LSTM</h2>
<section id="no-regularization-9" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-9">No Regularization</h3>
<div class="cell" data-execution_count="35">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb379"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb379-2"><a href="#cb379-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-3"><a href="#cb379-3" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb379-4"><a href="#cb379-4" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb379-5"><a href="#cb379-5" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb379-6"><a href="#cb379-6" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb379-7"><a href="#cb379-7" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb379-8"><a href="#cb379-8" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb379-9"><a href="#cb379-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb379-10"><a href="#cb379-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb379-11"><a href="#cb379-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-12"><a href="#cb379-12" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb379-13"><a href="#cb379-13" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb379-14"><a href="#cb379-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-15"><a href="#cb379-15" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb379-16"><a href="#cb379-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb379-17"><a href="#cb379-17" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb379-18"><a href="#cb379-18" aria-hidden="true" tabindex="-1"></a><span class="co"># TRAIN MODEL</span></span>
<span id="cb379-19"><a href="#cb379-19" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb379-20"><a href="#cb379-20" aria-hidden="true" tabindex="-1"></a>    trainX,</span>
<span id="cb379-21"><a href="#cb379-21" aria-hidden="true" tabindex="-1"></a>    trainY,</span>
<span id="cb379-22"><a href="#cb379-22" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb379-23"><a href="#cb379-23" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">int</span>(f_batch <span class="op">*</span> trainX.shape[<span class="dv">0</span>]),</span>
<span id="cb379-24"><a href="#cb379-24" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span>validation_split,</span>
<span id="cb379-25"><a href="#cb379-25" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb379-26"><a href="#cb379-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb379-27"><a href="#cb379-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-28"><a href="#cb379-28" aria-hidden="true" tabindex="-1"></a><span class="co"># MAKE PREDICTIONS</span></span>
<span id="cb379-29"><a href="#cb379-29" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).squeeze()</span>
<span id="cb379-30"><a href="#cb379-30" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).squeeze()</span>
<span id="cb379-31"><a href="#cb379-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-32"><a href="#cb379-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-33"><a href="#cb379-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb379-34"><a href="#cb379-34" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb379-35"><a href="#cb379-35" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb379-36"><a href="#cb379-36" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb379-37"><a href="#cb379-37" aria-hidden="true" tabindex="-1"></a>plt.figure(facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>, dpi<span class="op">=</span><span class="dv">200</span>)  <span class="co"># Set the background color and DPI</span></span>
<span id="cb379-38"><a href="#cb379-38" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, loss, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb379-39"><a href="#cb379-39" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, val_loss, <span class="st">'c'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb379-40"><a href="#cb379-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb379-41"><a href="#cb379-41" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb379-42"><a href="#cb379-42" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)  <span class="co"># Set the axes background color</span></span>
<span id="cb379-43"><a href="#cb379-43" aria-hidden="true" tabindex="-1"></a>plt.grid(color<span class="op">=</span><span class="st">'white'</span>)  <span class="co"># Set the grid color to white for better visibility on the gray background</span></span>
<span id="cb379-44"><a href="#cb379-44" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb379-45"><a href="#cb379-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-46"><a href="#cb379-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-47"><a href="#cb379-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb379-48"><a href="#cb379-48" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb379-49"><a href="#cb379-49" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb379-50"><a href="#cb379-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-51"><a href="#cb379-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-52"><a href="#cb379-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb379-53"><a href="#cb379-53" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb379-54"><a href="#cb379-54" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb379-55"><a href="#cb379-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-56"><a href="#cb379-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb379-57"><a href="#cb379-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb379-58"><a href="#cb379-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb379-59"><a href="#cb379-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-60"><a href="#cb379-60" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_result(trainY, testY, train_predict, test_predict):</span>
<span id="cb379-61"><a href="#cb379-61" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">200</span>, facecolor<span class="op">=</span><span class="st">'#E0E0E0'</span>)</span>
<span id="cb379-62"><a href="#cb379-62" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_facecolor(<span class="st">'#E0E0E0'</span>)</span>
<span id="cb379-63"><a href="#cb379-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-64"><a href="#cb379-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create time indices for training and testing data</span></span>
<span id="cb379-65"><a href="#cb379-65" aria-hidden="true" tabindex="-1"></a>    time_indices_train <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(trainY))</span>
<span id="cb379-66"><a href="#cb379-66" aria-hidden="true" tabindex="-1"></a>    time_indices_test <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(testY))</span>
<span id="cb379-67"><a href="#cb379-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-68"><a href="#cb379-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plotting actual values vs. predictions for training data</span></span>
<span id="cb379-69"><a href="#cb379-69" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb379-70"><a href="#cb379-70" aria-hidden="true" tabindex="-1"></a>    plt.plot(time_indices_train, trainY, <span class="st">"o"</span>, label<span class="op">=</span><span class="st">"Actual Train"</span>)</span>
<span id="cb379-71"><a href="#cb379-71" aria-hidden="true" tabindex="-1"></a>    plt.plot(time_indices_train, train_predict, <span class="st">"r-"</span>, label<span class="op">=</span><span class="st">"Predicted Train"</span>)</span>
<span id="cb379-72"><a href="#cb379-72" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Training: Actual vs Predicted"</span>)</span>
<span id="cb379-73"><a href="#cb379-73" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Time Steps"</span>)</span>
<span id="cb379-74"><a href="#cb379-74" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Scaled Value"</span>)</span>
<span id="cb379-75"><a href="#cb379-75" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb379-76"><a href="#cb379-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-77"><a href="#cb379-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plotting actual values vs. predictions for testing data</span></span>
<span id="cb379-78"><a href="#cb379-78" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb379-79"><a href="#cb379-79" aria-hidden="true" tabindex="-1"></a>    plt.plot(time_indices_test, testY, <span class="st">"o"</span>, label<span class="op">=</span><span class="st">"Actual Test"</span>)</span>
<span id="cb379-80"><a href="#cb379-80" aria-hidden="true" tabindex="-1"></a>    plt.plot(time_indices_test, test_predict, <span class="st">"r-"</span>, label<span class="op">=</span><span class="st">"Predicted Test"</span>)</span>
<span id="cb379-81"><a href="#cb379-81" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Testing: Actual vs Predicted"</span>)</span>
<span id="cb379-82"><a href="#cb379-82" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Time Steps"</span>)</span>
<span id="cb379-83"><a href="#cb379-83" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Scaled Value"</span>)</span>
<span id="cb379-84"><a href="#cb379-84" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb379-85"><a href="#cb379-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-86"><a href="#cb379-86" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb379-87"><a href="#cb379-87" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb379-88"><a href="#cb379-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-89"><a href="#cb379-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Calling the function</span></span>
<span id="cb379-90"><a href="#cb379-90" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_18"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> lstm_6 (LSTM)               (None, 3)                 84        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_18 (Dense)            (None, 1)                 4         </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 88 (352.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 88 (352.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0 (0.00 Byte)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/6 [====&gt;.........................] - ETA: 1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 1ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-36-output-18.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/6 [====&gt;.........................] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 2ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.00729 RMSE = 0.08540
Test MSE = 0.11003 RMSE = 0.33170</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-36-output-24.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="with-regularization-9" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-9">With Regularization</h3>
<div class="cell" data-execution_count="36">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb402"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb402-1"><a href="#cb402-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb402-2"><a href="#cb402-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-3"><a href="#cb402-3" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb402-4"><a href="#cb402-4" aria-hidden="true" tabindex="-1"></a>    LSTM(</span>
<span id="cb402-5"><a href="#cb402-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb402-6"><a href="#cb402-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb402-7"><a href="#cb402-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb402-8"><a href="#cb402-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb402-9"><a href="#cb402-9" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb402-10"><a href="#cb402-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb402-11"><a href="#cb402-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb402-12"><a href="#cb402-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb402-13"><a href="#cb402-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-14"><a href="#cb402-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb402-15"><a href="#cb402-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb402-16"><a href="#cb402-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-17"><a href="#cb402-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb402-18"><a href="#cb402-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb402-19"><a href="#cb402-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-20"><a href="#cb402-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-21"><a href="#cb402-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-22"><a href="#cb402-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb402-23"><a href="#cb402-23" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb402-24"><a href="#cb402-24" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb402-25"><a href="#cb402-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-26"><a href="#cb402-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-27"><a href="#cb402-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb402-28"><a href="#cb402-28" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb402-29"><a href="#cb402-29" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb402-30"><a href="#cb402-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-31"><a href="#cb402-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb402-32"><a href="#cb402-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb402-33"><a href="#cb402-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb402-34"><a href="#cb402-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-35"><a href="#cb402-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-36"><a href="#cb402-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-37"><a href="#cb402-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Calling the function</span></span>
<span id="cb402-38"><a href="#cb402-38" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/6 [====&gt;.........................] - ETA: 1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 1ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.15387 RMSE = 0.39226
Test MSE = 0.07804 RMSE = 0.27936</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-37-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="rnn-3" class="level2">
<h2 class="anchored" data-anchor-id="rnn-3">RNN</h2>
<div class="cell" data-execution_count="37">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb408"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb408-1"><a href="#cb408-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb408-2"><a href="#cb408-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb408-3"><a href="#cb408-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb408-4"><a href="#cb408-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb408-5"><a href="#cb408-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb408-6"><a href="#cb408-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb408-7"><a href="#cb408-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb408-8"><a href="#cb408-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb408-9"><a href="#cb408-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb408-10"><a href="#cb408-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb408-11"><a href="#cb408-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb408-12"><a href="#cb408-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb408-13"><a href="#cb408-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb408-14"><a href="#cb408-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb408-15"><a href="#cb408-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb408-16"><a href="#cb408-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb408-17"><a href="#cb408-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb408-18"><a href="#cb408-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb408-19"><a href="#cb408-19" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb408-20"><a href="#cb408-20" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb408-21"><a href="#cb408-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb408-22"><a href="#cb408-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb408-23"><a href="#cb408-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb408-24"><a href="#cb408-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb408-25"><a href="#cb408-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb408-26"><a href="#cb408-26" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb408-27"><a href="#cb408-27" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb408-28"><a href="#cb408-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb408-29"><a href="#cb408-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb408-30"><a href="#cb408-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb408-31"><a href="#cb408-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb408-32"><a href="#cb408-32" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/6 [====&gt;.........................] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 2ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 16ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (19,)
Train MSE = 0.25535 RMSE = 0.50532
Test MSE = 0.17439 RMSE = 0.41760</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-38-output-6.png" class="img-fluid"></p>
</div>
</div>
<section id="with-regularization-10" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-10">With Regularization</h3>
<div class="cell" data-execution_count="38">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb414"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb414-1"><a href="#cb414-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb414-2"><a href="#cb414-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb414-3"><a href="#cb414-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb414-4"><a href="#cb414-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb414-5"><a href="#cb414-5" aria-hidden="true" tabindex="-1"></a>    SimpleRNN(</span>
<span id="cb414-6"><a href="#cb414-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># model.add(GRU(</span></span>
<span id="cb414-7"><a href="#cb414-7" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb414-8"><a href="#cb414-8" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb414-9"><a href="#cb414-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb414-10"><a href="#cb414-10" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb414-11"><a href="#cb414-11" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb414-12"><a href="#cb414-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb414-13"><a href="#cb414-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb414-14"><a href="#cb414-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb414-15"><a href="#cb414-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb414-16"><a href="#cb414-16" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb414-17"><a href="#cb414-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb414-18"><a href="#cb414-18" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb414-19"><a href="#cb414-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb414-20"><a href="#cb414-20" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb414-21"><a href="#cb414-21" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb414-22"><a href="#cb414-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb414-23"><a href="#cb414-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, print the shapes to verify</span></span>
<span id="cb414-24"><a href="#cb414-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of test_predict after flattening:"</span>, test_predict.shape)</span>
<span id="cb414-25"><a href="#cb414-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb414-26"><a href="#cb414-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb414-27"><a href="#cb414-27" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb414-28"><a href="#cb414-28" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb414-29"><a href="#cb414-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb414-30"><a href="#cb414-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb414-31"><a href="#cb414-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb414-32"><a href="#cb414-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb414-33"><a href="#cb414-33" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/6 [====&gt;.........................] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 2ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 14ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of test_predict after flattening: (19,)
Train MSE = 0.06878 RMSE = 0.26225
Test MSE = 0.11937 RMSE = 0.34551</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-39-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="gru-3" class="level2">
<h2 class="anchored" data-anchor-id="gru-3">GRU</h2>
<section id="no-regularization-10" class="level3">
<h3 class="anchored" data-anchor-id="no-regularization-10">No Regularization</h3>
<div class="cell" data-execution_count="39">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb420"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb420-1"><a href="#cb420-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb420-2"><a href="#cb420-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb420-3"><a href="#cb420-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb420-4"><a href="#cb420-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb420-5"><a href="#cb420-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb420-6"><a href="#cb420-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb420-7"><a href="#cb420-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb420-8"><a href="#cb420-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb420-9"><a href="#cb420-9" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb420-10"><a href="#cb420-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb420-11"><a href="#cb420-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb420-12"><a href="#cb420-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb420-13"><a href="#cb420-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb420-14"><a href="#cb420-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb420-15"><a href="#cb420-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb420-16"><a href="#cb420-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb420-17"><a href="#cb420-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb420-18"><a href="#cb420-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb420-19"><a href="#cb420-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb420-20"><a href="#cb420-20" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb420-21"><a href="#cb420-21" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb420-22"><a href="#cb420-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb420-23"><a href="#cb420-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb420-24"><a href="#cb420-24" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb420-25"><a href="#cb420-25" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb420-26"><a href="#cb420-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb420-27"><a href="#cb420-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb420-28"><a href="#cb420-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb420-29"><a href="#cb420-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb420-30"><a href="#cb420-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Calling the function</span></span>
<span id="cb420-31"><a href="#cb420-31" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/6 [====&gt;.........................] - ETA: 1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 2ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 15ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.16875 RMSE = 0.41079
Test MSE = 0.16586 RMSE = 0.40726</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-40-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="with-regularization-11" class="level3">
<h3 class="anchored" data-anchor-id="with-regularization-11">With Regularization</h3>
<div class="cell" data-execution_count="40">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb426"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb426-1"><a href="#cb426-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CREATE MODEL</span></span>
<span id="cb426-2"><a href="#cb426-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb426-3"><a href="#cb426-3" aria-hidden="true" tabindex="-1"></a><span class="co"># COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU</span></span>
<span id="cb426-4"><a href="#cb426-4" aria-hidden="true" tabindex="-1"></a>model.add(</span>
<span id="cb426-5"><a href="#cb426-5" aria-hidden="true" tabindex="-1"></a>    GRU(</span>
<span id="cb426-6"><a href="#cb426-6" aria-hidden="true" tabindex="-1"></a>        recurrent_hidden_units,</span>
<span id="cb426-7"><a href="#cb426-7" aria-hidden="true" tabindex="-1"></a>        return_sequences<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb426-8"><a href="#cb426-8" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(trainX.shape[<span class="dv">1</span>], trainX.shape[<span class="dv">2</span>]),</span>
<span id="cb426-9"><a href="#cb426-9" aria-hidden="true" tabindex="-1"></a>        recurrent_regularizer<span class="op">=</span>regularizers.L2(<span class="fl">1e-2</span>),</span>
<span id="cb426-10"><a href="#cb426-10" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"tanh"</span>,</span>
<span id="cb426-11"><a href="#cb426-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb426-12"><a href="#cb426-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb426-13"><a href="#cb426-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-14"><a href="#cb426-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR</span></span>
<span id="cb426-15"><a href="#cb426-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">"linear"</span>))</span>
<span id="cb426-16"><a href="#cb426-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-17"><a href="#cb426-17" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPILE THE MODEL</span></span>
<span id="cb426-18"><a href="#cb426-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"MeanSquaredError"</span>, optimizer<span class="op">=</span>optimizer)</span>
<span id="cb426-19"><a href="#cb426-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb426-20"><a href="#cb426-20" aria-hidden="true" tabindex="-1"></a>train_predict <span class="op">=</span> model.predict(trainX).flatten()</span>
<span id="cb426-21"><a href="#cb426-21" aria-hidden="true" tabindex="-1"></a>test_predict <span class="op">=</span> model.predict(testX).flatten()  <span class="co"># Flattening to ensure it is a 1D array</span></span>
<span id="cb426-22"><a href="#cb426-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-23"><a href="#cb426-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb426-24"><a href="#cb426-24" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> np.sqrt(mean_squared_error(trainY, train_predict))</span>
<span id="cb426-25"><a href="#cb426-25" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(testY, test_predict))</span>
<span id="cb426-26"><a href="#cb426-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-27"><a href="#cb426-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE and RMSE</span></span>
<span id="cb426-28"><a href="#cb426-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((trainY <span class="op">-</span> train_predict) <span class="op">**</span> <span class="fl">2.0</span>), train_rmse))</span>
<span id="cb426-29"><a href="#cb426-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test MSE = </span><span class="sc">%.5f</span><span class="st"> RMSE = </span><span class="sc">%.5f</span><span class="st">"</span> <span class="op">%</span> (np.mean((testY <span class="op">-</span> test_predict) <span class="op">**</span> <span class="fl">2.0</span>), test_rmse))</span>
<span id="cb426-30"><a href="#cb426-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Calling the function</span></span>
<span id="cb426-31"><a href="#cb426-31" aria-hidden="true" tabindex="-1"></a>plot_result(trainY, testY, train_predict, test_predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/6 [====&gt;.........................] - ETA: 1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 2ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - ETA: 0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 17ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Train MSE = 0.15670 RMSE = 0.39585
Test MSE = 0.48956 RMSE = 0.69968</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TS_files/figure-html/cell-41-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
</section>
<section id="discussion-iii" class="level1">
<h1>Discussion III</h1>
<section id="overall-effect-of-including-regularization" class="level2">
<h2 class="anchored" data-anchor-id="overall-effect-of-including-regularization">Overall Effect of Including Regularization:</h2>
<p>Regularization is used to prevent overfitting by penalizing large weights in the model. In my case, the LSTM performs the best. However, there are difference for using regularization. The results show that there are some overfitting if we do not use regularization. Therefore, in my case, the regularization is effective in preventing overfitting</p>
</section>
<section id="how-far-can-the-deep-learning-model-predict" class="level2">
<h2 class="anchored" data-anchor-id="how-far-can-the-deep-learning-model-predict">How far can the Deep Learning Model predict</h2>
<p>It seems that the deep learning model did not preform too well for these mutivariables. The points are off with the actual values. However, the patterns and trends are captured. Therefore, I would say that for multivariable analysis, the deep learning methods might not be the most optimal choice. By adding additional dataset, the ability of predicting is not improved.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>