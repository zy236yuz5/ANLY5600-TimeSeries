{"title":"Financial Time Series Models (ARCH/GARCH)","markdown":{"yaml":{"title":"Financial Time Series Models (ARCH/GARCH)","navbar":{"left":["about.qmd","Introduction.qmd","DataSources.qmd","DataVis.qmd","EDA.qmd","ARModels.qmd","ASV.qmd","SAF.qmd","GARCH.qmd","TS.qmd","conclusion.qmd","dv.qmd"]},"format":{"html":{"theme":"sandstone","css":"./styles/layout.css","code-fold":true,"toc":true}}},"headingText":"Income Stock Analaysis","containsRefs":false,"markdown":"\n\nIn this section, the goal is to determine if the GARCH model can help the dataset better. The basic work flow of this section is to compare different models within ARIMA models. Then Based on different analysis to determine whether a GARCH model can help or not. In my case, the goal is to apply the models on the following datasets: Income Stock, Home value, Sale price, Rental price. The corresponding returns are being calculated before fitting into to differnet models through model diagnostics. \n\n\n## Prepare the Dataset\n\n```{r, echo=FALSE, results='hide',warning=FALSE,message=FALSE}\nlibrary(reticulate)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(gridExtra)\nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(TTR) # For the SMA function\n\n```\n\n\n```{r, echo=FALSE, results='hide',warning=FALSE,message=FALSE}\ndf1 <- read.csv(\"../Dataset/project/household_saving.csv\")\ndf2 <- read.csv(\"../Dataset/project/MEHOINUSA672N.csv\")\ndf3 <- read.csv(\"../Dataset/project/MSPUS.csv\")\ndf4 <- read.csv(\"../Dataset/project/SIPOVGINIUSA.csv\")\ndf5 <- read.csv(\"../Dataset/project/FIXHAI.csv\")\ndf6 <- read.csv(\"../Dataset/project/PSAVERT.csv\")\ndf7 <- read.csv(\"../Dataset/project/A191RI1Q225SBEA.csv\")\ndf8 <- read.csv(\"../Dataset/project/Merged_downsample.csv\")\n\ndf1$DATE <- as.Date(df1$DATE)\ndf2$DATE <- as.Date(df2$DATE)\ndf3$DATE <- as.Date(df3$DATE)\ndf4$DATE <- as.Date(df4$DATE)\ndf5$DATE <- as.Date(df5$DATE)\ndf6$DATE <- as.Date(df6$DATE)\ndf7$DATE <- as.Date(df7$DATE)\ndf8$date <- as.Date(df8$date)\n\n```\n\n\nIncome Stock Analsyis with Verizon\n\nLiteruature Review:\nSince my big picture and goal is to evaluate the correlation between Home values, prices and income to see the impact among them. Therefore, an income stock would be effective for me to get my result.\n\nWireless subscribers of Verizon provide a reliable base of revenue and cash flow. Verizon generated an impressive $12.4 billion of free cash flow through the first nine months of 2022, giving it the funds to reward its shareholders with $8.1 billion in dividends.\n\nVerizon's shares offer a hefty dividend yield (it was more than 6% in late 2022). The telecom giant has also increased its dividend for 16 straight years, the longest current streak in the U.S. telecom sector. That attractive and growing income stream makes Verizon a great stock for earning passive income.\n\nUsing this dataset, I can represent and make analysis on the income to see if the modeling can capture the pattern effectively.\n\n\n## Calculate the Returns\n\n```{r, echo=FALSE}\nlibrary('quantmod')\n# gather stock price data from Yahoo Finance and focus on Disneyâ€™s adjusted stock prices starting from 2016\n\ngetSymbols(\"VZ\", from=\"2016-01-01\", src=\"yahoo\")\n\n```\n\n\n\n```{r, echo=FALSE}\n# Calculate the logarithmic returns\nVZ$VZ.Log.Returns <- c(diff(log(VZ$VZ.Close)))\nVZ <- na.omit(VZ)\n```\n\n\n```{r, echo=FALSE}\nx <- list(\n  title = \"date\"\n)\ny <- list(\n  title = \"value\"\n)\n\nstock <- data.frame(VZ$VZ.Log.Returns)\n\n\nstock <- data.frame(stock,rownames(stock))\ncolnames(stock) <- append('Income Stock Returns','date')   # USE Adjusted price as required\nhead(stock)\n```\n\nHere, we also have the new column for returns\n\n```{r}\nstock$date<-as.Date(stock$date,\"%Y-%m-%d\")\nfig <- plot_ly(stock, x = ~date, y = ~`Income Stock Returns`, name = 'Income Stock Returns From 2016', type = 'scatter', mode = 'lines') %>%\n  \n  layout(\n    title = \"Income Stock Returns  From 2016\",\n    paper_bgcolor = '#E0E0E0', # Set the background color \n    plot_bgcolor = '#E0E0E0', # Set the background color \n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"Stock returns\")\n  )\n\n\n```\n\n<iframe src=\"./image/GARCH/income_stock_returns.html\" width=\"100%\" height=\"400\"></iframe>\n\n## Stationarity\nThe plot shows no particular trend. This indicates that the series is likely stationary because the mean of the series could be constant or not changing too much over time. \n\n## Volatility\nThe series seems to exhibit periods of different volatility levels within expectations. However, overall, it is pretty steady throughout the time. There are some fluctuations, but the variations appear relatively stable and small. \n\nVolatility in financial time series is often clustered; periods of high volatility are followed by periods of high volatility, and periods of low volatility are followed by periods of low volatility. This plot suggests such clustering might be present.\n\n\n\n## Prepare to fit the model and check acf and pacf\n\n```{r}\nreturns = ts(stock$`Income Stock Returns`)\nacf_plot <- ggAcf(returns) +\n  labs(title = \"ACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(returns) +\n  labs(title = \"PACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)             \n\n```\n\n\nWe can see that the plots for the returns are weakly stationary.\n\n## ACF of absolute values of the returns \n\n```{r}\n\nacf_plot <- ggAcf(abs(returns)) +\n  labs(title = \"ACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(abs(returns)) +\n  labs(title = \"PACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)             \n\n```\n\n## ACF for squared values\n\n```{r}\nacf_plot <- ggAcf(returns^2) +\n  labs(title = \"ACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(returns^2) +\n  labs(title = \"PACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)             \n\n```\n\n\nBased on the acf and pacf, we can see that the returns are weakly stationary.\n\n```{r}\nlibrary(tseries)\nadf.test(returns)\n```\n\nWe can see that there are little correlations left. The returns are stationary.\n\n\n##  Fit an appropriate AR+ARCH/ARMA+GARCH or ARIMA-ARCH/GARCH\n\n\n### First, determine the ARIMA model using model diagnostic\n\n```{r}\n# Reference from the lab 6 part 1 demo:\ntemp.ts = returns\nd=0\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*71),nrow=71)\n\nfor (p in 1:5)\n{\n  for(q in 1:5)\n  {\n    for(d in 0:2)#\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(temp.ts,order=c(p-1,d,q-1),include.drift=FALSE) \n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\nknitr::kable(temp)\n```\n\n### Evaluations using AIC, BIC, and AICc\n\n```{r,echo=FALSE}\ntemp[which.min(temp$AIC),]\ntemp[which.min(temp$BIC),]\ntemp[which.min(temp$AICc),]\n```\n\nWe can see that  for (4,0,4) has the lowest AIC and AICc. For (0,0,0), it has the lowest BIC.\nTherefore we should compare them.\n\n## Compare ARIMA Models for (4,0,4) and ARIMA (0,0,0)\n```{r,warning=FALSE,echo=FALSE}\nset.seed(236)\n\nmodel_output21 <- capture.output(sarima(returns, 4,0,4)) \nmodel_output22 <- capture.output(sarima(returns, 0,0,0)) \n```\n\n```{r,echo=FALSE}\ncat(model_output21[160:200], model_output21[length(model_output21)], sep = \"\\n\")\n```\n\n```{r,echo=FALSE}\n\ncat(model_output22[20:38], model_output22[length(model_output22)], sep = \"\\n\")\n```\n\nBased on the model comparsion and diagnostic, I think that ARIMA Models for (4,0,4) is better with smaller evaluation matrices and it is more suitable and proper based on acf and pacf plots. In addition, the acf of residule is also more stationary.\n\n## Fit the best one ARIMA(4,0,4)\n\n```{r,warning=FALSE}\nfit2 <- arima(temp.ts, order = c(4,0,4))\nsummary(fit2)\n```\n\n## get the residuals of the arima model\n```{r,echo=FALSE}\narima.res <- residuals(fit2)\n\nacf_plot <- ggAcf(arima.res) +\n  labs(title = \"ACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(arima.res) +\n  labs(title = \"PACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)   \n\n```\n\n\nWe can see that mostly, the residual is stationary however the residuals of ARIMA model indicates some flutucations. \nIn this case, I think that we can try to fit an ARCH/GARCH model.\n\nTherefore, I think we can further making analysis by adding GARCH models to see if we should use it.\n\n## Model Diagnostics For ARCH/GARCH model \n\n### Acf and pacf for squared residuals\n```{r,echo=FALSE}\narima.res <- residuals(fit2)\n\nacf_plot <- ggAcf(arima.res^2) +\n  labs(title = \"ACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(arima.res^2) +\n  labs(title = \"PACF for data\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)   \n\n```\n\nWe can see that it is not yet stationary for squared residuals. GARCH model can be applied.\n\nHowever, no matter what, I still think that I should make a further diagnostic and compare the results.\n\n```{r}\nmean_res <- mean(arima.res, na.rm = TRUE)\nsd_res <- sd(arima.res, na.rm = TRUE)\n\n# Normalize the residuals\narima.res <- (arima.res - mean_res) / sd_res\n\nmodel <- list() ## set counter\ncc <- 1\nfor (p in 1:7) {\n  for (q in 1:7) {\n  \nmodel[[cc]] <- garch(arima.res,order=c(q,p),trace=F)\ncc <- cc + 1\n}\n} \n\n## get AIC values for model evaluation\nGARCH_AIC <- sapply(model, AIC) ## model with lowest AIC is the best\n```\n\n```{r,echo=FALSE}\nwhich(GARCH_AIC == min(GARCH_AIC))\nmodel[[which(GARCH_AIC == min(GARCH_AIC))]]\n```\n\nFrom here, I think that garch(5,6) is a good choice\n\n```{r,warning=FALSE,echo=FALSE}\nlibrary(fGarch)\nsummary(garchFit(~garch(5,6), arima.res,trace = F)) \n```\n\nThe results shows that (5,6) is not an optimal fit. The coefficients are not significant.\n\nTherefore, let us try GARCH(1,2) and GARCH(1,1)\n\n### Try to compare with Garch(1,1),Garch(1,2)\n```{r,echo=FALSE}\nsummary(garchFit(~garch(1,1), arima.res,trace = F)) \nsummary(garchFit(~garch(1,2), arima.res,trace = F)) \n\n```\n\nNow, it seems that the GARCH(1,2) is better with more siginificant components.\n\n\n## Final Model: ARIMA (4,0,4) + GARCH(1,2)\n\nThe final model consist of the ARIMA modeling with no differencing and the GARCH model.\nThis model combined the two different models to evaluate and capture the returns. The final one is better than the separate ones.\n\n### Forecast: ARIMA (4,0,4) + GARCH(1,2)\n```{r}\nfinal.fit <- garchFit(~garch(1,2), arima.res,trace = F)\npredict(final.fit, n.ahead = 365, plot=TRUE)\n```\n\nWe can see that the model captures the relatively constant variation with the confidence intervals fitted in the range. This means that the model combination is effective to predict the future values. The overall interpretation and prediction on the historical dataset is reasonable.\n\n### Box Ljung Test\n```{r}\nbox_ljung_test <- Box.test(arima.res, lag = 10, type = \"Ljung-Box\")\n\n# Display the test results\nbox_ljung_test\n```\n\nThe Box Ljung yields the simiarl results of my model choosing. The p-value is above a significance level 0.05, therefore, I do not reject the null hypothesis. This suggests that the residuals do not exhibit autocorrelation and that the model is adequate. This conclusion alignes that my models choosing capture the dataset and make predictions well.\n\n### The Equation\n\n\nThe ARIMA (0,2,3) + Garch(1,0) model is defined as:\nThe combined ARIMA(0,2,3) + GARCH(1,0) model is defined as:\n\nThe ARIMA(0,2,3) + GARCH(1,0) model is defined as:\n\n\\[\n\\begin{align*}\n(1 - B)^2 X_t &= \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3} + \\varepsilon_t, \\\\\n\\text{where } \\varepsilon_t &\\sim N(0, \\sigma_t^2), \\\\\n\\sigma_t^2 &= \\alpha_0 + \\alpha_1 \\varepsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2.\n\\end{align*}\n\\]\n\nHere:\n- \\( (1 - B)^2 X_t \\) represents the second difference of the time series \\( X_t \\).\n- \\( \\theta_1, \\theta_2, \\theta_3 \\) are the parameters of the moving average (MA) component.\n- \\( \\varepsilon_t \\) is the white noise error term at time \\( t \\).\n- \\( \\sigma_t^2 \\) is the conditional variance at time \\( t \\).\n- \\( \\alpha_0, \\alpha_1 \\) are the coefficients of the GARCH model's variance equation.\n- \\( \\beta_1 \\) is the coefficient for the lagged conditional variance.\n\n\n# Home Value, Sale Price, and Rental Price Return analysis\n\n\n## Calculate the Returns\n```{r,echo=FALSE}\n# Load necessary library\nlibrary(dplyr)\n\n\n\n# Calculate returns\ndata <- df8 %>%\n  mutate(\n    Home_Value_Return = (Mean.Home.Value - lag(Mean.Home.Value)) / lag(Mean.Home.Value) * 100,\n    Rental_Price_Return = (mean - lag(mean)) / lag(mean) * 100,\n    Sale_Price_Return = (Mean.Sale.Price - lag(Mean.Sale.Price)) / lag(Mean.Sale.Price) * 100\n  )\n\n\n\n```\n\n\n```{r,echo=FALSE}\nsan_jose_data <- data %>% \n  filter(Metropolitan.Area == \"San Jose, CA\")\nhead(san_jose_data)\n```\n\n## Plot For Rental, Sale, Home Values For San Jose, CA\n```{r,message=FALSE}\nlibrary(plotly)\n\n# Your existing plot_ly code\np <- plot_ly(data = san_jose_data, x = ~date) %>%\n     add_trace(y = ~Rental_Price_Return, name = 'Mean Rental Price', mode = 'lines') \n\n# Adding background color and title\np <- p %>% layout(\n    title = \"Mean Rental Price Over Time\",  # Add your title here\n    paper_bgcolor = '#E0E0E0',  # Set the background color of the plotting area\n    plot_bgcolor = '#E0E0E0'  # Set the background color of the graph\n)\n\n\n```\n\n<iframe src=\"./image/GARCH/rental.html\" width=\"100%\" height=\"400\"></iframe>\n\n\n\n```{r,message=FALSE}\np <- plot_ly(data = san_jose_data, x = ~date) %>%\n     add_trace(y = ~Mean.Sale.Price, name = 'Mean Sale Price', mode = 'lines') %>%\n     add_trace(y = ~Mean.Home.Value, name = 'Mean Home Value', mode = 'lines') \n# Adding background color and title\np <- p %>% layout(\n    title = \"Mean Sale Price and Home Value Over Time\",  # Add your title here\n    paper_bgcolor = '#E0E0E0',  # Set the background color of the plotting area\n    plot_bgcolor = '#E0E0E0'  # Set the background color of the graph\n)\n\n```\n\n<iframe src=\"./image/GARCH/hs.html\" width=\"100%\" height=\"400\"></iframe>\n\n\n## Return Plots\n```{r,warning=FALSE}\nlibrary(ggplot2)\n\np <- ggplot(san_jose_data, aes(x = date)) +\n  geom_line(aes(y = Sale_Price_Return), color = \"blue\") +\n  geom_line(aes(y = Home_Value_Return), color = \"red\") +\n  geom_line(aes(y = Rental_Price_Return), color = \"green\") +\n  labs(title = \"Time Series Plot Of Returns\", x = \"Date\", y = \"Value\") +\n  theme_minimal()\n\n# Modify the background color\np <- p + theme(\n    plot.background = element_rect(fill = \"#E0E0E0\", color = NA), # Background of the entire plot\n    panel.background = element_rect(fill = \"#E0E0E0\", color = NA)  # Background of the plotting area\n)\n\n# Display the plot\np\n\n```\n\n\n\n## Stationarity\nThe plot shows a clear upward trend in both Mean Sale Price and Mean Home Value over time until what appears to be a sharp drop in the most recent data point. This trend indicates that the series is likely non-stationary because the mean of the series is changing over time. The presence of a trend is a strong indication that at least the mean is not constant.\nThe drop at the end could be due to the incident of Covid-19, an extreme value, or a real market crash. \n## Volatility\nThe series seems to exhibit periods of different volatility levels. Initially, there is some fluctuation, but the variations appear relatively stable and small. However, the spike at the end of the series suggests a sudden increase in volatility.\nVolatility in financial time series is often clustered; periods of high volatility are followed by periods of high volatility, and periods of low volatility are followed by periods of low volatility. This plot suggests such clustering might be present, although the spike at the end may skew this perception.\n\n\n\n\n```{r,echo=FALSE}\ndf1 = san_jose_data\n\ndf1$date <- as.Date(df1$date, format = \"%Y-%m-%d\")\n```\n\n## First Fit a Linear Model\n\nI think that the home value can be consisted of the sale price and rental price\n```{r,warning=FALSE}\nlibrary(caret)\n```\n\n\n\n\n```{r,echo=FALSE}\n# Linear model and check coefficients\nmodel <- lm(Mean.Home.Value ~ Mean.Sale.Price + mean, data = df1)\nsummary(model)\n```\n\n\n\nThe coefficients are significant\n\n```{r,warning=FALSE}\nlibrary(car)\nvif(model)\n```\n\nWe can see that the Mean sale price and rental price have much relatively low VIF scores. Therefore, we can keep them in modeling:\n\n```{r, echo=FALSE}\nset.seed(236) # for reproducibility\nsplitIndex <- createDataPartition(df1$Home_Value_Return, p = 0.8, list = FALSE)\ntrain <- df1[splitIndex, ]\ntest <- df1[-splitIndex, ]\n\n```\n\n## Evaluations of the model\n```{r}\npredictions <- predict(model, newdata = test)\nSSE <- sum((predictions - test$Mean.Home.Value)^2)\nSST <- sum((test$Mean.Home.Value - mean(train$Mean.Home.Value))^2)\nrsquared_test <- 1 - SSE/SST\nrsquared_test \n```\n\nThe rsquared is relatively small, we can now keep the model for later analysis.\n\n## Prepare to fit the model and get residuals\n\n```{r}\nlm.residuals <- residuals(model)\nplot(lm.residuals, ylab = \"Residuals\", main = \"Residuals \")\n```\n\n### check correlation in these residuals using an ACF plot \n\n```{r}\n\nacf_plot <- ggAcf(lm.residuals) +\n  labs(title = \"ACF for Model Residuals\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(lm.residuals) +\n  labs(title = \"PACF for Model Residuals\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)             \n\n```\n\n\n\nBased on the acf and pacf, we can choose p = 0,1,2,3 q = 0,1,2\n\n```{r,warning=FALSE}\nlibrary(tseries)\nadf.test(lm.residuals)\n```\n\nWE can see that there are little correlations left. The lm residuals are stationary now.\n\n\n##  Fit an appropriate AR+ARCH/ARMA+GARCH or ARIMA-ARCH/GARCH\n\n\n### First, determine the ARIMA model using model diagnostic\n\n\n```{r,warning=FALSE}\n# Reference from the lab 6 part 1 demo:\ntemp.ts = log(diff(lm.residuals))\nd=0\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*71),nrow=71)\n\nfor (p in 1:5)\n{\n  for(q in 1:5)\n  {\n    for(d in 0:2)#\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(temp.ts,order=c(p-1,d,q-1),include.drift=FALSE) \n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\nknitr::kable(temp)\n```\n\n### Evaluations using AIC, BIC, and AICc\n\n```{r}\ntemp[which.min(temp$AIC),]\ntemp[which.min(temp$BIC),]\ntemp[which.min(temp$AICc),]\n```\n\nWe can see that  for (0,1,1) and (0,1,4), the AIC, BIC, and AICc are different. We should choose from them.\n\n\n\n### Compare ARIMA Models for (4,0,4) and ARIMA (0,0,0)\n```{r,warning=FALSE}\nset.seed(236)\n\nmodel_output21 <- capture.output(sarima(lm.residuals, 0,1,1)) \nmodel_output22 <- capture.output(sarima(lm.residuals, 0,1,4)) \n```\n\n```{r}\ncat(model_output21[120:147], model_output21[length(model_output21)], sep = \"\\n\")\n```\n\n```{r}\n\ncat(model_output22[50:80], model_output22[length(model_output22)], sep = \"\\n\")\n```\n\nBased on the model comparsion and diagnostic, I think that ARIMA Models for (0,1,1) is better with smaller evaluation matrices and it is more suitable and proper based on acf and pacf plots. In addition, the acf of residule is also more stationary.\n\n\n## Fit the best one ARIMA(0,1,1)\n\n```{r}\n\nmean_value <- mean(temp.ts, na.rm = TRUE)\n\n# Replace NaN values with the mean\ntemp.ts[is.na(temp.ts)] <- mean_value\n\n```\n\n```{r}\nfit2 <- arima(temp.ts, order = c(0,1,1))\nsummary(fit2)\n```\n\n### get the residuals of the arima model\n```{r}\narima.res <- residuals(fit2)\n# Plot the residuals\n\n\nacf_plot <- ggAcf(arima.res) +\n  labs(title = \"ACF for Model Residuals\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(arima.res) +\n  labs(title = \"PACF for Model Residuals\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)             \n```\n\n\n\n\nWe can see that mostly, the residual is stationary however the residuals of ARIMA model indicates some flutucations. \nIn this case, I think that we can try to fit an ARCH/GARCH model.\n\nTherefore, I think we can further making analysis by adding GARCH models to see if we should use it.\n\n## Model Diagnostics For ARCH/GARCH model (No need in my case, Just to Verify)\n\n\n```{r}\n\n\nacf_plot <- ggAcf(arima.res^2) +\n  labs(title = \"ACF for Squared Model Residuals\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\npacf_plot <- ggPacf(arima.res^2) +\n  labs(title = \"PACF for Squared Model Residuals\") +\n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Combine the plots\ngrid.arrange(acf_plot, pacf_plot, ncol = 1)             \n\n```\n\nWe can see that it acutally already sufficient to just use ARIMA model. GARCH model is not required since it is already pretty good in removing correlations. The residual and squared residual are stationary.\n\nHowever, I still think that I can at least try to make a further diagnostic and compare the results to verify that I do not need to fit GARCH model.\n\n\n\n```{r,echo=FALSE}\narima.res[is.na(arima.res)] <- mean(arima.res, na.rm = TRUE)  # Or median\n\n\n```\n\n```{r,warning=FALSE,echo=FALSE}\nmodel <- list() ## set counter\ncc <- 1\nfor (p in 1:7) {\n  for (q in 1:7) {\n  \nmodel[[cc]] <- garch(arima.res,order=c(q,p),trace=F)\ncc <- cc + 1\n}\n} \n\n## get AIC values for model evaluation\nGARCH_AIC <- sapply(model, AIC) ## model with lowest AIC is the best\n```\n\n```{r,echo=FALSE}\nwhich(GARCH_AIC == min(GARCH_AIC))\nmodel[[which(GARCH_AIC == min(GARCH_AIC))]]\n```\n\nFrom here, I think that garch(5,1) is a good choice\n\n```{r,warning=FALSE}\nlibrary(fGarch)\nsummary(garchFit(~garch(5,1), arima.res,trace = F)) \n```\n\nThe results shows that (5,1) is not an optimal fit. The coefficients are not significant.\n\nTherefore, let us try (1,0)\n\n### Try to compare with Garch(1,0)\n```{r}\nsummary(garchFit(~garch(1,0), arima.res,trace = F)) \n```\n\nNow, it seems that the alpha1 is still not significant.\nTherefore, in this case, we can stop with arima model. No additional Garch is needed.\n\nHowever, we still can compare the prediction fits.\n\n## Forecast \n\n### ARIMA (0,1,1)\n\n```{r}\n\n# Autoplot with custom colors\nplot_fit_ <- autoplot(forecast(fit2,10)) + \n  theme(\n    panel.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    plot.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    legend.background = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\"),\n    legend.key = element_rect(fill = \"#E0E0E0\", color = \"#E0E0E0\")\n  )\n\n# Display the plot\nprint(plot_fit_)\n```\n\n\n\nBy comparing the fits, I think that the ARIMA model alone is better. We do not need the GArch in my case\n\n## Final model: ARIMA (0,1,1) and equation\n\n### Box Ljung Test\n```{r}\nbox_ljung_test <- Box.test(arima.res, lag = 10, type = \"Ljung-Box\")\n\n# Display the test results\nbox_ljung_test\n```\n\nthe p-value is above a significance level 0.05, therefore, I do not reject the null hypothesis. This suggests that the residuals do not exhibit autocorrelation and that the model is adequate. This conclusion alignes with my model diagnostics and forecasting comparesion. The ARIMA(0,2,3) alone is enough in my case.\n\n\n### Equation\n\nThe ARIMA(0,1,1) model is defined as:\n\n$$\n(1 - B) X_t = (1 + \\theta_1B)a_t\n$$\n\nwhere:\n- \\( B \\) is the backshift operator,\n- \\( X_t \\) is the time series observation at time t,\n- \\( (1 - B) \\) denotes first-order differencing,\n- \\( \\theta_1 \\) is the parameter of the moving average part of the model,\n- \\( a_t \\) is the error term at time t.\n\nThis model is a simplification of higher-order ARIMA models and is used when the data exhibits a level of temporal dependency that can be explained with a single differencing and a single lag in the moving average component.\n\n\nNo Garch components since in my case the ARIMA is better and sufficient.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles/layout.css","./styles/layout.css"],"toc":true,"output-file":"GARCH.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","theme":"sandstone","title":"Financial Time Series Models (ARCH/GARCH)","navbar":{"left":["about.qmd","Introduction.qmd","DataSources.qmd","DataVis.qmd","EDA.qmd","ARModels.qmd","ASV.qmd","SAF.qmd","GARCH.qmd","TS.qmd","conclusion.qmd","dv.qmd"]}},"extensions":{"book":{"multiFile":true}}}}}