{"title":"Deep Learning for TS","markdown":{"yaml":{"title":"Deep Learning for TS","navbar":{"left":["about.qmd","Introduction.qmd","DataSources.qmd","DataVis.qmd","EDA.qmd","ARModels.qmd","ASV.qmd","SAF.qmd","GARCH.qmd","TS.qmd","conclusion.qmd","dv.qmd"]},"format":{"html":{"theme":"sandstone","css":"./styles/layout.css","code-fold":true,"toc":true}}},"headingText":"Median Sale Price Deep Learning Analysis","containsRefs":false,"markdown":"\n\n\nThe first analysis is the median sale price analysis, which is also utilzied during previous sections. In here, the goal is to utilize three different models: LSTM, RNN, and GRU. Then make comparsion between deep learning methods and ARIMA models. \n\n## Data Preparation\n\nThe corresponding time seires dataset is prepared and cleaned with objective column and then use train test splits for furthering steps in later section.\n\n```{python, echo = FALSE}\nimport numpy as np\nimport warnings\nimport pandas as pd\nimport os\nimport random\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.layers import SimpleRNN, Dense\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, GRU, Dense\nfrom tensorflow.keras import regularizers\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\nwarnings.filterwarnings('ignore')\n# Setting seeds for reproducibility\nrandom.seed(236)\nnp.random.seed(236)\ntf.random.set_seed(236)\ndf = pd.read_csv(\"../Dataset/project/MSPUS.csv\")\ndf.head()\n\n\n\ndf = df.rename(columns={\"MSPUS\": \"y\"}) # The objective\ndf = df[[\"DATE\", \"y\"]]\nX = np.array(df[\"y\"].values.astype(\"float32\")).reshape(df.shape[0], 1)\n\n# Train and Test Split & Normalization\n\ndef train_test_split(data, split_percent=0.8):\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data = scaler.fit_transform(data).flatten()\n    n = len(data)\n   \n    split = int(n * split_percent)\n    train_data = data[range(split)]\n    test_data = data[split:]\n    return train_data, test_data, data\n\n\ntrain_data, test_data, data = train_test_split(X)\n\nprint(\"train shape:\", train_data.shape)\nprint(\"test shape:\", test_data.shape)\n```\n\n## Train & Test Dataset\n\nBelow, we can see clearly about the train and test dataset that I splitted. The goal is to have a visulization of the dataset as a whole.\n\n```{python}\nfig, ax = plt.subplots(figsize=(15, 6), dpi=100)  # Set the size and DPI of the figure\nfig.patch.set_facecolor('#E0E0E0')  # Set the background color for the outer figure\nax.set_facecolor('#E0E0E0')  # Set the background color for the axes\n\n# Plot the training data\nax.plot(range(0, len(train_data)), train_data, \"-\", label=\"Training Data\")\n\n# Plot the test data\nax.plot(range(len(train_data), len(train_data) + len(test_data)), test_data, \"-\", label=\"Test Data\")\n\n# Set labels and title\nax.set(xlabel=\"Time (days)\", ylabel=\"Median Sale Price Scaled\", title=\"Median Sale Price Over Time\")\n\n# Add grid with white color for better visibility on the gray background\nax.grid(color='white')\n\n# Add legend to the plot\nax.legend()\n\n# Show the plot\nplt.show()\n```\n\n## Preparation For Input and Target\n\nIn order to correctly fit into the corresonding models, the size of x and y must be determined and transformed correctly.\n\n```{python}\n# PREPARE THE INPUT X AND TARGET Y\ndef get_XY(dat, time_steps, plot_data_partition=False):\n    global X_ind, X, Y_ind, Y  # use for plotting later\n\n    # INDICES OF TARGET ARRAY\n    # Y_ind [  12   24   36   48 ..]; print(np.arange(1,12,1)); exit()\n    Y_ind = np.arange(time_steps, len(dat), time_steps)\n    # print(Y_ind); exit()\n    Y = dat[Y_ind]\n\n    # PREPARE X\n    rows_x = len(Y)\n    X_ind = [*range(time_steps * rows_x)]\n    del X_ind[::time_steps]  # if time_steps=10 remove every 10th entry\n    X = dat[X_ind]\n\n    # PLOT\n    if plot_data_partition:\n        plt.figure(figsize=(15, 6), dpi=80)\n        plt.plot(Y_ind, Y, \"o\", X_ind, X, \"-\")\n        plt.show()\n\n    # RESHAPE INTO KERAS FORMAT\n    X1 = np.reshape(X, (rows_x, time_steps - 1, 1))\n    # print([*X_ind]); print(X1); print(X1.shape,Y.shape); exit()\n\n    return X1, Y\n\n\n# PARTITION DATA\np = 30  #\ntestX, testY = get_XY(test_data, p)\ntrainX, trainY = get_XY(train_data, p)\n\n #USER PARAM\nrecurrent_hidden_units = 3\nepochs = 200\nf_batch = 0.2  # fraction used for batch size\noptimizer = \"RMSprop\"\nvalidation_split = 0.2\n# trainY=trainY.reshape(trainY.shape[0],1)\n# testY=testY.reshape(testY.shape[0],1)\nprint(\"Testing Array Shape:\", testX.shape, testY.shape)\nprint(\"Training Array Shape:\", trainX.shape, trainY.shape)\n```\n\nNow, we are ready for training into the model for analysis.\n\n## LSTM \n\nFor this LSTM model, we will compare the performance using RMSE for regularization and no regularization.\n\n### NO Regularization\n\n```{python}\n\nmodel = Sequential()\n\nmodel.add(\n    LSTM(\n        \n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n       \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n```\n\n```{python}\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=epochs,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\ndef plot_result(trainY, testY, train_predict, test_predict):\n    plt.figure(figsize=(15, 6), dpi=200, facecolor='#E0E0E0')  # Set higher DPI and background color for the figure\n    plt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\n    # ORIGINAL DATA\n    print(X.shape, Y.shape)\n    plt.plot(Y_ind, Y, \"o\", label=\"Target\")\n    plt.plot(X_ind, X, \".\", label=\"Training points\")\n    plt.plot(Y_ind, train_predict, \"b.\", label=\"Prediction\")\n    plt.plot(Y_ind, train_predict, \"r-\")\n    plt.legend()\n    plt.xlabel(\"Observation number after given time steps\")\n    plt.ylabel(\"Median Sale Price Scaled\")\n    plt.title(\"Actual and Predicted Values\")\n    plt.grid(color='white')  # Set grid color to white for better visibility\n    plt.show()\n\n\n\n```\n\nFor LSTM with no regulariztaion, we have the test and train RMSE: 0.29045 and 0.05688\n\n#### Predication Plot\n\n```{python}\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\nWe can see that from this plot based on LSTM no regulariztaion, the performance of the model is pretty good. The targets and prediction values are close.\n\n### With Regularization\n\nNow, we compare the model by adding some regularization. \nThe goal of the regularization is to prevent overfitting.\n\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    LSTM(\n        # model.add(SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n```\n\n```{python}\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n```\n\nFrom here, we can see that the test and train RMSE becomes: 0.15581 and 0.02203.\n\nIn this case, by adding the regularization the RMSE becomes lower. This means that my model did not overfit. Overall, LSTM performs well.\n\n\n### Predictions & Discussions\n```{python}\n\n\n\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n### Regulariztaion Effect\nThe result suggests that the model is able to capture the underlying trend in the data quite well. Regularization comparsion proved that the model did not overfit. Also, the smoothness of the prediction curve indicates that the L2 regularization has effectively penalized overly complex models that could have fit the noise in the training data.\n\n### How Far Into Future\nThe predictions seem to align well with the actual data for most of the original dataset. However, there appears to be a slight divergence toward the end. This divergence might indicate the limit of the model's predictive horizon, which is about 175 days ahead. In this case, we can say that the model can predict with relatively accuracy for 200 days ahead. \n\n\n\n## RNN \n\n\n### No Regularization\n\nLikewise, we will test the model prediction and errors with and without regularization for each model.\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n     \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n```\n\nWith no regularization, the RNN performs better than LSTM with lower rmse. \nHowever, regularization can help us prevent overfitting. Therefore, we need further using regularization to make thorough analysis.\n\n```{python}\n\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n### With Regularization\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Ensures a 1D array output\n\n# Check shapes again to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n```\n\n\n```{python}\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (train_rmse**2.0, train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (test_rmse**2.0, test_rmse))\n```\n\nNow, there are relatievly large differences when using regularization in RNN model. The results show that the model will overfit if we do not use regularization in RNN. The result for RNN model with regularization performs less than the LSTM model with higher rmse values. \n\n### Predictions\n\n```{python}\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\nThe figure of the predictions and actual values also proves that the RNN model with regulariztaion performs less than the LSTM model. We can see that there are differences for the step points \n\n## GRU \n\nThe third model is GRU, we will also test the two results for both with regulariztaion and no regularization. Then by combining the results in a table, we can compare them clearly.\n\n\n### NO Regularization\n\nLikewise, we will test the model prediction and errors with and without regularization for each model.\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n      \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n# TRAIN MODEL\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n```\n\nWe can see that with no regulariztaion, the model performs very good. However, it could be overfitting.\n\n```{python}\n\n\n# Call the function with your data\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\nThe predictions and actual values align very well. This could be the reason of overfitting.\n\n\n### With Regularization\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()  # Ensures a 1D array output\ntest_predict = model.predict(testX).flatten()\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\n```\n\n```{python}\n\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\nWe can see that if we add regularization, the result of RMSE becomes higher. This shows that with no regularization, the GRU model overfitted.\n\nIn general, in my case, with regularization, LSTM model performed the best among the three models. RNN model perfomed the least among the three models.\n\n\n# Household Saving Deep Learning Analysis\n\nAs we did in ARMA section, we will also do the deep learning analysis and compare with the results for household saving analysis.\n\n## Data Preparation\n```{python}\ndf = pd.read_csv(\"../Dataset/project/household_saving.csv\")\ndf = df.rename(columns={\"W398RC1A027NBEA\": \"y\"}) # The objective\ndf = df[[\"DATE\", \"y\"]]\nX = np.array(df[\"y\"].values.astype(\"float32\")).reshape(df.shape[0], 1)\n\n# Train and Test Split & Normalization\n\ndef train_test_split(data, split_percent=0.8):\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data = scaler.fit_transform(data).flatten()\n    n = len(data)\n   \n    split = int(n * split_percent)\n    train_data = data[range(split)]\n    test_data = data[split:]\n    return train_data, test_data, data\n\n\ntrain_data, test_data, data = train_test_split(X)\n# PREPARE THE INPUT X AND TARGET Y\ndef get_XY(dat, time_steps, plot_data_partition=False):\n    global X_ind, X, Y_ind, Y  # use for plotting later\n\n    # INDICES OF TARGET ARRAY\n    # Y_ind [  12   24   36   48 ..]; print(np.arange(1,12,1)); exit()\n    Y_ind = np.arange(time_steps, len(dat), time_steps)\n    # print(Y_ind); exit()\n    Y = dat[Y_ind]\n\n    # PREPARE X\n    rows_x = len(Y)\n    X_ind = [*range(time_steps * rows_x)]\n    del X_ind[::time_steps]  # if time_steps=10 remove every 10th entry\n    X = dat[X_ind]\n\n    # PLOT\n    if plot_data_partition:\n        plt.figure(figsize=(15, 6), dpi=80)\n        plt.plot(Y_ind, Y, \"o\", X_ind, X, \"-\")\n        plt.show()\n\n    # RESHAPE INTO KERAS FORMAT\n    X1 = np.reshape(X, (rows_x, time_steps - 1, 1))\n    # print([*X_ind]); print(X1); print(X1.shape,Y.shape); exit()\n\n    return X1, Y\n\n\n# PARTITION DATA\np = 3  #\ntestX, testY = get_XY(test_data, p)\ntrainX, trainY = get_XY(train_data, p)\n\n #USER PARAM\nrecurrent_hidden_units = 3\nepochs = 200\nf_batch = 0.2  # fraction used for batch size\noptimizer = \"RMSprop\"\nvalidation_split = 0.2\n# trainY=trainY.reshape(trainY.shape[0],1)\n# testY=testY.reshape(testY.shape[0],1)\nprint(\"Testing Array Shape:\", testX.shape, testY.shape)\nprint(\"Training Array Shape:\", trainX.shape, trainY.shape)\n```\n\nAfter getting the corresponding train and test datasets, we can continue the process similarly.\n\n## LSTM \n\n### No Regularization\n```{python}\n\nmodel = Sequential()\n\nmodel.add(\n    LSTM(\n        \n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n       \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\ndef plot_result(trainY, testY, train_predict, test_predict):\n    plt.figure(figsize=(15, 6), dpi=200, facecolor='#E0E0E0')  # Set higher DPI and background color for the figure\n    plt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\n    # ORIGINAL DATA\n    print(X.shape, Y.shape)\n    plt.plot(Y_ind, Y, \"o\", label=\"Target\")\n    plt.plot(X_ind, X, \".\", label=\"Training points\")\n    plt.plot(Y_ind, train_predict, \"b.\", label=\"Prediction\")\n    plt.plot(Y_ind, train_predict, \"r-\")\n    plt.legend()\n    plt.xlabel(\"Observation number after given time steps\")\n    plt.ylabel(\" Household Saving Scaled\")\n    plt.title(\"Actual and Predicted Values\")\n    plt.grid(color='white')  # Set grid color to white for better visibility\n    plt.show()\n\n\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\nThe RMSE for household saving analysis is about 0.41, we can see that the points predicted roughly the same from 1 to 15 time steps. Then it started to predict wrongly. Then, we will compare with regularization conducted to see if the result is overfitted.\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    LSTM(\n        # model.add(SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n\nFrom this result, we can see that the RMSE is actually lower. This means that in this case, the LSTM did not overfit for the household saving dataset. The possible reason could be the size of the dataset is relatively small which actually prevented the overfitting. However, I think that due to the small size of the dataset, the deep learning model is not as effective as the ARIMA models.\n\n## RNN\n\nFor RNN, we do the same process.\n\n### No Regularization\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n     \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\nFor RNN with no regularization, the result is higher compare to LSTM\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n# Check shapes again to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\nAgain, we can see that the RNN model with and without regularization yields similar results. I think the reason could be the same as LSTM, the dataset is relatively small such that there is no overfitting yet.\n\n## GRU\n\nSame steps with GRU\n\n### No Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n      \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\nWe can see that overall, GRU has the lowest RMSE for no regularization.\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()  # Ensures a 1D array output\ntest_predict = model.predict(testX).flatten()\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\n# Call the function with your data\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\nOverll, the GRU model performs the best for household savings analysis.\n\n# Discussions I\n\n## For Median Sale Price\n\n### Deep learning methods comparison\nIn my case, the LSTM performed the best with lowest RMSE. In addition, the prediction plot with the actual data also shows that the LSTM is better among the three methods for my median sale price analysis.\n\n### Regulariztaion Effect\nThe result suggests that the model is able to capture the underlying trend in the data quite well. Regularization comparsion proved that the model did not overfit too much. Also, the smoothness of the prediction curve indicates that the L2 regularization has effectively penalized overly complex models that could have fit the noise in the training data.\n\n### How Far can the deep learning methods predict\nIn my analsyis for median sale price, overall, the LSTM made relatively better predictions. The predictions started going wrong after 150 given steps. Therefore, I think that for deep learning methods, it can predict around half of year correctly.\n\n### Comparison to ARMA/ARIMA \nFor median sale price analsyis, the LSTM model performs the best with relatively low RMSE. Compare to the ARIMA model in ARIMA section, the model used for median sale price was ARIMA(1,1,1). And the RMSE is higher than the deep learning methods. Therefore, in my case, I believe that the LSTM model provides better predictions. The possible reason I think is that the deep learning models can evaluate the dataset by capturing more features. Especially that the dataset has an obvious upwarding trend. The deep learning model can interpret the trend better with each epoch trained therefore we can get better results. However, the overfitting could exist therefore regularization must be included to avoid overfitting.\n\n\n\n## For Household Saving\nWe can see that comparing to Median Sale Price analysis, the analysis for household saving is not as effective. The reason is because of the dataset size different. With less datapoints, the models for household saving did not perform as well as they should be. We also can not determine the prediction power of models on this dataset. Therefore, in my case for household saving analysis, the deep learning methods are not as effective as the ARIMA models.\n\n### Deep learning methods comparison\nIn my case, the GRU performed the best with lowest RMSE. In addition, the prediction plot with the actual data also shows that the GRU is better among the three methods for my household saving analysis.\n\n### Regularization Effect\nIn this case, the regularization actually did not change too much for the results. Regularization comparsion proved that the model did not overfit. Again, it could be due to the small size of the dataset. \n\n### How Far can the deep learning methods predict\nThe RMSE for household saving analysis is about 0.41, we can see that the points predicted roughly the same from 1 to 15 time steps. Then it started to predict wrongly. Again, it could be due to the small size of this dataset. It is hard to tell the exact prediction power. Overall, I do not think that deep learning methods are effective for household saving analysis.\n\n\n### Comparison to ARMA/ARIMA \nFor household saving analsyis, I think that due to the small size of the dataset, the deep learning model is not as effective as the ARIMA models. ARIMA model can capture better for this dataset by considering different patterns such as stationary and season. In my case, I believe that the ARIMA model performs better. For deep learning methods, although the results have smaller RMSEs, I still think that the analysis could be improved by using larger datasets.\n\n\n\n\n\n# GDP Deflator Deep Learning Analysis (Compare With VAR Model)\n\nIn my ARIMAX and VAR section, I made analysis on two VAR models. Both of the VAR models contain the GDP deflator variable since it is a crucial factor in representing the economic as a whole. It can provide insights in determine the effects and impacts on personal income and saving, further impling the housing prices and affordability. Therefore, in here, I want to gain insights and make comparison by using deep learning methods.\n\n## Data Preparation\nIn this code part, I also included datasets for mutivariable analysis in later section\n\n```{python}\ndf = pd.read_csv(\"../Dataset/project/A191RI1Q225SBEA.csv\")\ndf2 = pd.read_csv(\"../Dataset/project/MSPUS.csv\")\ndf3 = pd.read_csv(\"../Dataset/project/PSAVERT.csv\")\n\ndf = df.rename(columns={\"A191RI1Q225SBEA\": \"y\"}) # The objective\ndf = df[[\"DATE\", \"y\"]]\nX = np.array(df[\"y\"].values.astype(\"float32\")).reshape(df.shape[0], 1)\n\n# Train and Test Split & Normalization\n\ndef train_test_split(data, split_percent=0.8):\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data = scaler.fit_transform(data).flatten()\n    n = len(data)\n   \n    split = int(n * split_percent)\n    train_data = data[range(split)]\n    test_data = data[split:]\n    return train_data, test_data, data\n\n\ntrain_data, test_data, data = train_test_split(X)\n\nprint(\"train shape:\", train_data.shape)\nprint(\"test shape:\", test_data.shape)\n\nfig, ax = plt.subplots(figsize=(15, 6), dpi=100)  # Set the size and DPI of the figure\nfig.patch.set_facecolor('#E0E0E0')  # Set the background color for the outer figure\nax.set_facecolor('#E0E0E0')  # Set the background color for the axes\n\n# Plot the training data\nax.plot(range(0, len(train_data)), train_data, \"-\", label=\"Training Data\")\n\n# Plot the test data\nax.plot(range(len(train_data), len(train_data) + len(test_data)), test_data, \"-\", label=\"Test Data\")\n\n# Set labels and title\nax.set(xlabel=\"Time (days)\", ylabel=\"Median GDP Deflator Scaled\", title=\"Median GDP Deflator Over Time\")\n\n# Add grid with white color for better visibility on the gray background\nax.grid(color='white')\n\n# Add legend to the plot\nax.legend()\n\n# Show the plot\nplt.show()\n# PREPARE THE INPUT X AND TARGET Y\ndef get_XY(dat, time_steps, plot_data_partition=False):\n    global X_ind, X, Y_ind, Y  # use for plotting later\n\n    # INDICES OF TARGET ARRAY\n    # Y_ind [  12   24   36   48 ..]; print(np.arange(1,12,1)); exit()\n    Y_ind = np.arange(time_steps, len(dat), time_steps)\n    # print(Y_ind); exit()\n    Y = dat[Y_ind]\n\n    # PREPARE X\n    rows_x = len(Y)\n    X_ind = [*range(time_steps * rows_x)]\n    del X_ind[::time_steps]  # if time_steps=10 remove every 10th entry\n    X = dat[X_ind]\n\n    # PLOT\n    if plot_data_partition:\n        plt.figure(figsize=(15, 6), dpi=80)\n        plt.plot(Y_ind, Y, \"o\", X_ind, X, \"-\")\n        plt.show()\n\n    # RESHAPE INTO KERAS FORMAT\n    X1 = np.reshape(X, (rows_x, time_steps - 1, 1))\n    # print([*X_ind]); print(X1); print(X1.shape,Y.shape); exit()\n\n    return X1, Y\n\n\n# PARTITION DATA\np = 30  #\ntestX, testY = get_XY(test_data, p)\ntrainX, trainY = get_XY(train_data, p)\n #USER PARAM\nrecurrent_hidden_units = 3\nepochs = 200\nf_batch = 0.2  # fraction used for batch size\noptimizer = \"RMSprop\"\nvalidation_split = 0.2\n\nprint(\"Testing Array Shape:\", testX.shape, testY.shape)\nprint(\"Training Array Shape:\", trainX.shape, trainY.shape)\n```\n\n## LSTM\n\nSimilar Process as the above sections\n\n### No Regularization\n\n```{python}\n\nmodel = Sequential()\n\nmodel.add(\n    LSTM(\n        \n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n       \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=epochs,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\ndef plot_result(trainY, testY, train_predict, test_predict):\n    plt.figure(figsize=(15, 6), dpi=200, facecolor='#E0E0E0')  # Set higher DPI and background color for the figure\n    plt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\n    # ORIGINAL DATA\n    print(X.shape, Y.shape)\n    plt.plot(Y_ind, Y, \"o\", label=\"Target\")\n    plt.plot(X_ind, X, \".\", label=\"Training points\")\n    plt.plot(Y_ind, train_predict, \"b.\", label=\"Prediction\")\n    plt.plot(Y_ind, train_predict, \"r-\")\n    plt.legend()\n    plt.xlabel(\"Observation number after given time steps\")\n    plt.ylabel(\"Median GDP Deflator Scaled\")\n    plt.title(\"Actual and Predicted Values\")\n    plt.grid(color='white')  # Set grid color to white for better visibility\n    plt.show()\n\n\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    LSTM(\n        # model.add(SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n## RNN\n\n### No Regularization\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n     \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n\n\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Ensures a 1D array output\n\n# Check shapes again to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (train_rmse**2.0, train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (test_rmse**2.0, test_rmse))\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n## GRU\n\n### No Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n      \n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n# Call the function with your data\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        # recurrent_dropout=0.8,\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()  # Ensures a 1D array output\ntest_predict = model.predict(testX).flatten()\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\n# Call the function with your data\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\n# Discussions II\n\n## For GDP Deflator\n\n### Deep learning methods comparison\nIn my case, the LSTM performed the best with lowest RMSE. In addition, the prediction plot with the actual data also shows that the LSTM is better among the three methods for GDP Deflator analysis.\n\n### Regularization Effect\nFor LSTM, the regularization actually did not give in too much difference in the results. However, for RNN and GRU, the result suggests that the model is overfitting. The RMSE for both model is different when appling regularization. Therefore, regularization help these two models for not overfitting.\n\n### How Far can the deep learning methods predict\nIn my analsyis for gdp deflator, overall, the LSTM made relatively better predictions. The predictions aligned the actual points for all time steps. This imply that the LSTM model has very effective prediction power for the gdp deflator. Therefore, I think it can predict the values correctly given the trend and pattern for pretty long time in to the future if there is no sudden change or other external impacts.\n\n### Comparison to VAR Model\nThe LSTM model performs the best with relatively low RMSE. Compare to the VAR model in VAR section, the model used for GDP Deflator was Var(13). For Var(13) The RMSE for cross validation is also relatively small. However, in my case, I still believe that the LSTM model provides better predictions. The possible reason I think is that the deep learning models can evaluate the dataset by capturing more features with deeper analysis. The deep learning model can interpret the trend better with each epoch trained therefore we can get better results. In addition, for LSTM the overfitting did not exist. However, for other model, the RNN and GRU are not as effective as the VAR model.\n\n\n\n# Multivariable Deep Learning (OPTIONAL)\n\n## Data Preparation: GDP Deflator, Personal Saving Rate, Median Sale Price\n\n```{python}\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf2['DATE'] = pd.to_datetime(df2['DATE'])\ndf3['DATE'] = pd.to_datetime(df3['DATE'])\n\n\n# Filter data based on the date range\nstart_date = '1963-01-01'\nend_date = '2023-04-01'\ndf1 = df[(df['DATE'] >= start_date) & (df['DATE'] <= end_date)]\ndf2 = df2[(df2['DATE'] >= start_date) & (df2['DATE'] <= end_date)]\ndf3 = df3[(df3['DATE'] >= start_date) & (df3['DATE'] <= end_date)]\n\n# Merge the dataframes on the 'DATE' column\ndf = pd.merge(df1, df2, on='DATE', how='inner')\ndf = pd.merge(df, df3, on='DATE', how='inner')\n\ndf.head()\n\n\n\n\n# Train/Test Split & Normalization\ndef train_test_split_normalize(data, split_percent=0.8):\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data_scaled = scaler.fit_transform(data)\n    n = len(data_scaled)\n   \n    split = int(n * split_percent)\n    train_data = data_scaled[:split, :]\n    test_data = data_scaled[split:, :]\n    return train_data, test_data, data_scaled\n\n# Assuming the data from the CSVs are now in df\ntrain_data, test_data, _ = train_test_split_normalize(df.iloc[:, 1:].values)  # Exclude 'DATE' column\n\n# Prepare input X and target Y for multivariate time-series\ndef get_XY_multivariate(dat, time_steps, num_features):\n    X, Y = [], []\n    for i in range(len(dat) - time_steps):\n        X.append(dat[i:(i + time_steps), :])\n        Y.append(dat[i + time_steps, 0])  # Assuming target is the first feature\n    return np.array(X), np.array(Y)\n\n# Partition Data\np = 30  # Time steps\nnum_features = df.shape[1] - 1  # Number of features, excluding 'DATE' column\ntrainX, trainY = get_XY_multivariate(train_data, p, num_features)\ntestX, testY = get_XY_multivariate(test_data, p, num_features)\n\n# Display shapes\nprint(\"Testing Array Shape:\", testX.shape, testY.shape)\nprint(\"Training Array Shape:\", trainX.shape, trainY.shape)\n\nfig, ax = plt.subplots(figsize=(15, 6), dpi=100)  # Set the size and DPI of the figure\nfig.patch.set_facecolor('#E0E0E0')  # Set the background color for the outer figure\nax.set_facecolor('#E0E0E0')  # Set the background color for the axes\n\n# Plot the training data for each time-series\nax.plot(range(0, len(train_data)), train_data[:, 0], \"-\", label=\"Training Data - TS1\")\nax.plot(range(0, len(train_data)), train_data[:, 1], \"-\", label=\"Training Data - TS2\")\nax.plot(range(0, len(train_data)), train_data[:, 2], \"-\", label=\"Training Data - TS3\")\n\n# Plot the test data for each time-series\nax.plot(range(len(train_data), len(train_data) + len(test_data)), test_data[:, 0], \"-\", label=\"Test Data - TS1\")\nax.plot(range(len(train_data), len(train_data) + len(test_data)), test_data[:, 1], \"-\", label=\"Test Data - TS2\")\nax.plot(range(len(train_data), len(train_data) + len(test_data)), test_data[:, 2], \"-\", label=\"Test Data - TS3\")\n\n# Set labels and title\nax.set(xlabel=\"Time (days)\", ylabel=\"Values Scaled\", title=\"Multivariate Time Series Over Time\")\n\n# Add grid with white color for better visibility on the gray background\nax.grid(color='white')\n\n# Add legend to the plot\nax.legend()\n\n# Show the plot\nplt.show()\n```\n\n## Array Preparations for Modeling\n```{python}\ndef get_XY_multivariate(dat, time_steps, num_features, plot_data_partition=False):\n    X, Y = [], []\n\n    # Prepare X and Y\n    for i in range(len(dat) - time_steps):\n        X.append(dat[i:i + time_steps, :])\n        Y.append(dat[i + time_steps, 0])  # Assuming target is the first feature at the next time step\n\n    # Convert to numpy arrays\n    X = np.array(X)\n    Y = np.array(Y)\n\n    if plot_data_partition:\n        plt.figure(figsize=(15, 6), dpi=80)\n        for i in range(num_features):\n            plt.plot(Y_ind, dat[Y_ind, i], \"o\", label=f\"Feature {i+1} Targets\")\n            plt.plot(range(len(dat)), dat[:, i], \"-\", label=f\"Feature {i+1} Data\")\n        plt.legend()\n        plt.show()\n\n    return X, Y\n\n# Use this function to partition data again\ntestX, testY = get_XY_multivariate(test_data, p, num_features)\ntrainX, trainY = get_XY_multivariate(train_data, p, num_features)\n\n# Print shapes\nprint(\"Testing Array Shape:\", testX.shape, testY.shape)\nprint(\"Training Array Shape:\", trainX.shape, trainY.shape)\n #USER PARAM\nrecurrent_hidden_units = 3\nepochs = 200\nf_batch = 0.2  # fraction used for batch size\noptimizer = \"RMSprop\"\nvalidation_split = 0.2\n\n```\n\n\n## LSTM\n\n### No Regularization\n```{python}\n\nmodel = Sequential()\n\nmodel.add(\n    LSTM(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\nmodel.summary()\n# TRAIN MODEL\nhistory = model.fit(\n    trainX,\n    trainY,\n    epochs=200,\n    batch_size=int(f_batch * trainX.shape[0]),\n    validation_split=validation_split,\n    verbose=0,\n)\n\n# MAKE PREDICTIONS\ntrain_predict = model.predict(trainX).squeeze()\ntest_predict = model.predict(testX).squeeze()\n\n\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure(facecolor='#E0E0E0', dpi=200)  # Set the background color and DPI\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'c', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.gca().set_facecolor('#E0E0E0')  # Set the axes background color\nplt.grid(color='white')  # Set the grid color to white for better visibility on the gray background\nplt.show()\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\ndef plot_result(trainY, testY, train_predict, test_predict):\n    plt.figure(figsize=(15, 6), dpi=200, facecolor='#E0E0E0')\n    plt.gca().set_facecolor('#E0E0E0')\n\n    # Create time indices for training and testing data\n    time_indices_train = range(len(trainY))\n    time_indices_test = range(len(testY))\n\n    # Plotting actual values vs. predictions for training data\n    plt.subplot(1, 2, 1)\n    plt.plot(time_indices_train, trainY, \"o\", label=\"Actual Train\")\n    plt.plot(time_indices_train, train_predict, \"r-\", label=\"Predicted Train\")\n    plt.title(\"Training: Actual vs Predicted\")\n    plt.xlabel(\"Time Steps\")\n    plt.ylabel(\"Scaled Value\")\n    plt.legend()\n\n    # Plotting actual values vs. predictions for testing data\n    plt.subplot(1, 2, 2)\n    plt.plot(time_indices_test, testY, \"o\", label=\"Actual Test\")\n    plt.plot(time_indices_test, test_predict, \"r-\", label=\"Predicted Test\")\n    plt.title(\"Testing: Actual vs Predicted\")\n    plt.xlabel(\"Time Steps\")\n    plt.ylabel(\"Scaled Value\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Calling the function\nplot_result(trainY, testY, train_predict, test_predict)\n\n\n\n```\n\n### With Regularization\n\n```{python}\n\nmodel = Sequential()\n\nmodel.add(\n    LSTM(\n        \n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\n\n\n\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n\n\n\n# Calling the function\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\n## RNN\n\n```{python}\n\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\nplot_result(trainY, testY, train_predict, test_predict)\n\n```\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    SimpleRNN(\n        # model.add(GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Now, print the shapes to verify\nprint(\"Shape of test_predict after flattening:\", test_predict.shape)\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n## GRU\n\n### No Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n# Calling the function\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n### With Regularization\n\n```{python}\n# CREATE MODEL\nmodel = Sequential()\n# COMMENT/UNCOMMENT TO USE RNN, LSTM,GRU\nmodel.add(\n    GRU(\n        recurrent_hidden_units,\n        return_sequences=False,\n        input_shape=(trainX.shape[1], trainX.shape[2]),\n        recurrent_regularizer=regularizers.L2(1e-2),\n        activation=\"tanh\",\n    )\n)\n\n# NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR\nmodel.add(Dense(units=1, activation=\"linear\"))\n\n# COMPILE THE MODEL\nmodel.compile(loss=\"MeanSquaredError\", optimizer=optimizer)\n# Make predictions\ntrain_predict = model.predict(trainX).flatten()\ntest_predict = model.predict(testX).flatten()  # Flattening to ensure it is a 1D array\n\n# Compute RMSE\ntrain_rmse = np.sqrt(mean_squared_error(trainY, train_predict))\ntest_rmse = np.sqrt(mean_squared_error(testY, test_predict))\n\n# Print MSE and RMSE\nprint(\"Train MSE = %.5f RMSE = %.5f\" % (np.mean((trainY - train_predict) ** 2.0), train_rmse))\nprint(\"Test MSE = %.5f RMSE = %.5f\" % (np.mean((testY - test_predict) ** 2.0), test_rmse))\n# Calling the function\nplot_result(trainY, testY, train_predict, test_predict)\n```\n\n\n# Discussion III\n\n## Overall Effect of Including Regularization:\nRegularization is used to prevent overfitting by penalizing large weights in the model. \nIn my case, the LSTM performs the best. However, there are difference for using regularization. The results show that there are some overfitting if we do not use regularization. Therefore, in my case, the regularization is effective in preventing overfitting\n\n## How far can the Deep Learning Model predict\nIt seems that the deep learning model did not preform too well for these mutivariables. The points are off with the actual values. However, the patterns and trends are captured. Therefore, I would say that for multivariable analysis, the deep learning methods might not be the most optimal choice. By adding additional dataset, the ability of predicting is not improved."},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles/layout.css","./styles/layout.css"],"toc":true,"output-file":"TS.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","theme":"sandstone","title":"Deep Learning for TS","navbar":{"left":["about.qmd","Introduction.qmd","DataSources.qmd","DataVis.qmd","EDA.qmd","ARModels.qmd","ASV.qmd","SAF.qmd","GARCH.qmd","TS.qmd","conclusion.qmd","dv.qmd"]}},"extensions":{"book":{"multiFile":true}}}}}