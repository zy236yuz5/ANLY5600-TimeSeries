---
title: "Exploratory Data Analysis"
navbar:
    left:
      
      - about.qmd
      
      - Introduction.qmd
      - DataSources.qmd
      - DataVis.qmd
      - EDA.qmd
      - ARModels.qmd
      - ASV.qmd
      - SAF.qmd
      - GARCH.qmd
      - TS.qmd
      - conclusion.qmd
      - dv.qmd

format:
  html:
    theme: sandstone
    css: ./styles/layout.css
    code-fold: true
    toc: true
---


For Exploratory Data Analysis (EDA), we aim to have a deeper understanding of the time series data. This section involves multiple medthods and datasets for us to gain insights and understandings such as decompositions, lag plots, ACF, PACF, ADF tests, detrending, and others. For these methods, we are going to identify correlations, trends, seasonalities, and stationaries. Which can help us to make analysis and apply models in later sections. To be more specific, the lag plots and decomposing methods will allow us to discover dependencies and components. ACF and PACF can help us see the correlations and stationary, and the Augmented Dickey-Fuller Test to empirically probe its stationarity. 

## The Household Income Data Analysis

As we did in previous section, we start with the household income. In here, we have a basic look about the household income time series.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(reticulate)
library(ggplot2)
library(forecast)
library(astsa) 
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(tidyverse)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
library(ggplot2)
library(lubridate)
```

```{r, echo=FALSE, results='hide',warning=FALSE,message=FALSE}
df <- read.csv("../Dataset/project/household_saving.csv")
df$DATE <- as.Date(df$DATE)

```

```{r,warning=FALSE,echo=FALSE}
library(ggplot2)


ggplot(data = df, aes(x = DATE, y = W398RC1A027NBEA)) +
  geom_line(color = "DarkViolet") +
  labs(title = "Time Series Plot of Household Income",
       x = "Date", 
       y = "The Household Income") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))


```

From the plot, we can visually inspect:
Trend: There is clearly positive trend.
Seasonality: It seems that it does not contain patterns.
Variation: Fluctuations in the data exists.
Periodic fluctuations: The fluctuations are randomly presented.
multiplicative or additive： Only based on the timeseries plot, I think this follows multiplicative, because it has varying amplitude/frequency.

<br>
<br>

Then, we want to see if there is any correlations. By utilizing lag plot, we can see if there are any correlations present:

### LAG Plot
```{r,warning=FALSE,echo=FALSE}
# Lag plot
lagged_data <- data.frame(value = df$W398RC1A027NBEA[-1],
                          lagged_value = df$W398RC1A027NBEA[-length(df$W398RC1A027NBEA)])

# Enhanced Lag Plot
ggplot(data = lagged_data, aes(x = lagged_value, y = value)) +
  geom_point(color = "DarkViolet", alpha = 0.5) +
  labs(title = "Lag Plot",
       x = "Value at t-1",
       y = "Value at t") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))



```


Based on the lag plot, there's a positive correlation since the points cluster along a diagonal line from bottom-left to top-right. This shows linearity. However, it could also mean that the dataset is not stationary.

In order to determine if the dataset is stationary. we should use other methods as well. Before doing that, we should first check the trend, seasonality through decompositions.

### Decomposition
```{r, echo=FALSE}
#library(ggfortify)

# Decomposition using ggplot2 styling
decomposed <- decompose(ts(df$W398RC1A027NBEA, frequency=12), type = "additive")
autoplot(decomposed) + 
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```


Now, based on the decomposition plot, we can see that it is correct that the data follows an upwarding trend. However, it seems that there is seasonal pattern involves with flutuations. In addition, it has varying amplitude/frequency. Therefore, I think this follows multiplicative.

Then, we should utilize ACF and PACF to see about the correlation and stationary.

### ACF & PACF
```{r, echo=FALSE}
library(forecast)

# ACF Plot
ggAcf(df$W398RC1A027NBEA) +
  labs(title = "ACF of Household Income Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

# PACF Plot
ggPacf(df$W398RC1A027NBEA) +
  labs(title = "PACF of Household Income Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that the dataset has a correlation, which also means that it is not stationary. In order to prove this conclusion, we utilize the adf test to ensure the results are the same.


### Validation with ADF Test
```{r, echo=FALSE}
library(tseries)
adf.test(df$W398RC1A027NBEA)


```

Based on the result, we can see that the p-value is greater than the thershold value, this means that we fail to reject the Null hypothesis. The time series dataset is not stationary.

Then, to explore more, we utilize detrended and log-transformation to see about the patterns


### Detrended and Log-transformed
```{r, echo=FALSE}
detrended_data <- data.frame(Date = df$DATE[-1], Detrended = diff(df$W398RC1A027NBEA))

# Enhanced Detrended Plot
ggplot(data = detrended_data, aes(x = Date, y = Detrended)) +
  geom_line(color = "blue") +
  labs(title = "Detrended Household Income Time Series",
       x = "Date",
       y = "Detrended Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```


```{r,warning=FALSE, echo=FALSE}
log_transformed_data <- data.frame(Date = df$DATE, LogTransformed = log(df$W398RC1A027NBEA))

# Enhanced Log-transformed Plot with Custom Background
ggplot(data = log_transformed_data, aes(x = Date, y = LogTransformed)) +
  geom_line(color = "blue") +
  labs(title = "Log-transformed Time Series of Household Income",
       x = "Date",
       y = "Log-transformed Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that after detrending and dfferencing, the household income remains fluctuations espectially during 2020 period, which could be the cause of the Covid-19. In addition, Log-transformed time series, in order to remove the hetroscadastisity, we can see that the trend remains. I think the reason is possibly because log-transformation can assuage issues related to non-constant variance, which means that the inherent trend within the data may persist.

### Make it Stationary by using differencing
```{r}
diff_series <- diff(df$W398RC1A027NBEA)

# Plotting the differenced series
ggplot(data = data.frame(Date = df$DATE[-1], Diff = diff_series), aes(x = Date, y = Diff)) +
  geom_line(color = "blue") +
  labs(title = "Differenced Household Income Time Series",
       x = "Date",
       y = "Differenced Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

# ACF Plot for differenced series
ggAcf(diff_series) +
  labs(title = "ACF of Differenced Household Income Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that after detrending and dfferencing has succeeded in making the datasets stationary: spikes all fall within the blue shaded confidence intervals, which represent the region where correlations are not statistically significant.


## The Median House Sale Price Data Analysis

Since our key is to discover the impact of the income and house price, we certainly need to make analysis for the sale price data. 

### The Time Series
```{r, echo=FALSE, results='hide',warning=FALSE,message=FALSE}
df <- read.csv("../Dataset/project/MSPUS.csv")
df$DATE <- as.Date(df$DATE)
```



```{r,warning=FALSE,echo=FALSE}
library(ggplot2)


ggplot(data = df, aes(x = DATE, y = MSPUS)) +
  geom_line(color = "blue") +
  labs(title = "Time Series Plot of Median Sale Price",
       x = "Date", 
       y = "The Sale Price") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))


```
From the plot, the results are the same with the previous section. It has an upwarding trend. 

To be more specific, from the plot, we can visually inspect:
Trend: There is clearly positive trend.
Seasonality: It seems that it does not contain patterns.
Variation: Fluctuations in the data exists but not too much.
Periodic fluctuations: The fluctuations are presented in 2010 and 2021.
multiplicative or additive： Only based on the timeseries plot, I think this follows additive, because it does not have too much variance.


Then, we want to see if there is any correlations. By utilizing lag plot, we can see if there are any correlations present:


### Lag Plots
```{r,warning=FALSE,echo=FALSE}
# Lag plot
lagged_data <- data.frame(value = df$MSPUS[-1],
                          lagged_value = df$MSPUS[-length(df$MSPUS)])

# Enhanced Lag Plot
ggplot(data = lagged_data, aes(x = lagged_value, y = value)) +
  geom_point(color = "blue", alpha = 0.5) +
  labs(title = "Lag Plot",
       x = "Value at t-1",
       y = "Value at t") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))



```

Based on the lag plot, there's a positive correlation since the points cluster along a diagonal line from bottom-left to top-right. In addition, this aligns with the same conclusion and it has a strong positive correlation. This shows linearity. 

### Decomposition for the data
```{r, echo=FALSE}
#library(ggfortify)

# Decomposition using ggplot2 styling
decomposed <- decompose(ts(df$MSPUS, frequency=12), type = "additive")
autoplot(decomposed) + 
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

Now, based on the decomposition plot, we can see that it is correct that the data follows an upwarding trend.  In addition, it has roughly constant amplitude/frequency. Therefore, I think this follows additive.

Then, we should utilize ACF and PACF to see about the correlation and stationary.

### ACF and PACF of the data
```{r, echo=FALSE}
library(forecast)

# ACF Plot
ggAcf(df$MSPUS) +
  labs(title = "ACF of Median Sale Price Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

# PACF Plot
ggPacf(df$MSPUS) +
  labs(title = "PACF of Median Sale Price Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that the dataset has a correlation, which also means that it is not stationary. In order to prove this conclusion, we utilize the adf test to ensure the results are the same.

### ADF Test
```{r, echo=FALSE}
library(tseries)
adf.test(df$MSPUS)


```

Based on the result, we can see that the p-value is greater than the thershold value, this means that we fail to reject the Null hypothesis. The time series dataset is not stationary.

Then, to explore more, we utilize detrended and log-transformation to see about the patterns

### Detrended and Log transformation
```{r, echo=FALSE}
detrended_data <- data.frame(Date = df$DATE[-1], Detrended = diff(df$MSPUS))

# Enhanced Detrended Plot
ggplot(data = detrended_data, aes(x = Date, y = Detrended)) +
  geom_line(color = "blue") +
  labs(title = "Detrended Median Sale Price Time Series",
       x = "Date",
       y = "Detrended Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```



```{r,warning=FALSE, echo=FALSE}
log_transformed_data <- data.frame(Date = df$DATE, LogTransformed = log(df$MSPUS))

# Enhanced Log-transformed Plot with Custom Background
ggplot(data = log_transformed_data, aes(x = Date, y = LogTransformed)) +
  geom_line(color = "blue") +
  labs(title = "Log-transformed Time Series of Median Sale Price",
       x = "Date",
       y = "Log-transformed Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that after detrending, the sale prices remains fluctuations espectially from 2000 to 2020 period. In addition, Log-transformed time series, in order to remove the hetroscadastisity, we can see that the trend remains. I think the reason is possibly because log-transformation can assuage issues related to non-constant variance, which means that the inherent trend within the data may persist.

### Make it Stationary by using differencing
```{r}
diff_series <- diff(df$MSPUS)

# Plotting the differenced series
ggplot(data = data.frame(Date = df$DATE[-1], Diff = diff_series), aes(x = Date, y = Diff)) +
  geom_line(color = "blue") +
  labs(title = "Differenced Sale Price Time Series",
       x = "Date",
       y = "Differenced Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

# ACF Plot for differenced series
ggAcf(diff_series) +
  labs(title = "ACF of Differenced Sale Price Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that after detrending and dfferencing has succeeded in making the datasets stationary: Most of the spikes fall within the blue shaded confidence intervals, which means that the dataset is stationary now compared to the orginal one.

## The Housing Affordability Index Data Analysis

Then, after we have a basic understanding about the income and sale price. We need to dive into the impact. We utilize the housing affordability index to see the impact of the income and sale price. Let us firt explore the houseing affordability index first.

### Time Series Plot for Housing Affordability Index
```{r, echo=FALSE, results='hide',warning=FALSE,message=FALSE}
df <- read.csv("../Dataset/project/PSAVERT.csv")
df$DATE <- as.Date(df$DATE)

```

```{r,warning=FALSE}
library(ggplot2)


ggplot(data = df, aes(x = DATE, y = PSAVERT)) +
  geom_line(color = "blue") +
  labs(title = "Time Series Plot of Housing Affordability Index",
       x = "Date", 
       y = "The Housing Affordability Index") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))


```

From the plot, we can visually inspect:
Trend: It seems that it did not have a consistent trend. From 1960 to 1970, it has upwarding trend. But then it has dewarding trend. And has a huge fluctuations during 2020, Covid period.
Seasonality: I think there are small patterns that show seasonality in dataset.
Variation: Fluctuations in the data exist.
Periodic fluctuations: Spikes or drops at consistent intervals exist.
Multiplicative or additive: I think the dataset could follow an additive pattern. Because it seems that it has constant amplitude and frequency although with some fluctuations. In order to prove these, we need to explore more using different methods.

### Lag Plot for Houseing Affordability
```{r}
# Lag plot
lagged_data <- data.frame(value = df$PSAVERT[-1],
                          lagged_value = df$PSAVERT[-length(df$PSAVERT)])

# Enhanced Lag Plot
ggplot(data = lagged_data, aes(x = lagged_value, y = value)) +
  geom_point(color = "blue", alpha = 0.5) +
  labs(title = "Lag Plot",
       x = "Value at t-1",
       y = "Value at t") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))



```

Based on the lag plot, there's a positive correlation since the points cluster along a diagonal line from bottom-left to top-right. This shows linearity. However, it could also mean that the dataset is not stationary.

In order to determine if the dataset is stationary. we should use other methods as well. Before doing that, we should first check the trend, seasonality through decompositions.

### Decomposition of the Housing Affordability
```{r}
#library(ggfortify)

# Decomposition using ggplot2 styling
decomposed <- decompose(ts(df$PSAVERT, frequency=12), type = "additive")
autoplot(decomposed) + 
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

Now, based on the decomposition plot, we can see that it is correct that the data did not follow a specific trend. However, it seems that there is seasonal pattern involves with flutuations. In addition, mostly it has constant amplitude/frequency. Therefore, I think this follows additive pattern.

Then, we should utilize ACF and PACF to see about the correlation and stationary.


### ACF and PACF Analysis
```{r}
library(forecast)

# ACF Plot
ggAcf(df$PSAVERT) +
  labs(title = "ACF of Housing Affordability Index Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

# PACF Plot
ggPacf(df$PSAVERT) +
  labs(title = "PACF of Housing Affordability Index Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

The ACF plot can help determine if the series is stationary. From here, we can see that the dataset has a correlation, and it is decaying slowly which also means that it is not stationary. In order to prove this conclusion, we utilize the adf test to ensure the results are the same. 

### ADF Test
```{r}
library(tseries)
adf.test(df$PSAVERT)


```

Based on the ADF test, since the p-value is smaller than the threshold value, we should reject the null hypothesis, which means that the dataset is stationary! However, the value is close to 0.05. In addition, the ADF test is not as reliable as the ACF test. Therefore, since the ACF decays slowly, and it showed strong correlation. This means that, the dataset is not stationary.


### Detrened and Log-transformation
Then, to explore more, we utilize detrended and log-transformation to see about the patterns


```{r}
detrended_data <- data.frame(Date = df$DATE[-1], Detrended = diff(df$PSAVERT))

# Enhanced Detrended Plot
ggplot(data = detrended_data, aes(x = Date, y = Detrended)) +
  geom_line(color = "blue") +
  labs(title = "Detrended Time Series",
       x = "Date",
       y = "Detrended Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```


```{r,warning=FALSE}
log_transformed_data <- data.frame(Date = df$DATE, LogTransformed = log(df$PSAVERT))

# Enhanced Log-transformed Plot with Custom Background
ggplot(data = log_transformed_data, aes(x = Date, y = LogTransformed)) +
  geom_line(color = "blue") +
  labs(title = "Log-transformed Time Series of Housing Affordability Index",
       x = "Date",
       y = "Log-transformed Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that after detrending, the household income remains fluctuations espectially during 2020 period, which could be the cause of the Covid-19. In addition, Log-transformed time series, in order to remove the hetroscadastisity, we can see that the trend remains. I think the reason is possibly because log-transformation can assuage issues related to non-constant variance, which means that the inherent trend within the data may persist.

### ENsure it Stationary by using differencing
```{r}
diff_series <- diff(df$PSAVERT)

# Plotting the differenced series
ggplot(data = data.frame(Date = df$DATE[-1], Diff = diff_series), aes(x = Date, y = Diff)) +
  geom_line(color = "blue") +
  labs(title = "Differenced Housing Affordability IndexTime Series",
       x = "Date",
       y = "Differenced Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

# ACF Plot for differenced series
ggAcf(diff_series) +
  labs(title = "ACF of Differenced Housing Affordability Index Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that after detrending and dfferencing has succeeded in making the datasets stationary: Most of the spikes fall within the blue shaded confidence intervals, which means that the dataset is stationary now compared to the orginal one.


## The GDP Exploratory Data Analysis

Then, after making analysis for income, sale price, and houseing affordability. We should have a look at for analyzing the GDP, which can represent the economy as a whole. By analyzing the GDP data, we can have a more generalized view and gain more insights about the patterns, seasonalities, and stationaries.

### Time Series Plot of GDP
```{r, echo = FALSE}
df <- read.csv("../Dataset/project/A191RI1Q225SBEA.csv")
df$DATE <- as.Date(df$DATE)
```
```{r, echo = FALSE,warning=FALSE}
library(ggplot2)


ggplot(data = df, aes(x = DATE, y = A191RI1Q225SBEA)) +
  geom_line(color = "blue") +
  labs(title = "Time Series Plot of GDP",
       x = "Date", 
       y = "Percent Change from Preceding Period") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))


```

From the plot, we can visually inspect:
Trend: It seems that it did not have a consistent trend. From 1960 to 1980, it has upwarding trend. But then it has dewarding trend. And has a huge fluctuations during 2020, Covid period. Which is similar to the houseing affordability index. I think we can see that there is a positive correlation between GDP and housing affordability index. When GDP gets higher, people can afford a house more easily.
Seasonality: I think there are small patterns that show seasonality in dataset.
Variation: Fluctuations in the data exist.
Periodic fluctuations: Spikes or drops at consistent intervals exist.
Multiplicative or additive: I think the dataset could follow a multiplicative pattern. Because it seems that it does not have constant amplitude and frequency. In order to prove these, we need to explore more using different methods.

### Lag for GDP
```{r, echo = FALSE}
# Lag plot
lagged_data <- data.frame(value = df$A191RI1Q225SBEA[-1],
                          lagged_value = df$A191RI1Q225SBEA[-length(df$A191RI1Q225SBEA)])

# Enhanced Lag Plot
ggplot(data = lagged_data, aes(x = lagged_value, y = value)) +
  geom_point(color = "blue", alpha = 0.5) +
  labs(title = "Lag Plot",
       x = "Value at t-1",
       y = "Value at t") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))
```

Based on the lag plot, there's a correlation but not too strong. This shows potential linearity. However, it could also mean that the dataset is not stationary but we can not decide yet.

In order to determine if the dataset is stationary. we should use other methods as well. Before doing that, we should first check the trend, seasonality through decompositions.

### Decomposition of the Data
```{r, echo = FALSE}

# Decomposition using ggplot2 styling
decomposed <- decompose(ts(df$A191RI1Q225SBEA, frequency=12), type = "multiplicative")
autoplot(decomposed) + 
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))
```

Now, based on the decomposition plot, we can see that it is correct that the data did not follow a specific trend. However, it seems that there is seasonal pattern involves with flutuations. In addition, it has almost constant amplitude/frequency. Therefore, I think this follows multiplicative.

Then, we should utilize ACF and PACF to see about the correlation and stationary.

### ACF and PACF
```{r, echo = FALSE}
library(forecast)

# ACF Plot
ggAcf(df$A191RI1Q225SBEA) +
  labs(title = "ACF of GDP Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

# PACF Plot
ggPacf(df$A191RI1Q225SBEA) +
  labs(title = "PACF of GDP Time Series") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        plot.background = element_rect(fill = "#E0E0E0"))

```

From here, we can see that the acf decays very quickly, which also means that it is stationary. In order to prove this conclusion, we utilize the adf test to ensure the results are the same.

```{r, echo = FALSE}
library(tseries)
adf.test(df$A191RI1Q225SBEA)
```

Based on the result, we can see that the p-value is smaller than the thershold value, this means that we reject the Null hypothesis. The time series dataset is stationary.

Then, to explore more, we utilize detrended and log-transformation to see about the patterns

### Detrended and Log-transformation
```{r, echo = FALSE}
detrended_data <- data.frame(Date = df$DATE[-1], Detrended = diff(df$A191RI1Q225SBEA))

# Enhanced Detrended Plot
ggplot(data = detrended_data, aes(x = Date, y = Detrended)) +
  geom_line(color = "blue") +
  labs(title = "Detrended Time Series",
       x = "Date",
       y = "Detrended Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```


```{r, warning=FALSE, echo = FALSE}
log_transformed_data <- data.frame(Date = df$DATE, LogTransformed = log(df$A191RI1Q225SBEA))

# Enhanced Log-transformed Plot with Custom Background
ggplot(data = log_transformed_data, aes(x = Date, y = LogTransformed)) +
  geom_line(color = "blue") +
  labs(title = "Log-transformed Time Series of GDP",
       x = "Date",
       y = "Log-transformed Value") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#E0E0E0"),
        panel.grid.major = element_line(color = "grey", size = 0.1),
        panel.grid.minor = element_line(color = "grey", size = 0.05),
        plot.background = element_rect(fill = "#E0E0E0"))

```

Since, the original dataset is already stationary. Therefore, no further action is needed to make it stationary. The detrend and log transformation is just to explore the dataset.


## The Sale Price Disparity Analysis

Lastly, after analyzing the corresponding numeric datasets, we will explore more about the disparitis by using the Mean Sale price datasets which involves with different regions and states. From here, by making analysis on the pattern and seasonality, it can help us provide with more insights and knowledge in determining the impact of the disparities of the income and sale prices.

### Time Series Decomposition Plot
```{python, echo=FALSE}
import  pandas  as  pd

import matplotlib.pyplot as plt
import altair as alt
import warnings
warnings.filterwarnings('ignore')

```


```{python, echo=FALSE}
# directory containing the CSV files

path2 = '../Dataset/project/Merged_downsample.csv'

df_selected = pd.read_csv(path2)
plt.rcParams.update(plt.rcParamsDefault)
import matplotlib as mpl

# Set global figure settings
mpl.rcParams['figure.facecolor'] = '#E0E0E0'
mpl.rcParams['axes.facecolor'] = '#E0E0E0'
mpl.rcParams['savefig.facecolor'] = '#E0E0E0'
warnings.filterwarnings('ignore')
```


```{python,echo=FALSE}
from statsmodels.tsa.seasonal import seasonal_decompose

# Decomposing
result = seasonal_decompose(df_selected['Mean Sale Price'].values, model='additive', period=12)
fig = result.plot()
fig.set_facecolor('#E0E0E0')
plt.show()

warnings.filterwarnings('ignore')
```

From the decomposition plot, we can visually inspect:
Trend: There is no clear trend.
Seasonality: It seems that it has seasonal patterns.
Variation: Fluctuations in the data exists.
Periodic fluctuations: The fluctuations are randomly presented.
multiplicative or additive： I think this follows multiplicative, because it has varying amplitude/frequency.

Then, we want to see if there is any correlations. By utilizing lag plot, we can see if there are any correlations present:

### Lag Plot 
```{python, echo=FALSE}
from pandas.plotting import lag_plot

plt.figure(figsize=(6, 6))
lag_plot(df_selected['Mean Sale Price'])
plt.title('Lag Plot of Mean Sale Price')
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.show()

```

Based on the lag plot, there's a strong positive correlation since the points cluster along a diagonal line from bottom-left to top-right. This shows linearity. 

In order to explore more, we utilize the acf and pacf to check the accuracy.

### ACF and PACF plots
```{python, echo=FALSE}
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# ACF plot
fig, ax = plt.subplots(figsize=(10, 4))
plot_acf(df_selected['Mean Sale Price'], ax=ax)
plt.title('ACF of Mean Sale Price')
plt.show()

# PACF plot
fig, ax = plt.subplots(figsize=(10, 4))
plot_pacf(df_selected['Mean Sale Price'], ax=ax)
plt.title('PACF of Mean Sale Price')
plt.show()


```

From here, we can see that the dataset has a correlation and decays slowly. Howeverm for PACF, it decays dramatically. Therefore, we can say that it is stationary. In order to prove this conclusion, we utilize the adf test to ensure the results are the same.


### ADF tests
```{python, echo=FALSE}
from statsmodels.tsa.stattools import adfuller

adf_result = adfuller(df_selected['Mean Sale Price'].values)
print(f'ADF Statistic: {adf_result[0]}')
print(f'p-value: {adf_result[1]}')
print('Critical Values:')
for key, value in adf_result[4].items():
    print(f'\t{key}: {value}')

```

Based on the result, we can see that the p-value is smaller than the thershold value, this means that we can reject the Null hypothesis. The time series dataset is stationary.

Then, we wish to make analysis for different values to see if they have correlations among each other. A heatmap can also help us to determine the correlations among the sale price, rental price, and homevalue of the dataset.

### Correlation heatmap
```{python, echo=FALSE}
import seaborn as sns
import matplotlib.pyplot as plt
# Filter only numeric columns
df_selected = df_selected.rename(columns={
    "mean": "Mean Rental Price",
    "Log_Mean_Sale_Price": "Log Mean Sale Price"
})


numeric_cols = df_selected.select_dtypes(include=[float, int])

```


```{python, echo=FALSE}


# Calculate correlations
corr = numeric_cols.corr()

# Set up the matplotlib figure with the desired theme
plt.figure(figsize=(10, 8))
sns.set_theme(style="white", rc={"axes.facecolor": "#E0E0E0", "grid.color": "#E0E0E0"})
sns.set_context("talk")

# Draw the heatmap with a color map of choice
sns.heatmap(corr, annot=True, cmap='coolwarm', linewidths=0.5, linecolor='black')

# Adjust the plot's aesthetics
plt.title('Correlation Heatmap')
plt.show()

```

From here, we can see that there is a strong  positive correlation between the Sale price and home value. The higher of the home value, the higher of the sale price. However, the rental price did not have too much correlations with the other two. The possible reason could be the cause of the geographic difference and this could also affect the housing affordability.

In conclusion, in this section, we provide different observations. And these observations underscore the nature of real estate pricing, incomes, GDP changes througout the years as well as the housing affordability. In addition, different patterns and features are found to identify the trend, seasonality, patterns, and correlations. which allow us to have a more understanding about the dataset.


# References and Codes
- Codes: [Rmd, Python & Qmd](https://github.com/zy236yuz5/ANLY5600-TimeSeries)
- U.S. Bureau of Economic Analysis, Household saving [W398RC1A027NBEA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/W398RC1A027NBEA, September 19, 2023.
- U.S. Census Bureau, Real Median Household Income in the United States [MEHOINUSA672N], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/MEHOINUSA672N, September 19, 2023.
- U.S. Bureau of Economic Analysis, Gross Domestic Product: Implicit Price Deflator [A191RI1Q225SBEA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/A191RI1Q225SBEA, September 18, 2023.
- Zillow Group. Accessed April 19, 2023. “Zillow Research Data.” https://www.zillow.com/research/data/.